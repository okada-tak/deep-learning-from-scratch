{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/okada-tak/deep-learning-from-scratch/blob/master/notebooks/ch07.ipynb)\n",
        "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/okada-tak/deep-learning-from-scratch/blob/master/notebooks/ch07.ipynb)  \n",
        "# ■ch07/xxxx.py以外は追記（岡田）\n",
        "# 7章 畳み込みニューラルネットワーク のまとめ\n",
        "- CNNは、これまでの全結合層のネットワークに対して、畳み込み層とプーリング層が新たに加わる。  \n",
        "- 畳み込み層とプーリング層は、im2col(画像を行列に展開する関数)を用いるとシンプルで効率の良い実装ができる。  \n",
        "- CNNの可視化によって、層が深くなるにつれて高度な情報が抽出されていく様子がわかる。  \n",
        "- CNNの代表的なネットワークには、LeNetとAlexNetがある。  \n",
        "- ディープラーニングの発展に、ビッグデータとGPUが大きく貢献している。"
      ],
      "metadata": {
        "id": "qbSs0VoiWQ9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.1 全体の構造\n",
        "- 全結合５層  \n",
        "　入力 → Affine-ReLU → Affine-ReLU → Affine-ReLU → Affine-ReLU → Affine-Softmax → 出力  \n",
        "- CNNの例  \n",
        "　入力 → Conv-ReLU-Pooling → Conv-ReLU-Pooling → Conv-ReLU → Affine-ReLU → Affine-Softmax → 出力  "
      ],
      "metadata": {
        "id": "f8XVJDESYJ_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.2 畳み込み層\n",
        "## 7.2.1 全結合層の問題点\n",
        "- データの形状が無視されてしまう。  \n",
        "　画像データ：縦×横×チャネル方向の3次元形状  \n",
        "\n",
        "用語：入力データ、出力データ  \n",
        "　入力特徴マップ → Conv → 出力特徴マップ"
      ],
      "metadata": {
        "id": "uZ6lLEWjZO2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2.2 畳み込み演算\n",
        "用語：フィルター(重み)  \n",
        "　カーネル  \n",
        "\n",
        "p.209の例は、パディングなし、ストライド1  \n",
        "\n",
        "入力データ [積和] フィルター(重み) → 中間出力＋バイアス → 出力データ  \n",
        "\n",
        "フィルター適用後のデータに対して１つ（１×１）のバイアスをすべての要素に加算する。"
      ],
      "metadata": {
        "id": "VrrdFYgjaNuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2.3 パディング\n",
        "(4,4)の入力データ [積和] (3,3)のフィルター → (2,2)の出力データ  \n",
        "↑小さくなってしまい、層を重ねるとどんどん小さくなっていく。  \n",
        "\n",
        "(4,4)の入力データ → 幅1のパディング → (6,6)の入力データ  \n",
        "(6,6)の入力データ [積和] (3,3)のフィルター → (4,4)の出力データ  "
      ],
      "metadata": {
        "id": "yxnAKKOXcRfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2.4 ストライド\n",
        "フィルターを適用する位置の間隔。  \n",
        "(7,7)の入力データ → ストライド2 → (3,3)の出力データ  \n",
        "\n",
        "$OH=\\frac{H+2P-FH}{S}+1$  \n",
        "\n",
        "$OW=\\frac{W+2P-FW}{S}+1$  \n",
        "\n",
        "入力サイズ：$(H,W)$  \n",
        "フィルターサイズ：$(FH,FW)$  \n",
        "出力サイズ：$(OH,OW)$  \n",
        "パディング：$P$  \n",
        "ストライド：$S$  \n",
        "\n",
        "$S$で割り切れるように設定すること。（ストライドを2以上にするなら）"
      ],
      "metadata": {
        "id": "S_1pr0Roefon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2.5 3次元データの畳み込み演算\n",
        "チャンネルごとに入力データとフィルターの畳み込み演算を行い、結果を加算してひとつの出力。  \n",
        "※出力のチャンネル数は1ということ。\n",
        "- 入力データとフィルターのチャンネル数は同じ値にする。  \n",
        "- フィルターのサイズは任意。ただし、チャンネルごとのフィルターのサイズはすべて同じ。  \n",
        "\n",
        "※この意味は？R,G,Bチャンネルがあったとして、フィルターのチャンネル数は3。R,G,Bのフィルターのサイズはすべて同じ（R,G,Bでサイズが違ってはいけない。サイズ自体は任意）。ということかな？7.2.6の式からみるとたぶんそう。"
      ],
      "metadata": {
        "id": "gFetdtikjVtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2.6 ブロックで考える\n",
        "入力データ(C,H,W) [積和] フィルター(C,FH,FW) → 出力データ(1,OH,OW)  \n",
        "\n",
        "疑問：  \n",
        "p.217 畳み込み演算の出力をチャンネル方向にも複数持たせるには複数のフィルターを用いる、とあるが、FN個のフィルターであってFC個ではない。「チャンネル方向」という意味がよくわからない。  \n",
        "\n",
        "複数のフィルターによる畳み込み演算の例：  \n",
        "入力データ(C,H,W) [積和] フィルター(FN,C,FH,FW) → 出力データ(FN,OH,OW)  \n",
        "\n",
        "バイアス項も追加すると結局以下：  \n",
        "入力データ(C,H,W) [積和] フィルター(FN,C,FH,FW) → 中間出力(FN,OH,OW)＋バイアス(FN,1,1) → 出力データ(FN,OH,OW)  \n",
        "※バイアスはFN個のチャンネルごとに1つ。"
      ],
      "metadata": {
        "id": "OCV_u-xjpaTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2.7 バッチ処理\n",
        "(batch_num, channel, height, width)の4次元で表現する。\n",
        "\n",
        "N個のデータに対してバッチ処理：  \n",
        "入力データ(N,C,H,W) [積和] フィルター(FN,C,FH,FW) → 中間出力(N,FN,OH,OW)＋バイアス(FN,1,1) → 出力データ(N,FN,OH,OW)  \n",
        "※N回分の処理を1回で行っている。"
      ],
      "metadata": {
        "id": "13Bm2e38JXiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.3 プーリング層\n",
        "縦・横方向の空間を小さくする演算。  \n",
        "一般的に、プーリングのウィンドウサイズとストライドは同じ値に設定する。\n",
        "\n",
        "Maxプーリングの他にAverageプーリングなどがあるが画像認識では主にMaxプーリングが使われる。"
      ],
      "metadata": {
        "id": "RhM4xzppKcE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3.1 プーリング層の特徴\n",
        "- 学習するパラメータがない。  \n",
        "- チャンネル数は変化しない。  \n",
        "- 微小な位置変化に対してロバスト（頑健）。  "
      ],
      "metadata": {
        "id": "ytxdx5dVLgOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.4 Convolution / Poolingレイヤの実装\n",
        "## 7.4.1 4次元配列\n"
      ],
      "metadata": {
        "id": "i-UM0HvBL2eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.random.rand(10, 1, 28, 28)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOm_bBduMTfq",
        "outputId": "cc935fb2-e0de-41a3-d650-9c68561a28f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9U04Ds8Mh5D",
        "outputId": "c3da5fa5-338c-42cd-a05b-58afe8d627b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZEC11KtMmMA",
        "outputId": "a4eb31e5-219e-42b7-93dd-4a368fc8124b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EgKoa3tMpQE",
        "outputId": "fdba3b37-f03e-44ce-b943-5d4bdc4e22fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.71412064, 0.13509261, 0.88070301, 0.56992325, 0.35064352,\n",
              "        0.36593439, 0.0781417 , 0.03726013, 0.42891319, 0.68147575,\n",
              "        0.3424712 , 0.20787797, 0.25711263, 0.39118542, 0.63286136,\n",
              "        0.81230085, 0.66671711, 0.09124888, 0.39965205, 0.53432956,\n",
              "        0.86027159, 0.40041664, 0.59320584, 0.81091043, 0.55510577,\n",
              "        0.58140506, 0.41930415, 0.18501125],\n",
              "       [0.04430769, 0.36680073, 0.52128287, 0.7157661 , 0.24828306,\n",
              "        0.80467658, 0.82375671, 0.02214566, 0.09077362, 0.79645532,\n",
              "        0.44659174, 0.88374228, 0.49291845, 0.32742891, 0.5127306 ,\n",
              "        0.98535722, 0.60468284, 0.25827405, 0.52896059, 0.45912675,\n",
              "        0.72763567, 0.59885562, 0.05063273, 0.31118886, 0.00927957,\n",
              "        0.08972246, 0.67256007, 0.65674929],\n",
              "       [0.34398422, 0.4812563 , 0.89688977, 0.98191953, 0.43209336,\n",
              "        0.18216453, 0.52950717, 0.24001336, 0.09834772, 0.94291951,\n",
              "        0.50158136, 0.19494433, 0.19796849, 0.08086533, 0.8879106 ,\n",
              "        0.57912239, 0.22245105, 0.14645229, 0.04863218, 0.31386594,\n",
              "        0.96232497, 0.51449085, 0.50990263, 0.14669941, 0.81527217,\n",
              "        0.0560191 , 0.94333294, 0.32179958],\n",
              "       [0.62926346, 0.83118422, 0.41037338, 0.4142398 , 0.00470714,\n",
              "        0.48461455, 0.51611674, 0.04639202, 0.09161249, 0.23552979,\n",
              "        0.44746854, 0.95021936, 0.84657624, 0.13424032, 0.6777811 ,\n",
              "        0.47803697, 0.107587  , 0.13990444, 0.66233536, 0.94941535,\n",
              "        0.27161609, 0.42549473, 0.45435941, 0.27232577, 0.19589945,\n",
              "        0.45355963, 0.30419008, 0.21725013],\n",
              "       [0.88071705, 0.32440365, 0.98589199, 0.33058379, 0.02154116,\n",
              "        0.40298689, 0.07147622, 0.98605161, 0.67592017, 0.84310637,\n",
              "        0.36928405, 0.4722424 , 0.6232032 , 0.92172779, 0.20002288,\n",
              "        0.8745728 , 0.24026592, 0.88475102, 0.75763234, 0.55999253,\n",
              "        0.49397469, 0.33362753, 0.27565697, 0.67767603, 0.55397375,\n",
              "        0.71187856, 0.31712925, 0.78271541],\n",
              "       [0.30891144, 0.17510356, 0.8474706 , 0.89179827, 0.3317025 ,\n",
              "        0.99691235, 0.05620304, 0.95721958, 0.73622507, 0.52395422,\n",
              "        0.48693254, 0.80937594, 0.68741712, 0.22116552, 0.6512089 ,\n",
              "        0.16352811, 0.92960246, 0.64751273, 0.86244286, 0.78890873,\n",
              "        0.52488268, 0.88734171, 0.32641822, 0.46518462, 0.97489403,\n",
              "        0.66974972, 0.16901174, 0.3205001 ],\n",
              "       [0.10812415, 0.51699453, 0.33558256, 0.04626765, 0.91003271,\n",
              "        0.35610469, 0.22072071, 0.5400419 , 0.87307985, 0.94595982,\n",
              "        0.15778389, 0.74195073, 0.78463364, 0.49041339, 0.01042543,\n",
              "        0.36445859, 0.12053437, 0.42502812, 0.27802108, 0.6879938 ,\n",
              "        0.44007238, 0.82991838, 0.21425925, 0.45539537, 0.58462702,\n",
              "        0.30165118, 0.84622141, 0.75246733],\n",
              "       [0.98774448, 0.45561164, 0.06685944, 0.58402791, 0.90478395,\n",
              "        0.45080462, 0.88597631, 0.70999092, 0.26859379, 0.94458774,\n",
              "        0.2453026 , 0.5560666 , 0.30423576, 0.21766314, 0.18713171,\n",
              "        0.85197928, 0.9140309 , 0.93914135, 0.23409407, 0.19041604,\n",
              "        0.89172782, 0.38136538, 0.37527649, 0.08827104, 0.00344104,\n",
              "        0.97946891, 0.20561958, 0.27342785],\n",
              "       [0.39686637, 0.41261703, 0.06061953, 0.48712563, 0.92327718,\n",
              "        0.89799222, 0.77671675, 0.94911608, 0.29845287, 0.90112565,\n",
              "        0.2112138 , 0.00799574, 0.90701667, 0.60589205, 0.72753694,\n",
              "        0.75733659, 0.92269733, 0.69496379, 0.32341808, 0.04783404,\n",
              "        0.19107421, 0.69066449, 0.38115137, 0.68131836, 0.23196523,\n",
              "        0.68193107, 0.92053427, 0.17093775],\n",
              "       [0.63025666, 0.1095801 , 0.9832291 , 0.45287558, 0.98021654,\n",
              "        0.01934573, 0.98647305, 0.86679123, 0.84572794, 0.84231311,\n",
              "        0.67060542, 0.10024013, 0.01558853, 0.57545345, 0.9612059 ,\n",
              "        0.14967499, 0.83943143, 0.53571494, 0.06714465, 0.59573217,\n",
              "        0.44453698, 0.77931734, 0.87022264, 0.85334377, 0.60535323,\n",
              "        0.50073068, 0.49235311, 0.73244964],\n",
              "       [0.35696649, 0.57185343, 0.08377762, 0.27112597, 0.59262756,\n",
              "        0.9918734 , 0.29468128, 0.49051313, 0.87004005, 0.72122546,\n",
              "        0.79200738, 0.01215775, 0.99398955, 0.31826471, 0.62040278,\n",
              "        0.75975314, 0.30395178, 0.31018332, 0.41291975, 0.89469683,\n",
              "        0.56643165, 0.97043835, 0.46511578, 0.17722599, 0.79203144,\n",
              "        0.19999364, 0.26999622, 0.66719192],\n",
              "       [0.71394061, 0.89154044, 0.69724233, 0.59971547, 0.65152594,\n",
              "        0.24092889, 0.34913735, 0.65966363, 0.4106164 , 0.07123983,\n",
              "        0.36216179, 0.34085637, 0.06407558, 0.78446419, 0.71865619,\n",
              "        0.45053703, 0.73778039, 0.49590882, 0.94322184, 0.08771034,\n",
              "        0.50127566, 0.36215548, 0.40195531, 0.17756372, 0.85463689,\n",
              "        0.27683085, 0.48006676, 0.72153474],\n",
              "       [0.35269686, 0.09214199, 0.01609457, 0.53966436, 0.82113963,\n",
              "        0.96282516, 0.57614485, 0.5837894 , 0.01517212, 0.46045658,\n",
              "        0.73084958, 0.64586934, 0.20804058, 0.70791499, 0.63821408,\n",
              "        0.66714362, 0.22449806, 0.11884504, 0.54386716, 0.23500222,\n",
              "        0.58980336, 0.03804485, 0.22089125, 0.67917289, 0.47680914,\n",
              "        0.39359778, 0.18947398, 0.44575224],\n",
              "       [0.98648417, 0.84792032, 0.173436  , 0.86708418, 0.0550542 ,\n",
              "        0.86403178, 0.27898721, 0.98378382, 0.55986971, 0.94277573,\n",
              "        0.20853376, 0.32506218, 0.89587044, 0.86857423, 0.89757311,\n",
              "        0.16512977, 0.1400151 , 0.18269806, 0.12067889, 0.2493833 ,\n",
              "        0.93826013, 0.08457736, 0.39035586, 0.885666  , 0.4876153 ,\n",
              "        0.51791133, 0.51339058, 0.93454946],\n",
              "       [0.44979283, 0.52424001, 0.19099974, 0.10700431, 0.61677715,\n",
              "        0.43187304, 0.13112964, 0.99169982, 0.19334013, 0.64254694,\n",
              "        0.67089353, 0.94432702, 0.12523474, 0.19861605, 0.84226135,\n",
              "        0.25310978, 0.67562361, 0.22875825, 0.79465811, 0.22230308,\n",
              "        0.3831914 , 0.54769437, 0.95541925, 0.03732168, 0.09056519,\n",
              "        0.31606697, 0.27070338, 0.991757  ],\n",
              "       [0.03394959, 0.39018113, 0.63140795, 0.77930622, 0.35465208,\n",
              "        0.10692173, 0.02745871, 0.09693751, 0.78836484, 0.26386944,\n",
              "        0.37692033, 0.89012902, 0.69659197, 0.42048576, 0.48529165,\n",
              "        0.27492559, 0.74526454, 0.50234617, 0.63991962, 0.50784773,\n",
              "        0.75747696, 0.81024076, 0.26852582, 0.79545664, 0.94156841,\n",
              "        0.90812766, 0.74523224, 0.43744623],\n",
              "       [0.71118516, 0.67723062, 0.76748087, 0.92008458, 0.87187733,\n",
              "        0.82117494, 0.63105211, 0.26452918, 0.79798562, 0.35160572,\n",
              "        0.59030059, 0.72564267, 0.80614333, 0.60678657, 0.77591687,\n",
              "        0.63674955, 0.31645003, 0.8604438 , 0.48105557, 0.95471638,\n",
              "        0.71122156, 0.60147016, 0.12071393, 0.84511409, 0.82451781,\n",
              "        0.69058529, 0.51349255, 0.62332179],\n",
              "       [0.28180457, 0.81415699, 0.13565567, 0.72289074, 0.74166727,\n",
              "        0.98921259, 0.65776037, 0.89668954, 0.11173959, 0.19851364,\n",
              "        0.88655704, 0.4869047 , 0.5087944 , 0.42776474, 0.78154187,\n",
              "        0.26047736, 0.93794491, 0.67609837, 0.95335491, 0.44916384,\n",
              "        0.29257705, 0.74187521, 0.25839665, 0.26210694, 0.63111429,\n",
              "        0.22295534, 0.36026467, 0.2217651 ],\n",
              "       [0.09446301, 0.31074266, 0.33909467, 0.29152183, 0.88457457,\n",
              "        0.75400963, 0.99745482, 0.19346941, 0.08336174, 0.32040966,\n",
              "        0.65877375, 0.86754429, 0.79581025, 0.2852382 , 0.38956101,\n",
              "        0.03355058, 0.31104918, 0.5415716 , 0.92441004, 0.61029467,\n",
              "        0.6788873 , 0.18786112, 0.74660769, 0.54945279, 0.72261904,\n",
              "        0.92989696, 0.83479813, 0.27474229],\n",
              "       [0.35840034, 0.04535614, 0.11325249, 0.47170013, 0.51125492,\n",
              "        0.03774356, 0.09375427, 0.01013923, 0.99416089, 0.64931243,\n",
              "        0.10383297, 0.03136509, 0.30198895, 0.99431831, 0.86826214,\n",
              "        0.96742329, 0.57369129, 0.63118084, 0.3662133 , 0.59429363,\n",
              "        0.13062859, 0.66964144, 0.18835263, 0.38199296, 0.60632952,\n",
              "        0.05519537, 0.91232492, 0.52816837],\n",
              "       [0.65546491, 0.18533466, 0.82703487, 0.82855559, 0.96558403,\n",
              "        0.13063134, 0.98821405, 0.36941546, 0.06876445, 0.17293468,\n",
              "        0.93373787, 0.5457427 , 0.81308855, 0.025015  , 0.78835719,\n",
              "        0.50104823, 0.51705459, 0.36416036, 0.19207622, 0.7783577 ,\n",
              "        0.83136411, 0.68530036, 0.15054354, 0.50800031, 0.00230504,\n",
              "        0.05614941, 0.17957274, 0.29440645],\n",
              "       [0.62432544, 0.28735223, 0.14879491, 0.07422304, 0.97258997,\n",
              "        0.99615288, 0.3326574 , 0.76630793, 0.82624463, 0.82363682,\n",
              "        0.02871938, 0.36262477, 0.63841871, 0.53443262, 0.0243533 ,\n",
              "        0.09641297, 0.11039024, 0.81311733, 0.78512917, 0.23963064,\n",
              "        0.70643203, 0.88985813, 0.01161964, 0.09063376, 0.36084764,\n",
              "        0.365656  , 0.5704434 , 0.39965827],\n",
              "       [0.27549792, 0.25363025, 0.11079665, 0.43398626, 0.15414812,\n",
              "        0.90888398, 0.52274937, 0.11268019, 0.00747268, 0.18349895,\n",
              "        0.97328736, 0.93325031, 0.88516019, 0.52012957, 0.76197238,\n",
              "        0.64879747, 0.95125093, 0.11727632, 0.76005043, 0.61703325,\n",
              "        0.27495303, 0.94694504, 0.93174849, 0.19700198, 0.14065236,\n",
              "        0.10238357, 0.46896928, 0.96950606],\n",
              "       [0.33153789, 0.43916012, 0.78378279, 0.35929688, 0.01524469,\n",
              "        0.40830071, 0.40941011, 0.30284926, 0.10200267, 0.02947457,\n",
              "        0.82938854, 0.19129092, 0.67623671, 0.45882779, 0.05487494,\n",
              "        0.7925251 , 0.77026874, 0.34356602, 0.68222835, 0.61071428,\n",
              "        0.76707996, 0.72221099, 0.32168847, 0.85233365, 0.28245314,\n",
              "        0.97859664, 0.25398901, 0.96469332],\n",
              "       [0.33703355, 0.79886731, 0.59418282, 0.53105151, 0.0070092 ,\n",
              "        0.03306906, 0.8892862 , 0.70717305, 0.62999238, 0.3822854 ,\n",
              "        0.00445894, 0.95955197, 0.77299723, 0.66574888, 0.61990412,\n",
              "        0.35448535, 0.44036417, 0.07086851, 0.4224752 , 0.52292188,\n",
              "        0.60566323, 0.10297242, 0.38879611, 0.61272638, 0.14875264,\n",
              "        0.33001068, 0.48079983, 0.68152992],\n",
              "       [0.49265111, 0.77532973, 0.79214951, 0.79005235, 0.80354316,\n",
              "        0.98776846, 0.40260152, 0.59929955, 0.44399087, 0.13042497,\n",
              "        0.93570002, 0.40719186, 0.12853613, 0.7907015 , 0.40178826,\n",
              "        0.92658051, 0.07926739, 0.46572623, 0.12412659, 0.31075784,\n",
              "        0.87968687, 0.34914774, 0.99294136, 0.49826022, 0.52944453,\n",
              "        0.6403941 , 0.6397285 , 0.27383313],\n",
              "       [0.59489375, 0.32798306, 0.29499535, 0.44889757, 0.13936005,\n",
              "        0.60983716, 0.02892854, 0.63204321, 0.99004859, 0.08200489,\n",
              "        0.76518682, 0.32168984, 0.32262862, 0.20730697, 0.02225066,\n",
              "        0.76016593, 0.41322289, 0.46887398, 0.92838036, 0.32757787,\n",
              "        0.47021288, 0.3124885 , 0.73769473, 0.44845816, 0.50935434,\n",
              "        0.99471528, 0.95984392, 0.16037249],\n",
              "       [0.89046881, 0.59535717, 0.23609272, 0.11329458, 0.20051655,\n",
              "        0.66580539, 0.53240451, 0.34568466, 0.48716617, 0.91710373,\n",
              "        0.28639334, 0.09785314, 0.29128321, 0.25552888, 0.77646188,\n",
              "        0.43904442, 0.97093706, 0.95511805, 0.05801667, 0.87704195,\n",
              "        0.60679782, 0.91483546, 0.36601585, 0.10229927, 0.47437998,\n",
              "        0.5653844 , 0.63399281, 0.25888727]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPewvqkwMvMf",
        "outputId": "092b322f-507b-406a-d70c-5a55ed69d82d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.71412064, 0.13509261, 0.88070301, 0.56992325, 0.35064352,\n",
              "        0.36593439, 0.0781417 , 0.03726013, 0.42891319, 0.68147575,\n",
              "        0.3424712 , 0.20787797, 0.25711263, 0.39118542, 0.63286136,\n",
              "        0.81230085, 0.66671711, 0.09124888, 0.39965205, 0.53432956,\n",
              "        0.86027159, 0.40041664, 0.59320584, 0.81091043, 0.55510577,\n",
              "        0.58140506, 0.41930415, 0.18501125],\n",
              "       [0.04430769, 0.36680073, 0.52128287, 0.7157661 , 0.24828306,\n",
              "        0.80467658, 0.82375671, 0.02214566, 0.09077362, 0.79645532,\n",
              "        0.44659174, 0.88374228, 0.49291845, 0.32742891, 0.5127306 ,\n",
              "        0.98535722, 0.60468284, 0.25827405, 0.52896059, 0.45912675,\n",
              "        0.72763567, 0.59885562, 0.05063273, 0.31118886, 0.00927957,\n",
              "        0.08972246, 0.67256007, 0.65674929],\n",
              "       [0.34398422, 0.4812563 , 0.89688977, 0.98191953, 0.43209336,\n",
              "        0.18216453, 0.52950717, 0.24001336, 0.09834772, 0.94291951,\n",
              "        0.50158136, 0.19494433, 0.19796849, 0.08086533, 0.8879106 ,\n",
              "        0.57912239, 0.22245105, 0.14645229, 0.04863218, 0.31386594,\n",
              "        0.96232497, 0.51449085, 0.50990263, 0.14669941, 0.81527217,\n",
              "        0.0560191 , 0.94333294, 0.32179958],\n",
              "       [0.62926346, 0.83118422, 0.41037338, 0.4142398 , 0.00470714,\n",
              "        0.48461455, 0.51611674, 0.04639202, 0.09161249, 0.23552979,\n",
              "        0.44746854, 0.95021936, 0.84657624, 0.13424032, 0.6777811 ,\n",
              "        0.47803697, 0.107587  , 0.13990444, 0.66233536, 0.94941535,\n",
              "        0.27161609, 0.42549473, 0.45435941, 0.27232577, 0.19589945,\n",
              "        0.45355963, 0.30419008, 0.21725013],\n",
              "       [0.88071705, 0.32440365, 0.98589199, 0.33058379, 0.02154116,\n",
              "        0.40298689, 0.07147622, 0.98605161, 0.67592017, 0.84310637,\n",
              "        0.36928405, 0.4722424 , 0.6232032 , 0.92172779, 0.20002288,\n",
              "        0.8745728 , 0.24026592, 0.88475102, 0.75763234, 0.55999253,\n",
              "        0.49397469, 0.33362753, 0.27565697, 0.67767603, 0.55397375,\n",
              "        0.71187856, 0.31712925, 0.78271541],\n",
              "       [0.30891144, 0.17510356, 0.8474706 , 0.89179827, 0.3317025 ,\n",
              "        0.99691235, 0.05620304, 0.95721958, 0.73622507, 0.52395422,\n",
              "        0.48693254, 0.80937594, 0.68741712, 0.22116552, 0.6512089 ,\n",
              "        0.16352811, 0.92960246, 0.64751273, 0.86244286, 0.78890873,\n",
              "        0.52488268, 0.88734171, 0.32641822, 0.46518462, 0.97489403,\n",
              "        0.66974972, 0.16901174, 0.3205001 ],\n",
              "       [0.10812415, 0.51699453, 0.33558256, 0.04626765, 0.91003271,\n",
              "        0.35610469, 0.22072071, 0.5400419 , 0.87307985, 0.94595982,\n",
              "        0.15778389, 0.74195073, 0.78463364, 0.49041339, 0.01042543,\n",
              "        0.36445859, 0.12053437, 0.42502812, 0.27802108, 0.6879938 ,\n",
              "        0.44007238, 0.82991838, 0.21425925, 0.45539537, 0.58462702,\n",
              "        0.30165118, 0.84622141, 0.75246733],\n",
              "       [0.98774448, 0.45561164, 0.06685944, 0.58402791, 0.90478395,\n",
              "        0.45080462, 0.88597631, 0.70999092, 0.26859379, 0.94458774,\n",
              "        0.2453026 , 0.5560666 , 0.30423576, 0.21766314, 0.18713171,\n",
              "        0.85197928, 0.9140309 , 0.93914135, 0.23409407, 0.19041604,\n",
              "        0.89172782, 0.38136538, 0.37527649, 0.08827104, 0.00344104,\n",
              "        0.97946891, 0.20561958, 0.27342785],\n",
              "       [0.39686637, 0.41261703, 0.06061953, 0.48712563, 0.92327718,\n",
              "        0.89799222, 0.77671675, 0.94911608, 0.29845287, 0.90112565,\n",
              "        0.2112138 , 0.00799574, 0.90701667, 0.60589205, 0.72753694,\n",
              "        0.75733659, 0.92269733, 0.69496379, 0.32341808, 0.04783404,\n",
              "        0.19107421, 0.69066449, 0.38115137, 0.68131836, 0.23196523,\n",
              "        0.68193107, 0.92053427, 0.17093775],\n",
              "       [0.63025666, 0.1095801 , 0.9832291 , 0.45287558, 0.98021654,\n",
              "        0.01934573, 0.98647305, 0.86679123, 0.84572794, 0.84231311,\n",
              "        0.67060542, 0.10024013, 0.01558853, 0.57545345, 0.9612059 ,\n",
              "        0.14967499, 0.83943143, 0.53571494, 0.06714465, 0.59573217,\n",
              "        0.44453698, 0.77931734, 0.87022264, 0.85334377, 0.60535323,\n",
              "        0.50073068, 0.49235311, 0.73244964],\n",
              "       [0.35696649, 0.57185343, 0.08377762, 0.27112597, 0.59262756,\n",
              "        0.9918734 , 0.29468128, 0.49051313, 0.87004005, 0.72122546,\n",
              "        0.79200738, 0.01215775, 0.99398955, 0.31826471, 0.62040278,\n",
              "        0.75975314, 0.30395178, 0.31018332, 0.41291975, 0.89469683,\n",
              "        0.56643165, 0.97043835, 0.46511578, 0.17722599, 0.79203144,\n",
              "        0.19999364, 0.26999622, 0.66719192],\n",
              "       [0.71394061, 0.89154044, 0.69724233, 0.59971547, 0.65152594,\n",
              "        0.24092889, 0.34913735, 0.65966363, 0.4106164 , 0.07123983,\n",
              "        0.36216179, 0.34085637, 0.06407558, 0.78446419, 0.71865619,\n",
              "        0.45053703, 0.73778039, 0.49590882, 0.94322184, 0.08771034,\n",
              "        0.50127566, 0.36215548, 0.40195531, 0.17756372, 0.85463689,\n",
              "        0.27683085, 0.48006676, 0.72153474],\n",
              "       [0.35269686, 0.09214199, 0.01609457, 0.53966436, 0.82113963,\n",
              "        0.96282516, 0.57614485, 0.5837894 , 0.01517212, 0.46045658,\n",
              "        0.73084958, 0.64586934, 0.20804058, 0.70791499, 0.63821408,\n",
              "        0.66714362, 0.22449806, 0.11884504, 0.54386716, 0.23500222,\n",
              "        0.58980336, 0.03804485, 0.22089125, 0.67917289, 0.47680914,\n",
              "        0.39359778, 0.18947398, 0.44575224],\n",
              "       [0.98648417, 0.84792032, 0.173436  , 0.86708418, 0.0550542 ,\n",
              "        0.86403178, 0.27898721, 0.98378382, 0.55986971, 0.94277573,\n",
              "        0.20853376, 0.32506218, 0.89587044, 0.86857423, 0.89757311,\n",
              "        0.16512977, 0.1400151 , 0.18269806, 0.12067889, 0.2493833 ,\n",
              "        0.93826013, 0.08457736, 0.39035586, 0.885666  , 0.4876153 ,\n",
              "        0.51791133, 0.51339058, 0.93454946],\n",
              "       [0.44979283, 0.52424001, 0.19099974, 0.10700431, 0.61677715,\n",
              "        0.43187304, 0.13112964, 0.99169982, 0.19334013, 0.64254694,\n",
              "        0.67089353, 0.94432702, 0.12523474, 0.19861605, 0.84226135,\n",
              "        0.25310978, 0.67562361, 0.22875825, 0.79465811, 0.22230308,\n",
              "        0.3831914 , 0.54769437, 0.95541925, 0.03732168, 0.09056519,\n",
              "        0.31606697, 0.27070338, 0.991757  ],\n",
              "       [0.03394959, 0.39018113, 0.63140795, 0.77930622, 0.35465208,\n",
              "        0.10692173, 0.02745871, 0.09693751, 0.78836484, 0.26386944,\n",
              "        0.37692033, 0.89012902, 0.69659197, 0.42048576, 0.48529165,\n",
              "        0.27492559, 0.74526454, 0.50234617, 0.63991962, 0.50784773,\n",
              "        0.75747696, 0.81024076, 0.26852582, 0.79545664, 0.94156841,\n",
              "        0.90812766, 0.74523224, 0.43744623],\n",
              "       [0.71118516, 0.67723062, 0.76748087, 0.92008458, 0.87187733,\n",
              "        0.82117494, 0.63105211, 0.26452918, 0.79798562, 0.35160572,\n",
              "        0.59030059, 0.72564267, 0.80614333, 0.60678657, 0.77591687,\n",
              "        0.63674955, 0.31645003, 0.8604438 , 0.48105557, 0.95471638,\n",
              "        0.71122156, 0.60147016, 0.12071393, 0.84511409, 0.82451781,\n",
              "        0.69058529, 0.51349255, 0.62332179],\n",
              "       [0.28180457, 0.81415699, 0.13565567, 0.72289074, 0.74166727,\n",
              "        0.98921259, 0.65776037, 0.89668954, 0.11173959, 0.19851364,\n",
              "        0.88655704, 0.4869047 , 0.5087944 , 0.42776474, 0.78154187,\n",
              "        0.26047736, 0.93794491, 0.67609837, 0.95335491, 0.44916384,\n",
              "        0.29257705, 0.74187521, 0.25839665, 0.26210694, 0.63111429,\n",
              "        0.22295534, 0.36026467, 0.2217651 ],\n",
              "       [0.09446301, 0.31074266, 0.33909467, 0.29152183, 0.88457457,\n",
              "        0.75400963, 0.99745482, 0.19346941, 0.08336174, 0.32040966,\n",
              "        0.65877375, 0.86754429, 0.79581025, 0.2852382 , 0.38956101,\n",
              "        0.03355058, 0.31104918, 0.5415716 , 0.92441004, 0.61029467,\n",
              "        0.6788873 , 0.18786112, 0.74660769, 0.54945279, 0.72261904,\n",
              "        0.92989696, 0.83479813, 0.27474229],\n",
              "       [0.35840034, 0.04535614, 0.11325249, 0.47170013, 0.51125492,\n",
              "        0.03774356, 0.09375427, 0.01013923, 0.99416089, 0.64931243,\n",
              "        0.10383297, 0.03136509, 0.30198895, 0.99431831, 0.86826214,\n",
              "        0.96742329, 0.57369129, 0.63118084, 0.3662133 , 0.59429363,\n",
              "        0.13062859, 0.66964144, 0.18835263, 0.38199296, 0.60632952,\n",
              "        0.05519537, 0.91232492, 0.52816837],\n",
              "       [0.65546491, 0.18533466, 0.82703487, 0.82855559, 0.96558403,\n",
              "        0.13063134, 0.98821405, 0.36941546, 0.06876445, 0.17293468,\n",
              "        0.93373787, 0.5457427 , 0.81308855, 0.025015  , 0.78835719,\n",
              "        0.50104823, 0.51705459, 0.36416036, 0.19207622, 0.7783577 ,\n",
              "        0.83136411, 0.68530036, 0.15054354, 0.50800031, 0.00230504,\n",
              "        0.05614941, 0.17957274, 0.29440645],\n",
              "       [0.62432544, 0.28735223, 0.14879491, 0.07422304, 0.97258997,\n",
              "        0.99615288, 0.3326574 , 0.76630793, 0.82624463, 0.82363682,\n",
              "        0.02871938, 0.36262477, 0.63841871, 0.53443262, 0.0243533 ,\n",
              "        0.09641297, 0.11039024, 0.81311733, 0.78512917, 0.23963064,\n",
              "        0.70643203, 0.88985813, 0.01161964, 0.09063376, 0.36084764,\n",
              "        0.365656  , 0.5704434 , 0.39965827],\n",
              "       [0.27549792, 0.25363025, 0.11079665, 0.43398626, 0.15414812,\n",
              "        0.90888398, 0.52274937, 0.11268019, 0.00747268, 0.18349895,\n",
              "        0.97328736, 0.93325031, 0.88516019, 0.52012957, 0.76197238,\n",
              "        0.64879747, 0.95125093, 0.11727632, 0.76005043, 0.61703325,\n",
              "        0.27495303, 0.94694504, 0.93174849, 0.19700198, 0.14065236,\n",
              "        0.10238357, 0.46896928, 0.96950606],\n",
              "       [0.33153789, 0.43916012, 0.78378279, 0.35929688, 0.01524469,\n",
              "        0.40830071, 0.40941011, 0.30284926, 0.10200267, 0.02947457,\n",
              "        0.82938854, 0.19129092, 0.67623671, 0.45882779, 0.05487494,\n",
              "        0.7925251 , 0.77026874, 0.34356602, 0.68222835, 0.61071428,\n",
              "        0.76707996, 0.72221099, 0.32168847, 0.85233365, 0.28245314,\n",
              "        0.97859664, 0.25398901, 0.96469332],\n",
              "       [0.33703355, 0.79886731, 0.59418282, 0.53105151, 0.0070092 ,\n",
              "        0.03306906, 0.8892862 , 0.70717305, 0.62999238, 0.3822854 ,\n",
              "        0.00445894, 0.95955197, 0.77299723, 0.66574888, 0.61990412,\n",
              "        0.35448535, 0.44036417, 0.07086851, 0.4224752 , 0.52292188,\n",
              "        0.60566323, 0.10297242, 0.38879611, 0.61272638, 0.14875264,\n",
              "        0.33001068, 0.48079983, 0.68152992],\n",
              "       [0.49265111, 0.77532973, 0.79214951, 0.79005235, 0.80354316,\n",
              "        0.98776846, 0.40260152, 0.59929955, 0.44399087, 0.13042497,\n",
              "        0.93570002, 0.40719186, 0.12853613, 0.7907015 , 0.40178826,\n",
              "        0.92658051, 0.07926739, 0.46572623, 0.12412659, 0.31075784,\n",
              "        0.87968687, 0.34914774, 0.99294136, 0.49826022, 0.52944453,\n",
              "        0.6403941 , 0.6397285 , 0.27383313],\n",
              "       [0.59489375, 0.32798306, 0.29499535, 0.44889757, 0.13936005,\n",
              "        0.60983716, 0.02892854, 0.63204321, 0.99004859, 0.08200489,\n",
              "        0.76518682, 0.32168984, 0.32262862, 0.20730697, 0.02225066,\n",
              "        0.76016593, 0.41322289, 0.46887398, 0.92838036, 0.32757787,\n",
              "        0.47021288, 0.3124885 , 0.73769473, 0.44845816, 0.50935434,\n",
              "        0.99471528, 0.95984392, 0.16037249],\n",
              "       [0.89046881, 0.59535717, 0.23609272, 0.11329458, 0.20051655,\n",
              "        0.66580539, 0.53240451, 0.34568466, 0.48716617, 0.91710373,\n",
              "        0.28639334, 0.09785314, 0.29128321, 0.25552888, 0.77646188,\n",
              "        0.43904442, 0.97093706, 0.95511805, 0.05801667, 0.87704195,\n",
              "        0.60679782, 0.91483546, 0.36601585, 0.10229927, 0.47437998,\n",
              "        0.5653844 , 0.63399281, 0.25888727]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4.2 im2colによる展開\n",
        "im2col : image to column のこと。  \n",
        "\n",
        "4次元を2次元に展開する。  \n",
        "横方向に1列。（各ストライドごとに1行のイメージ。）\n",
        "\n",
        "展開後：  \n",
        "- 畳み込み層のフィルターを1列(縦方向)に展開する。  \n",
        "- im2colした各行と↑のフィルターの各列で行列演算を行う。  \n",
        "- 2次元の出力データが得られるのでreshapeして出力データを整形する。"
      ],
      "metadata": {
        "id": "yd8XZlY0Na3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4.3 Convolutionレイヤの実装\n",
        "im2col(input_data, filterNh, filter_w, stride=1, pad=0)  \n",
        "- input_data：(データ数, チャンネル, 高さ, 横幅)の4次元配列からなる入力データ。  \n",
        "- filter_h：フィルターの高さ。  \n",
        "- filter_w：フィルターの横幅。  \n",
        "- stride：ストライド  \n",
        "- pad：パディング  \n"
      ],
      "metadata": {
        "id": "yCA0_P4ySkyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ■追記（岡田）Colaboratory用\n",
        "Google Colaboratoryの場合、Google Driveに  \n",
        "dl-from-scratch/ch07  \n",
        "というフォルダを用意し、そこにこのjupyter notebookを配置。  \n",
        "(dl-from-scratchの部分は任意。)  \n",
        "また、datasetフォルダとcommonフォルダを\n",
        "dl-from-scratch/dataset  \n",
        "dl-from-scratch/common\n",
        "にコピーしておく。  \n",
        "\n",
        "以下のセルでGoogle Driveをマウント。許可を求められるので許可する。"
      ],
      "metadata": {
        "id": "FCybl7DeJdTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "afijDOELJlOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c02da71-ea7e-47d7-d651-1af7dd17ca14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ■追記（岡田）Colaboratory用\n",
        "chdirする。"
      ],
      "metadata": {
        "id": "bIQogTBWJtqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys,os\n",
        "os.chdir('/content/drive/My Drive/dl-from-scratch/ch07')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "BXapxM9-J0EV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31bbac7f-4ded-447f-8193-f851f86e2e5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/dl-from-scratch/ch07'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "from common.util import im2col\n",
        "\n",
        "x1 = np.random.rand(1,3,7,7)\n",
        "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
        "print(col1.shape)\n",
        "\n",
        "x2 = np.random.rand(10,3,7,7)\n",
        "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
        "print(col2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJUK6T9tTrq8",
        "outputId": "34f1767e-b342-410c-a7ea-531f4b037c7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 75)\n",
            "(90, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "★？？？★  \n",
        "ここよくわからない。  \n",
        "75は、3(CH)×5(FH)×5(FW)なのはわかる。  \n",
        "9はどこからでてきた？  \n",
        "H=7, W=7, FH=5, FW=5, S=1, pad=0なので、OH=OW=3なので、OH×OW=9、ということ？？  \n",
        "\n",
        "↓読んだけど、、、、うーん？？  \n",
        "im2colに慣れるための最初の一歩　～何をしているの？～  \n",
        "https://aihack.aijobcolle.com/u/lukapla/ct2p5cc6ik2rdr  \n",
        "\n",
        "7.4.1-2：im2colの実装【ゼロつく1のノート(実装)】  \n",
        "https://www.anarchive-beta.com/entry/2020/08/23/180000\n",
        "\n",
        "★★いったん詳細は保留する。★★\n",
        "\n",
        "class Convolutionは、common/layers.pyにある。"
      ],
      "metadata": {
        "id": "hafw3sQrYz1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4.4 Poolingレイヤの実装\n",
        "p.228の図7-21は、4×4の入力データに、2×2のMaxプーリングをストライド2で実施する例。  \n",
        "Maxを求めたいブロックを1行になるようにim2colで展開してnp.maxで行の最大値をとるだけ。  \n"
      ],
      "metadata": {
        "id": "IoXSv4QrN1Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.5 CNNの実装\n",
        "- SimpleConvNet  \n",
        "　入力 → Conv-ReLU-Pooling → Affine-ReLU → Affine-Softmax → 出力  "
      ],
      "metadata": {
        "id": "je9u3wtfSnUc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z3K198DPs_8"
      },
      "source": [
        "# ch07/simple_convnet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6h4TmgvcPs__"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from common.layers import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "\n",
        "class SimpleConvNet:\n",
        "    \"\"\"単純なConvNet\n",
        "\n",
        "    conv - relu - pool - affine - relu - affine - softmax\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    input_size : 入力サイズ（MNISTの場合は784）\n",
        "    hidden_size_list : 隠れ層のニューロンの数のリスト（e.g. [100, 100, 100]）\n",
        "    output_size : 出力サイズ（MNISTの場合は10）\n",
        "    activation : 'relu' or 'sigmoid'\n",
        "    weight_init_std : 重みの標準偏差を指定（e.g. 0.01）\n",
        "        'relu'または'he'を指定した場合は「Heの初期値」を設定\n",
        "        'sigmoid'または'xavier'を指定した場合は「Xavierの初期値」を設定\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=(1, 28, 28), \n",
        "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
        "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
        "        filter_num = conv_param['filter_num']\n",
        "        filter_size = conv_param['filter_size']\n",
        "        filter_pad = conv_param['pad']\n",
        "        filter_stride = conv_param['stride']\n",
        "        input_size = input_dim[1]\n",
        "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
        "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
        "\n",
        "        # 重みの初期化\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * \\\n",
        "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
        "        self.params['b1'] = np.zeros(filter_num)\n",
        "        self.params['W2'] = weight_init_std * \\\n",
        "                            np.random.randn(pool_output_size, hidden_size)\n",
        "        self.params['b2'] = np.zeros(hidden_size)\n",
        "        self.params['W3'] = weight_init_std * \\\n",
        "                            np.random.randn(hidden_size, output_size)\n",
        "        self.params['b3'] = np.zeros(output_size)\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
        "                                           conv_param['stride'], conv_param['pad'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
        "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
        "        self.layers['Relu2'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
        "\n",
        "        self.last_layer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        \"\"\"損失関数を求める\n",
        "        引数のxは入力データ、tは教師ラベル\n",
        "        \"\"\"\n",
        "        y = self.predict(x)\n",
        "        return self.last_layer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t, batch_size=100):\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "        \n",
        "        acc = 0.0\n",
        "        \n",
        "        for i in range(int(x.shape[0] / batch_size)):\n",
        "            tx = x[i*batch_size:(i+1)*batch_size]\n",
        "            tt = t[i*batch_size:(i+1)*batch_size]\n",
        "            y = self.predict(tx)\n",
        "            y = np.argmax(y, axis=1)\n",
        "            acc += np.sum(y == tt) \n",
        "        \n",
        "        return acc / x.shape[0]\n",
        "\n",
        "    def numerical_gradient(self, x, t):\n",
        "        \"\"\"勾配を求める（数値微分）\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 入力データ\n",
        "        t : 教師ラベル\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        各層の勾配を持ったディクショナリ変数\n",
        "            grads['W1']、grads['W2']、...は各層の重み\n",
        "            grads['b1']、grads['b2']、...は各層のバイアス\n",
        "        \"\"\"\n",
        "        loss_w = lambda w: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        for idx in (1, 2, 3):\n",
        "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
        "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        \"\"\"勾配を求める（誤差逆伝搬法）\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 入力データ\n",
        "        t : 教師ラベル\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        各層の勾配を持ったディクショナリ変数\n",
        "            grads['W1']、grads['W2']、...は各層の重み\n",
        "            grads['b1']、grads['b2']、...は各層のバイアス\n",
        "        \"\"\"\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 設定\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads\n",
        "        \n",
        "    def save_params(self, file_name=\"params.pkl\"):\n",
        "        params = {}\n",
        "        for key, val in self.params.items():\n",
        "            params[key] = val\n",
        "        with open(file_name, 'wb') as f:\n",
        "            pickle.dump(params, f)\n",
        "\n",
        "    def load_params(self, file_name=\"params.pkl\"):\n",
        "        with open(file_name, 'rb') as f:\n",
        "            params = pickle.load(f)\n",
        "        for key, val in params.items():\n",
        "            self.params[key] = val\n",
        "\n",
        "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
        "            self.layers[key].W = self.params['W' + str(i+1)]\n",
        "            self.layers[key].b = self.params['b' + str(i+1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMG_C-taPtAB"
      },
      "source": [
        "# ch07/gradient_check.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xz797tpvPtAC",
        "outputId": "a37ccd8f-c371-4e2a-cec2-394d3f0a8fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 2.0644789112570126e-10\n",
            "b1 3.6484593719397686e-10\n",
            "W2 5.408784320457862e-11\n",
            "b2 0.00028426338386853563\n",
            "W3 3.775743224111263e-10\n",
            "b3 1.7989346901142734e-07\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "network = SimpleConvNet(input_dim=(1,10, 10), \n",
        "                        conv_param = {'filter_num':10, 'filter_size':3, 'pad':0, 'stride':1},\n",
        "                        hidden_size=10, output_size=10, weight_init_std=0.01)\n",
        "\n",
        "X = np.random.rand(100).reshape((1, 1, 10, 10))\n",
        "T = np.array([1]).reshape((1,1))\n",
        "\n",
        "grad_num = network.numerical_gradient(X, T)\n",
        "grad = network.gradient(X, T)\n",
        "\n",
        "for key, val in grad_num.items():\n",
        "    print(key, np.abs(grad_num[key] - grad[key]).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II7h0ibzPtAD"
      },
      "source": [
        "# ch07/train_convnet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "↓実行時間がかなりかかるので注意。"
      ],
      "metadata": {
        "id": "QvguT88dd3pj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZBjO7gtCPtAD",
        "outputId": "cb081a98-38ca-43d2-a155-4006ffa5e970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "train loss:0.0037612765640775425\n",
            "train loss:0.006746911242468889\n",
            "train loss:0.0013883427328885778\n",
            "train loss:0.0013928339138518438\n",
            "train loss:0.0010340436784107242\n",
            "train loss:0.009505522974810741\n",
            "train loss:0.0005315124782325794\n",
            "train loss:0.006794014438698923\n",
            "train loss:0.01586195071081634\n",
            "train loss:0.0006334181938564128\n",
            "train loss:0.0018237072612314032\n",
            "train loss:0.001999724486769207\n",
            "train loss:0.0002633985154324525\n",
            "train loss:0.0032881942056281767\n",
            "train loss:0.018445277442150954\n",
            "train loss:0.008843006869686464\n",
            "train loss:0.007086956579464744\n",
            "train loss:0.000604181148209055\n",
            "train loss:0.015397024012363423\n",
            "train loss:0.004928752892719937\n",
            "train loss:0.0009719689059962778\n",
            "train loss:5.759033086925582e-05\n",
            "train loss:0.014398503061781358\n",
            "train loss:0.0027178904967803037\n",
            "train loss:0.004731622878997716\n",
            "train loss:0.008850924048642133\n",
            "train loss:0.0004615902743441415\n",
            "train loss:0.0017230219079879638\n",
            "train loss:0.00193975912261261\n",
            "train loss:0.005943349463342324\n",
            "train loss:0.0018587467826914209\n",
            "train loss:0.0012286793284354029\n",
            "train loss:0.005160142970239805\n",
            "train loss:0.0032995416472503063\n",
            "train loss:0.005626786678271265\n",
            "train loss:0.0018566955792996625\n",
            "train loss:0.0017292423897422367\n",
            "train loss:0.09742904977976945\n",
            "train loss:0.003169361016680522\n",
            "train loss:0.0009403926978577426\n",
            "train loss:0.005432194660975957\n",
            "train loss:0.003918979787358473\n",
            "train loss:0.010996081065673673\n",
            "train loss:0.003068171163434213\n",
            "train loss:0.008712163341521051\n",
            "train loss:0.0002171683387868689\n",
            "train loss:0.0031291525602714625\n",
            "train loss:0.010418119225196651\n",
            "train loss:0.022530824850182953\n",
            "train loss:0.008647048354552954\n",
            "train loss:0.003421341514014999\n",
            "train loss:0.0013180864405675456\n",
            "train loss:0.006810813472825394\n",
            "train loss:0.0016280061979107765\n",
            "train loss:0.0013423596418639285\n",
            "train loss:0.01090000812870311\n",
            "train loss:0.0025612265478066804\n",
            "train loss:0.002335569841533639\n",
            "train loss:0.0006335868763219372\n",
            "train loss:0.011766030466883601\n",
            "train loss:0.0048926060626613595\n",
            "train loss:0.005153658700935561\n",
            "train loss:0.0005185194428601681\n",
            "train loss:0.00047538778248372915\n",
            "train loss:0.005738842713909294\n",
            "train loss:0.0028546262229574987\n",
            "train loss:0.001115934026095666\n",
            "train loss:0.0030711903638045122\n",
            "train loss:0.0037682609011232197\n",
            "train loss:0.003781586726837437\n",
            "train loss:0.0062754320212124815\n",
            "train loss:0.012053587455708852\n",
            "train loss:0.0019209728383656622\n",
            "train loss:0.0007819399054210318\n",
            "train loss:0.000177216149759356\n",
            "train loss:0.012058186521695397\n",
            "train loss:0.006038981849370684\n",
            "train loss:0.02451404313096054\n",
            "train loss:0.0017073754081612475\n",
            "train loss:0.0035373263754459555\n",
            "train loss:0.0022859100090409845\n",
            "train loss:0.0017256504258364707\n",
            "train loss:0.004430614225237904\n",
            "train loss:0.005843411717128446\n",
            "train loss:0.0029267550833009066\n",
            "train loss:9.572257952655197e-05\n",
            "train loss:0.0013853069450800685\n",
            "train loss:0.0001284431533850674\n",
            "train loss:0.0005483346041408598\n",
            "train loss:0.0021302410492976\n",
            "train loss:0.0004553731636912371\n",
            "train loss:0.001108217724758721\n",
            "train loss:0.002162234882459069\n",
            "train loss:0.0016125060638069462\n",
            "train loss:0.00109531168881961\n",
            "train loss:0.003047301806811839\n",
            "train loss:0.005984829137066728\n",
            "train loss:0.008134952767376137\n",
            "train loss:0.0010120165830818004\n",
            "train loss:0.0006103168072509796\n",
            "train loss:0.0011187839290104954\n",
            "train loss:0.00025316248286782176\n",
            "train loss:0.003008178861372573\n",
            "train loss:0.0016350389235741936\n",
            "train loss:0.0031582983172851026\n",
            "train loss:0.00828780730629462\n",
            "train loss:0.004890118156591437\n",
            "train loss:0.0025034139363460687\n",
            "train loss:0.002681321579834707\n",
            "train loss:0.007289653076520023\n",
            "train loss:0.0018784016471729142\n",
            "train loss:0.0028664833179952477\n",
            "train loss:0.0001519414336011579\n",
            "train loss:0.001056800020145419\n",
            "train loss:0.0015072293767705806\n",
            "train loss:0.011114867378250137\n",
            "train loss:0.0006960230358294525\n",
            "train loss:0.0023694253766269957\n",
            "train loss:0.005478051936014035\n",
            "train loss:0.0003842130996325143\n",
            "train loss:0.0020416006010929495\n",
            "train loss:0.0052614249211391\n",
            "train loss:0.000858463482427939\n",
            "train loss:0.0015868541232136068\n",
            "train loss:0.004847880315373519\n",
            "train loss:0.031300528824746196\n",
            "train loss:0.0015808249717510668\n",
            "train loss:0.010141798840468084\n",
            "train loss:0.001296166054465634\n",
            "train loss:0.00261728620070643\n",
            "train loss:0.0026743201047351073\n",
            "train loss:0.002367505264572683\n",
            "train loss:0.007575528028337355\n",
            "train loss:0.0006958302847377082\n",
            "train loss:0.0006739248960605632\n",
            "train loss:0.0005798794788683957\n",
            "train loss:0.004553342307079708\n",
            "train loss:0.03227868120846003\n",
            "train loss:0.008479231389989121\n",
            "train loss:0.0022472655990375995\n",
            "train loss:0.0002073020918141448\n",
            "train loss:0.0011286391728470096\n",
            "train loss:0.0012982556595289999\n",
            "train loss:0.00027946170768924585\n",
            "train loss:0.008180640004579937\n",
            "train loss:0.006669503494436322\n",
            "train loss:0.0004695598775300653\n",
            "train loss:0.005838212359320621\n",
            "train loss:0.005436211951303687\n",
            "train loss:0.0006252185239001438\n",
            "train loss:0.0011347921663606142\n",
            "train loss:0.002675271804712587\n",
            "train loss:0.00025348951970572466\n",
            "train loss:0.0013335175971017773\n",
            "train loss:0.006869379233225791\n",
            "train loss:0.00016179153869148486\n",
            "train loss:0.0024883470306058643\n",
            "train loss:0.0006387584404093836\n",
            "train loss:0.002179113107157508\n",
            "train loss:0.00037997657321770884\n",
            "train loss:0.0008094290656194352\n",
            "train loss:0.0004324854284375194\n",
            "train loss:0.0017480428570082452\n",
            "train loss:0.013440668882284184\n",
            "train loss:0.09960375876482773\n",
            "train loss:0.0021171672195164836\n",
            "train loss:0.005563619689432468\n",
            "train loss:0.0004065292989796483\n",
            "train loss:0.007892193292848277\n",
            "train loss:0.010314309114603858\n",
            "train loss:0.0011316528579340993\n",
            "train loss:0.0001559950167449833\n",
            "train loss:0.003085966766172559\n",
            "train loss:0.0009572892885990721\n",
            "train loss:0.0024747872455213233\n",
            "train loss:0.002331988124076161\n",
            "train loss:0.003471203206825072\n",
            "train loss:0.0006682623563344732\n",
            "train loss:0.0020699220252419458\n",
            "train loss:0.0006520477978508375\n",
            "train loss:0.006532569092600708\n",
            "train loss:0.0032734327928660954\n",
            "train loss:0.0036141232134340507\n",
            "train loss:0.0002443855216207143\n",
            "train loss:6.673840295170073e-05\n",
            "train loss:0.005807308660650538\n",
            "train loss:0.0003116287125045329\n",
            "train loss:0.03933577498912816\n",
            "train loss:0.027129499687768455\n",
            "train loss:0.00014944425048307006\n",
            "=== epoch:13, train acc:0.996, test acc:0.986 ===\n",
            "train loss:0.004097842937171671\n",
            "train loss:0.0019684918294061663\n",
            "train loss:0.011299907091283066\n",
            "train loss:0.01210324971038438\n",
            "train loss:0.0008250839496649546\n",
            "train loss:0.0025168203159676395\n",
            "train loss:0.0011252132113655725\n",
            "train loss:0.0025811347631276354\n",
            "train loss:0.001028929522904026\n",
            "train loss:0.05776417883258731\n",
            "train loss:0.0030834827201143998\n",
            "train loss:0.0003586170130380241\n",
            "train loss:0.0108724827030519\n",
            "train loss:0.00037282984640048337\n",
            "train loss:0.002637934337815524\n",
            "train loss:0.005239146920458333\n",
            "train loss:0.0057677787960125374\n",
            "train loss:0.00013747380604848527\n",
            "train loss:0.006048130877890421\n",
            "train loss:0.002033511913901678\n",
            "train loss:0.003880790363220056\n",
            "train loss:0.0014990736441829217\n",
            "train loss:0.005605229406657678\n",
            "train loss:0.0026526568768109227\n",
            "train loss:0.00437902687416969\n",
            "train loss:0.003560896424932285\n",
            "train loss:0.002659944439186104\n",
            "train loss:0.0003355846505420809\n",
            "train loss:9.716407237082463e-05\n",
            "train loss:0.0035392902045690844\n",
            "train loss:0.008542821730017018\n",
            "train loss:0.002882903324971553\n",
            "train loss:0.006313928838304332\n",
            "train loss:0.0016320286991201582\n",
            "train loss:0.0018908645606376918\n",
            "train loss:0.0054217472580048096\n",
            "train loss:0.0020251549429845975\n",
            "train loss:0.0091009164325395\n",
            "train loss:0.0023033962070094817\n",
            "train loss:0.003057453797030227\n",
            "train loss:0.001358206678398126\n",
            "train loss:0.0029872970686937407\n",
            "train loss:0.0018066789567116011\n",
            "train loss:0.005063025808384468\n",
            "train loss:0.002820268671609251\n",
            "train loss:0.003060011016624158\n",
            "train loss:0.0022057454496325055\n",
            "train loss:0.001009099787904369\n",
            "train loss:0.004542139273603666\n",
            "train loss:0.001922228562038201\n",
            "train loss:0.0004320859556967118\n",
            "train loss:0.001634388882220989\n",
            "train loss:0.00041804425500833244\n",
            "train loss:0.0008523495436573886\n",
            "train loss:0.028585448509202437\n",
            "train loss:0.0028894282310020186\n",
            "train loss:0.0001647718245875979\n",
            "train loss:0.0001180979806232103\n",
            "train loss:0.001159609993556165\n",
            "train loss:0.0020022206009654357\n",
            "train loss:0.005968042390935071\n",
            "train loss:0.01198201113654594\n",
            "train loss:0.016735619996955234\n",
            "train loss:0.000642041366351124\n",
            "train loss:0.003248520868735647\n",
            "train loss:0.011473208291527337\n",
            "train loss:0.0014241945797049639\n",
            "train loss:0.0005558361454041802\n",
            "train loss:0.00459367557818186\n",
            "train loss:0.0016250339227411364\n",
            "train loss:0.0009503742720032151\n",
            "train loss:0.006292264816649396\n",
            "train loss:0.003280886787199656\n",
            "train loss:0.049058542083732365\n",
            "train loss:0.0007855981696047534\n",
            "train loss:0.003887636293234891\n",
            "train loss:0.012032439718165668\n",
            "train loss:0.0003062863818543272\n",
            "train loss:0.002240837318001703\n",
            "train loss:0.0014338398894666086\n",
            "train loss:0.0011811437481133028\n",
            "train loss:0.002158092801110477\n",
            "train loss:0.005786346255979693\n",
            "train loss:0.0009594816423289261\n",
            "train loss:0.0026113063670398645\n",
            "train loss:0.007862095582115293\n",
            "train loss:0.0017688561514912831\n",
            "train loss:0.0012415861175684585\n",
            "train loss:0.002335954133770765\n",
            "train loss:0.0033729083733673253\n",
            "train loss:0.0005594167421215285\n",
            "train loss:0.0010473475501693757\n",
            "train loss:0.0004449018144743359\n",
            "train loss:0.005144806780193262\n",
            "train loss:0.002696388130037148\n",
            "train loss:0.0007842837295675825\n",
            "train loss:0.0014378181960036562\n",
            "train loss:0.0006923609616692223\n",
            "train loss:0.027860284788885623\n",
            "train loss:0.0023565633304073606\n",
            "train loss:0.0024138410885912102\n",
            "train loss:0.0010137457659392104\n",
            "train loss:0.005993959814546324\n",
            "train loss:0.001134080028539114\n",
            "train loss:0.021039591570158826\n",
            "train loss:0.004605031994804923\n",
            "train loss:0.0015891187381926277\n",
            "train loss:0.005327942424351087\n",
            "train loss:0.003980918302589565\n",
            "train loss:0.011292000717376896\n",
            "train loss:0.0034129606125355367\n",
            "train loss:0.001962966591562126\n",
            "train loss:0.0016559063393769063\n",
            "train loss:0.036451950627195535\n",
            "train loss:0.006417774849468152\n",
            "train loss:0.0009262628463448321\n",
            "train loss:0.005010199288683827\n",
            "train loss:0.0011796281553109686\n",
            "train loss:0.00537913196961612\n",
            "train loss:0.0007341749377085846\n",
            "train loss:0.00962536747589807\n",
            "train loss:0.00033404595135232503\n",
            "train loss:0.00033496145077485293\n",
            "train loss:0.01074918833743072\n",
            "train loss:0.005370387220715659\n",
            "train loss:0.000540914959502333\n",
            "train loss:0.004083394520795116\n",
            "train loss:0.0016546853753022874\n",
            "train loss:0.00033574889452760734\n",
            "train loss:0.0005195353921395819\n",
            "train loss:0.002249109298389533\n",
            "train loss:0.004665748405413808\n",
            "train loss:0.01451324605931896\n",
            "train loss:0.0027395496334768287\n",
            "train loss:0.009656368119749565\n",
            "train loss:0.005157331993007638\n",
            "train loss:0.003625306484779035\n",
            "train loss:0.003838485741095337\n",
            "train loss:0.0003222035180620891\n",
            "train loss:0.0019207863348773516\n",
            "train loss:0.001936441914169959\n",
            "train loss:0.0002006262962238029\n",
            "train loss:0.0007527051959049046\n",
            "train loss:0.02301962533751565\n",
            "train loss:0.01216349886565931\n",
            "train loss:0.0008540348265867265\n",
            "train loss:0.0011535633474365275\n",
            "train loss:0.007761984526272656\n",
            "train loss:0.002865449837114437\n",
            "train loss:0.004151199183926443\n",
            "train loss:0.002551575727114994\n",
            "train loss:0.0017726211355871963\n",
            "train loss:0.0006576965118568225\n",
            "train loss:0.00106236149487599\n",
            "train loss:0.013920344442162613\n",
            "train loss:0.0009467270717745237\n",
            "train loss:0.006901153198198162\n",
            "train loss:0.0035366570934051646\n",
            "train loss:0.0051007630348160185\n",
            "train loss:0.0020164455901561136\n",
            "train loss:0.0017469153693577626\n",
            "train loss:0.003430687407416816\n",
            "train loss:0.001876277454572213\n",
            "train loss:0.0024192052126483263\n",
            "train loss:0.000723024625220016\n",
            "train loss:0.0002961636730975942\n",
            "train loss:0.0018549733084559405\n",
            "train loss:0.00045109915990069625\n",
            "train loss:0.008890264267467243\n",
            "train loss:0.0007195586832010346\n",
            "train loss:0.0044489350506577395\n",
            "train loss:0.002295374505265022\n",
            "train loss:0.0038568468740145523\n",
            "train loss:0.0034366508189837765\n",
            "train loss:0.001343737028377054\n",
            "train loss:0.001807415333498116\n",
            "train loss:0.010945097359133822\n",
            "train loss:0.0019413373971290135\n",
            "train loss:0.0018355355480457359\n",
            "train loss:0.00020588276666393766\n",
            "train loss:0.009238085198667699\n",
            "train loss:0.006148539274230188\n",
            "train loss:0.006535209687393025\n",
            "train loss:0.003319052962393487\n",
            "train loss:0.004474551488623144\n",
            "train loss:0.0011418156852135873\n",
            "train loss:0.015918663485652775\n",
            "train loss:0.00047720730724195643\n",
            "train loss:0.004956228108536564\n",
            "train loss:0.0029136267017191866\n",
            "train loss:0.00031913969033930115\n",
            "train loss:0.015670550831037456\n",
            "train loss:0.019629125781066816\n",
            "train loss:0.06695772199968342\n",
            "train loss:0.0008589593133140031\n",
            "train loss:0.00034086225193342236\n",
            "train loss:0.05295028157977125\n",
            "train loss:0.0027772499954984604\n",
            "train loss:0.0006810250495025008\n",
            "train loss:0.04243039664863401\n",
            "train loss:0.010582107712109776\n",
            "train loss:0.005896930943368191\n",
            "train loss:0.022928818319957776\n",
            "train loss:0.007668636569926299\n",
            "train loss:0.005721986859405254\n",
            "train loss:0.0018579584619832692\n",
            "train loss:0.0050024268305325905\n",
            "train loss:0.006533571575702497\n",
            "train loss:0.004887726683013661\n",
            "train loss:0.008884217810475006\n",
            "train loss:0.00789126471406891\n",
            "train loss:0.0371866354189747\n",
            "train loss:0.018832019666363435\n",
            "train loss:0.0009144908335090166\n",
            "train loss:0.0019059097127966504\n",
            "train loss:0.0020318856113085925\n",
            "train loss:0.002154777837246891\n",
            "train loss:0.00711379128981451\n",
            "train loss:0.002200714037638432\n",
            "train loss:0.006054343020364692\n",
            "train loss:0.005391980578026181\n",
            "train loss:0.0004748171033850075\n",
            "train loss:0.0015675201977018941\n",
            "train loss:0.00035745246507897405\n",
            "train loss:7.127285910248481e-05\n",
            "train loss:0.024320504241863425\n",
            "train loss:0.0035343275764277956\n",
            "train loss:0.009449013068552023\n",
            "train loss:0.002209119513175667\n",
            "train loss:0.00294455264904107\n",
            "train loss:0.0008118963673718707\n",
            "train loss:0.0006389561751443177\n",
            "train loss:0.0008595554832700493\n",
            "train loss:0.00431136983688319\n",
            "train loss:0.0009562842995141106\n",
            "train loss:0.006199724477787561\n",
            "train loss:0.0010611900710601387\n",
            "train loss:0.00917799505849163\n",
            "train loss:0.014763912098977015\n",
            "train loss:0.0002975893947048001\n",
            "train loss:0.0001464008975201986\n",
            "train loss:0.004141054274337115\n",
            "train loss:0.002277484560621672\n",
            "train loss:0.002227228282504064\n",
            "train loss:0.0010387517386857932\n",
            "train loss:0.022265166173308412\n",
            "train loss:0.005815573240312379\n",
            "train loss:0.0019698426330091983\n",
            "train loss:0.0018397831996547166\n",
            "train loss:0.0035174401232646686\n",
            "train loss:0.0012299468063958904\n",
            "train loss:0.0020634164786721737\n",
            "train loss:0.0010802229947271707\n",
            "train loss:0.003652098907100502\n",
            "train loss:0.004193387372251977\n",
            "train loss:0.0009207812540204481\n",
            "train loss:0.00018046992365373303\n",
            "train loss:0.002263755650778616\n",
            "train loss:0.0007039293966675995\n",
            "train loss:0.0012767544713772352\n",
            "train loss:0.01783143699574401\n",
            "train loss:0.006605940904374194\n",
            "train loss:0.001560059102228199\n",
            "train loss:0.0023646295461973864\n",
            "train loss:0.0029188450853034568\n",
            "train loss:0.005135761949969367\n",
            "train loss:0.0006925161332309225\n",
            "train loss:0.024238413187594496\n",
            "train loss:0.002204298614991107\n",
            "train loss:0.0007316729704241575\n",
            "train loss:0.003406396748479632\n",
            "train loss:0.0015668976420425528\n",
            "train loss:0.0029191479971256685\n",
            "train loss:0.0028204145882779596\n",
            "train loss:0.006709428139091644\n",
            "train loss:0.004852135336001331\n",
            "train loss:0.006147337969333639\n",
            "train loss:0.011977251176289354\n",
            "train loss:0.005941012055423317\n",
            "train loss:0.005000871326077999\n",
            "train loss:0.0009271312473338013\n",
            "train loss:0.004309763799773874\n",
            "train loss:0.015161218597299997\n",
            "train loss:0.0009613014576067069\n",
            "train loss:0.003227546596299926\n",
            "train loss:0.0031827820282049448\n",
            "train loss:0.00015849482172621742\n",
            "train loss:0.005735438602634491\n",
            "train loss:0.002759925295601779\n",
            "train loss:0.013335265291631225\n",
            "train loss:0.00031267401017756147\n",
            "train loss:0.001550111988750862\n",
            "train loss:0.004556526528934212\n",
            "train loss:0.007713218577506683\n",
            "train loss:0.0014334431895179527\n",
            "train loss:0.0019023796014731643\n",
            "train loss:0.00203444280711514\n",
            "train loss:0.004933678759188915\n",
            "train loss:0.00716607257974648\n",
            "train loss:0.0005878771924839885\n",
            "train loss:0.01969388892735442\n",
            "train loss:0.0032947892479781747\n",
            "train loss:0.003527062228187304\n",
            "train loss:0.006551696292041806\n",
            "train loss:0.00048444103588999037\n",
            "train loss:0.010180232805310266\n",
            "train loss:0.006076398858046642\n",
            "train loss:0.001966176603414385\n",
            "train loss:0.0024777048242689845\n",
            "train loss:0.0023258545290064246\n",
            "train loss:0.0009266391593656376\n",
            "train loss:0.0016221517424434737\n",
            "train loss:0.004906531934166325\n",
            "train loss:0.0070444612510778245\n",
            "train loss:0.002160585222931029\n",
            "train loss:0.0011019431643817387\n",
            "train loss:0.00027628042502873834\n",
            "train loss:0.003907917711528053\n",
            "train loss:0.005136375170238949\n",
            "train loss:0.012228164005056935\n",
            "train loss:0.002857966616604594\n",
            "train loss:0.0028117534209347165\n",
            "train loss:0.004404804979332395\n",
            "train loss:0.005688141331673506\n",
            "train loss:0.01516035902854835\n",
            "train loss:0.0005611449644205505\n",
            "train loss:0.007320064921638692\n",
            "train loss:0.0020194253936716743\n",
            "train loss:0.0006388545539673856\n",
            "train loss:0.0016824412102600897\n",
            "train loss:0.00010419577990915389\n",
            "train loss:0.008653321994403164\n",
            "train loss:0.0006305575307063848\n",
            "train loss:0.006202597206620803\n",
            "train loss:0.002166970789698793\n",
            "train loss:0.0028810475938235245\n",
            "train loss:0.0073353326644837345\n",
            "train loss:0.0020715098889991924\n",
            "train loss:0.002851876918580189\n",
            "train loss:0.0010044244906888382\n",
            "train loss:0.009003591703804404\n",
            "train loss:0.004919996980191712\n",
            "train loss:0.0038694143197725837\n",
            "train loss:0.0032664050777396632\n",
            "train loss:0.0022964237220213565\n",
            "train loss:0.014231236018913825\n",
            "train loss:0.0013755575546870085\n",
            "train loss:0.000534078019145712\n",
            "train loss:0.005996129225771553\n",
            "train loss:0.0002420619538692412\n",
            "train loss:0.0002663702035024495\n",
            "train loss:0.005530481262796321\n",
            "train loss:0.0008174123620359187\n",
            "train loss:0.002992406985375721\n",
            "train loss:0.0015235007086903238\n",
            "train loss:0.0023686881278789746\n",
            "train loss:0.004484570321197164\n",
            "train loss:0.001358658126138303\n",
            "train loss:0.0075330988030629245\n",
            "train loss:0.0024601450307263346\n",
            "train loss:0.005843511673671129\n",
            "train loss:0.002415223152718515\n",
            "train loss:0.001760768344177123\n",
            "train loss:0.0007166401179698354\n",
            "train loss:0.005869298087319109\n",
            "train loss:0.0007288406590143013\n",
            "train loss:0.002814769548391071\n",
            "train loss:0.0005388764930539119\n",
            "train loss:0.0034897162939933803\n",
            "train loss:0.0014623779328172576\n",
            "train loss:0.011095224930543211\n",
            "train loss:0.0014531250803463919\n",
            "train loss:0.00114478170403179\n",
            "train loss:0.0025743601953002676\n",
            "train loss:0.0003444367348367914\n",
            "train loss:0.0006334676814736286\n",
            "train loss:0.0003979778719529924\n",
            "train loss:0.001457703819373397\n",
            "train loss:0.0013658033787218632\n",
            "train loss:0.0014535718192718228\n",
            "train loss:0.0004084833481967496\n",
            "train loss:0.0019682352150435086\n",
            "train loss:0.0005648406771733745\n",
            "train loss:0.00014354275326907274\n",
            "train loss:0.0040242700869870555\n",
            "train loss:0.005708090610090363\n",
            "train loss:0.0027671278906001434\n",
            "train loss:0.0021958749664384857\n",
            "train loss:0.008879873552468822\n",
            "train loss:0.0029251373971966037\n",
            "train loss:0.001993669768676943\n",
            "train loss:8.592393865779915e-05\n",
            "train loss:0.004165612187173633\n",
            "train loss:0.0015307688956535787\n",
            "train loss:0.0008916669400336003\n",
            "train loss:0.003917798938057297\n",
            "train loss:0.004242810583610032\n",
            "train loss:0.0037184044857779147\n",
            "train loss:0.0030541859605899215\n",
            "train loss:6.979224122717716e-05\n",
            "train loss:0.004390300770556411\n",
            "train loss:0.010138262790655201\n",
            "train loss:0.0003734022547009799\n",
            "train loss:0.0004185428600519175\n",
            "train loss:0.0007706115388442736\n",
            "train loss:0.0015136510497631753\n",
            "train loss:0.0008904148892040136\n",
            "train loss:0.005252996182899681\n",
            "train loss:0.0002707290791813168\n",
            "train loss:0.07390016717478738\n",
            "train loss:0.00023281144456013318\n",
            "train loss:0.0019790804530215975\n",
            "train loss:0.003565485754533684\n",
            "train loss:0.0003381156087171978\n",
            "train loss:0.0013284972401325999\n",
            "train loss:0.0012864444419591102\n",
            "train loss:0.0006075209436437064\n",
            "train loss:0.0014649021715180703\n",
            "train loss:0.0007379527897773903\n",
            "train loss:0.0036146562695078565\n",
            "train loss:0.00570050713269078\n",
            "train loss:0.004903828060113166\n",
            "train loss:0.0061063167408226225\n",
            "train loss:0.0005602377729184676\n",
            "train loss:0.0017080242001403178\n",
            "train loss:0.005265052197684467\n",
            "train loss:0.0015383946002455766\n",
            "train loss:0.016341984481214777\n",
            "train loss:0.005906227837410919\n",
            "train loss:0.0028923587567204253\n",
            "train loss:0.004694711099172699\n",
            "train loss:0.0003369671283693352\n",
            "train loss:0.0010238231067617807\n",
            "train loss:0.00021760703065510964\n",
            "train loss:0.011227629071882574\n",
            "train loss:0.00383582099843262\n",
            "train loss:0.0034157855086603623\n",
            "train loss:0.002408341339315718\n",
            "train loss:0.0075440947931034895\n",
            "train loss:0.0003350284504526007\n",
            "train loss:0.0006027853782482292\n",
            "train loss:0.00043970195977251984\n",
            "train loss:0.014731293987522596\n",
            "train loss:0.0009508926049558981\n",
            "train loss:0.005195393949076719\n",
            "train loss:0.00031964841552756604\n",
            "train loss:0.0014559755041973457\n",
            "train loss:0.000600094525590922\n",
            "train loss:0.00013850293993634182\n",
            "train loss:0.00014533838226047223\n",
            "train loss:0.002431695756709821\n",
            "train loss:0.007102593413617172\n",
            "train loss:0.0011970624116406873\n",
            "train loss:0.0009756219948626183\n",
            "train loss:0.001206912392958413\n",
            "train loss:0.00893569608283107\n",
            "train loss:0.0012412320708359195\n",
            "train loss:0.00025122456132477673\n",
            "train loss:0.0014159581283681494\n",
            "train loss:0.0006972951568246683\n",
            "train loss:0.0036900085716112933\n",
            "train loss:0.004129492247743242\n",
            "train loss:0.0002876320615657665\n",
            "train loss:0.003059712104064484\n",
            "train loss:0.006952033319349723\n",
            "train loss:0.001838355297332239\n",
            "train loss:0.00013982048733750032\n",
            "train loss:0.0005462376238048055\n",
            "train loss:0.006325045502586196\n",
            "train loss:0.0036335272663115758\n",
            "train loss:0.0014353564204512754\n",
            "train loss:0.0005628548705872473\n",
            "train loss:0.0008220488961975006\n",
            "train loss:0.0013824775040633076\n",
            "train loss:0.0005982950970414803\n",
            "train loss:0.002262412417593818\n",
            "train loss:0.001477054958132762\n",
            "train loss:0.006911557792123442\n",
            "train loss:0.002277459250781926\n",
            "train loss:0.0038929624833991426\n",
            "train loss:0.002723419140398337\n",
            "train loss:0.0005189945592568678\n",
            "train loss:0.0004607314441172039\n",
            "train loss:0.00011264513107637185\n",
            "train loss:0.0021552645461096333\n",
            "train loss:0.0016067012061338523\n",
            "train loss:0.024805343303005024\n",
            "train loss:0.028125810537878257\n",
            "train loss:0.0005452591360883989\n",
            "train loss:0.0034399877777702946\n",
            "train loss:0.0008773889851811392\n",
            "train loss:0.0006984764390982655\n",
            "train loss:0.0008028781780719563\n",
            "train loss:0.0011573570307184628\n",
            "train loss:0.0024583547750716274\n",
            "train loss:0.009253992923212499\n",
            "train loss:0.0009420547482152465\n",
            "train loss:0.010636430333222178\n",
            "train loss:0.0032153472213211826\n",
            "train loss:0.0016902922721505702\n",
            "train loss:0.0006103713160121087\n",
            "train loss:0.0013311168388420635\n",
            "train loss:0.006918995716560501\n",
            "train loss:0.006237459776057149\n",
            "train loss:0.0035029120443099177\n",
            "train loss:0.0013476313862309146\n",
            "train loss:0.00024306949279272042\n",
            "train loss:0.0005700293519873174\n",
            "train loss:0.0007640554711354448\n",
            "train loss:0.005057849431295775\n",
            "train loss:0.0007553390643881227\n",
            "train loss:0.012626582471006105\n",
            "train loss:0.012545658386077628\n",
            "train loss:0.002535231613615987\n",
            "train loss:0.0012003196866181645\n",
            "train loss:0.0008873748447906902\n",
            "train loss:0.003408515326789141\n",
            "train loss:0.005274713949252574\n",
            "train loss:0.0022728166215337485\n",
            "train loss:0.0008544870996673997\n",
            "train loss:0.00022910909015508182\n",
            "train loss:0.0007858691638223893\n",
            "train loss:0.00046108395778068234\n",
            "train loss:0.00024245952170288507\n",
            "train loss:0.004333421094411143\n",
            "train loss:0.0006669962645995441\n",
            "train loss:0.0031618091604189154\n",
            "train loss:0.006007077197928863\n",
            "train loss:0.0015004992593360043\n",
            "train loss:0.0006325318042233791\n",
            "train loss:0.0012435390586042169\n",
            "train loss:0.01076020430954882\n",
            "train loss:0.0018234830576833027\n",
            "train loss:0.011902085132021257\n",
            "train loss:0.004736813672590801\n",
            "train loss:0.004671076084169116\n",
            "train loss:0.000291275016232787\n",
            "train loss:0.00028736342528682454\n",
            "train loss:0.0025871831259479876\n",
            "train loss:0.014249496074938093\n",
            "train loss:0.0014192158201139823\n",
            "train loss:0.0013057172342138\n",
            "train loss:0.007149687850811493\n",
            "train loss:0.000963363841701326\n",
            "train loss:0.00526523698128711\n",
            "train loss:0.0001460129374373379\n",
            "train loss:0.0007657978133125755\n",
            "train loss:0.0025833077530653813\n",
            "train loss:0.001029767342853898\n",
            "train loss:0.0034692555163275025\n",
            "train loss:0.01789921626312914\n",
            "train loss:0.0015599062725939901\n",
            "train loss:0.00019257063467154276\n",
            "train loss:0.0023008049850374874\n",
            "train loss:0.00226457274059714\n",
            "train loss:0.0014689383005782874\n",
            "train loss:0.0014107512458209634\n",
            "train loss:0.0031523618093340744\n",
            "train loss:0.0002643560290412586\n",
            "train loss:0.0005397302647638367\n",
            "train loss:0.0026080310367902694\n",
            "train loss:0.0034702884691220352\n",
            "train loss:0.00046453184395656605\n",
            "train loss:0.0009741652158888141\n",
            "train loss:0.0013532352357762678\n",
            "train loss:0.0012869233844840459\n",
            "train loss:0.0007237816133804517\n",
            "train loss:0.0019980423680138167\n",
            "train loss:0.001524227057129358\n",
            "train loss:0.0009551784144966085\n",
            "train loss:0.00027872807730773254\n",
            "train loss:0.0016619077635214325\n",
            "train loss:0.029128671424396357\n",
            "train loss:0.00046810791402642437\n",
            "train loss:0.003922605223560495\n",
            "train loss:0.0010237037831218707\n",
            "train loss:5.1538210636895194e-05\n",
            "train loss:0.0011384208276203735\n",
            "train loss:0.0034234633015453107\n",
            "train loss:0.0008154511121106792\n",
            "train loss:0.0019522684622729819\n",
            "train loss:0.0035942781947517254\n",
            "train loss:0.0036754365197097677\n",
            "train loss:0.0010062782028709488\n",
            "train loss:0.0002650827380707883\n",
            "train loss:0.0007638260550678677\n",
            "train loss:0.007518907532206615\n",
            "train loss:0.00044061510782220504\n",
            "train loss:0.004412306194498585\n",
            "train loss:0.005458222492240574\n",
            "train loss:0.0011801873579368645\n",
            "train loss:0.0005665659638145628\n",
            "train loss:0.0002986434957550987\n",
            "train loss:0.004119697009242939\n",
            "train loss:0.014386987105283223\n",
            "train loss:0.0006687895944287244\n",
            "train loss:0.0014012432051792422\n",
            "train loss:0.0035021338904733545\n",
            "train loss:0.00029258086097724953\n",
            "train loss:0.00458728712840985\n",
            "=== epoch:14, train acc:1.0, test acc:0.987 ===\n",
            "train loss:0.00035693106644030443\n",
            "train loss:0.017122297934621687\n",
            "train loss:0.02192692811705221\n",
            "train loss:0.00021766999113577334\n",
            "train loss:0.00680234603184575\n",
            "train loss:0.007511096140542359\n",
            "train loss:0.001077308487875172\n",
            "train loss:0.004854901992557754\n",
            "train loss:0.005335642542029855\n",
            "train loss:0.006494441245238331\n",
            "train loss:0.004419913262907194\n",
            "train loss:0.0007632350583917839\n",
            "train loss:0.0030779818903005412\n",
            "train loss:0.004330998330340844\n",
            "train loss:0.003201999902254689\n",
            "train loss:0.0026475488398491303\n",
            "train loss:0.009214770077596794\n",
            "train loss:0.0004788103461451915\n",
            "train loss:0.006148897385828581\n",
            "train loss:0.004229079178074014\n",
            "train loss:0.0026182752474250663\n",
            "train loss:0.0010206256178545664\n",
            "train loss:0.0019563965638107242\n",
            "train loss:0.0002958097721592702\n",
            "train loss:0.010052169813676182\n",
            "train loss:0.0024745064960705913\n",
            "train loss:0.0015765063077488475\n",
            "train loss:0.0015030548410351055\n",
            "train loss:0.0011908527480716503\n",
            "train loss:0.0039104366332802145\n",
            "train loss:0.007528883013403026\n",
            "train loss:0.0011738899636151627\n",
            "train loss:0.02750040166632362\n",
            "train loss:0.004408460179400004\n",
            "train loss:0.010328475995712093\n",
            "train loss:0.003778785386392161\n",
            "train loss:0.0033763070007371255\n",
            "train loss:0.00033991616772785933\n",
            "train loss:0.0025047339844391737\n",
            "train loss:0.0006258686346327071\n",
            "train loss:0.002620589158006047\n",
            "train loss:0.00029548006919886824\n",
            "train loss:0.0023801821719424882\n",
            "train loss:0.006888159712608318\n",
            "train loss:0.01245709950978192\n",
            "train loss:0.008679299686017473\n",
            "train loss:0.00035454565701082216\n",
            "train loss:0.000243460527881947\n",
            "train loss:0.16138570811777464\n",
            "train loss:0.0041969282333997136\n",
            "train loss:0.007470547338689948\n",
            "train loss:0.00039282873144485766\n",
            "train loss:0.0036427009854980742\n",
            "train loss:0.002603948952065061\n",
            "train loss:0.11562946906891655\n",
            "train loss:0.0068283701773906745\n",
            "train loss:0.006691985548927975\n",
            "train loss:0.01712406266786567\n",
            "train loss:0.00815559249187779\n",
            "train loss:0.006660214208076311\n",
            "train loss:0.009326312293083925\n",
            "train loss:0.003849191201342601\n",
            "train loss:0.003561101097644459\n",
            "train loss:0.0019442574331214645\n",
            "train loss:0.008505030752308173\n",
            "train loss:0.02483202459795925\n",
            "train loss:0.002512041680498939\n",
            "train loss:0.003027031618179748\n",
            "train loss:0.0028865381606474876\n",
            "train loss:0.002442982965169607\n",
            "train loss:0.00440005851794311\n",
            "train loss:0.006278711027596228\n",
            "train loss:0.0056853064579171966\n",
            "train loss:0.01263080021363365\n",
            "train loss:0.003769364964704773\n",
            "train loss:0.006303227480625152\n",
            "train loss:0.0056617000736807425\n",
            "train loss:0.0013291947266771376\n",
            "train loss:0.0029819434944875645\n",
            "train loss:0.000640436840045647\n",
            "train loss:0.00015071453870502886\n",
            "train loss:0.0010845845307967642\n",
            "train loss:0.07230082387139776\n",
            "train loss:0.0067506005860102905\n",
            "train loss:0.003229812843114392\n",
            "train loss:0.0018446160599534212\n",
            "train loss:0.003853649907893394\n",
            "train loss:0.0015777164369275424\n",
            "train loss:0.000589979685287765\n",
            "train loss:0.009187803690649716\n",
            "train loss:0.0099579690333242\n",
            "train loss:0.0023638519168409223\n",
            "train loss:0.0034972595597378923\n",
            "train loss:0.004057288230165121\n",
            "train loss:0.005579166266839083\n",
            "train loss:0.002268985362475231\n",
            "train loss:0.004203703937814037\n",
            "train loss:0.01588271132317178\n",
            "train loss:0.0017524251972276313\n",
            "train loss:0.019459582844708813\n",
            "train loss:0.0035058459038607858\n",
            "train loss:0.0006762243365296321\n",
            "train loss:0.003963101983899083\n",
            "train loss:0.001483750534493046\n",
            "train loss:0.0033666673563862025\n",
            "train loss:0.0027677013326751956\n",
            "train loss:0.003495582302915\n",
            "train loss:0.0039885019609144975\n",
            "train loss:0.004839737636381436\n",
            "train loss:0.00662663205559714\n",
            "train loss:0.0235568392078497\n",
            "train loss:0.0005001351188995902\n",
            "train loss:0.0009324926838792301\n",
            "train loss:0.003252467585608923\n",
            "train loss:0.005939850917359582\n",
            "train loss:0.00972065526043414\n",
            "train loss:0.0028244551322937623\n",
            "train loss:0.002039867679131226\n",
            "train loss:0.0005220823108257695\n",
            "train loss:0.0010037677076750887\n",
            "train loss:0.00047885671723791386\n",
            "train loss:0.0016988192689245231\n",
            "train loss:0.002129963730855321\n",
            "train loss:0.0063623808362591105\n",
            "train loss:0.0016748482298898472\n",
            "train loss:0.00023122664714150045\n",
            "train loss:0.006179004255662819\n",
            "train loss:0.002713541073931242\n",
            "train loss:0.0008238720397173085\n",
            "train loss:0.0018281886570111596\n",
            "train loss:0.0021505527319004678\n",
            "train loss:0.00466253601658503\n",
            "train loss:0.003462045810708631\n",
            "train loss:0.0014520933717005124\n",
            "train loss:0.0011683103760433597\n",
            "train loss:0.00544492918555847\n",
            "train loss:0.0035016039979575875\n",
            "train loss:0.0006638282744785017\n",
            "train loss:0.0010695516480966286\n",
            "train loss:0.0013489932324375362\n",
            "train loss:0.0007492365412437896\n",
            "train loss:0.00046437622188856846\n",
            "train loss:0.00011213440165353904\n",
            "train loss:0.0007680077282087497\n",
            "train loss:0.0023623557806982886\n",
            "train loss:0.004800058815998914\n",
            "train loss:0.0024360345397852275\n",
            "train loss:0.0010158669167710367\n",
            "train loss:0.0035728926369562835\n",
            "train loss:0.00020981126144121586\n",
            "train loss:0.008196788778478938\n",
            "train loss:0.0004896247196937946\n",
            "train loss:0.000876727741661315\n",
            "train loss:0.0023726709146138702\n",
            "train loss:0.009800958555861857\n",
            "train loss:0.00029008886322023724\n",
            "train loss:0.00742448213667323\n",
            "train loss:0.0002176505032493961\n",
            "train loss:0.00060680048526294\n",
            "train loss:0.0008566759012743952\n",
            "train loss:0.0037833048423061284\n",
            "train loss:0.0010258999998038589\n",
            "train loss:0.005113172235576483\n",
            "train loss:0.0005805516011008725\n",
            "train loss:0.0013342462808455398\n",
            "train loss:0.0005935945395487685\n",
            "train loss:0.0010314748866520204\n",
            "train loss:0.0019167406067259014\n",
            "train loss:0.002340832819312303\n",
            "train loss:0.006351192547031125\n",
            "train loss:0.0007248740609225647\n",
            "train loss:0.001693885525788655\n",
            "train loss:0.0006579560563213314\n",
            "train loss:0.0005821120606559914\n",
            "train loss:0.00012336664538048644\n",
            "train loss:8.814133237463199e-05\n",
            "train loss:0.0013540230561220694\n",
            "train loss:0.0040785443022129456\n",
            "train loss:7.74195803277851e-05\n",
            "train loss:0.000322849404324995\n",
            "train loss:0.00024364912495115584\n",
            "train loss:0.000767620853928512\n",
            "train loss:0.0027115622272259454\n",
            "train loss:0.002437002159933413\n",
            "train loss:0.0009940741115682444\n",
            "train loss:0.0003013008624775479\n",
            "train loss:0.002528491139313102\n",
            "train loss:0.008568198286519163\n",
            "train loss:0.0032350895443097856\n",
            "train loss:0.0018852553554711054\n",
            "train loss:0.011435147531987475\n",
            "train loss:0.002045484040581793\n",
            "train loss:0.000571850491955119\n",
            "train loss:0.0017875272672808742\n",
            "train loss:0.00412848243293945\n",
            "train loss:0.029591349126912\n",
            "train loss:0.0022431756737190446\n",
            "train loss:0.002657798897744938\n",
            "train loss:0.03540028639604864\n",
            "train loss:0.0002789772041916461\n",
            "train loss:0.0020557487621328772\n",
            "train loss:0.003412261326180799\n",
            "train loss:0.0020730629946873686\n",
            "train loss:0.0005670697002337229\n",
            "train loss:0.0006091849468171646\n",
            "train loss:0.001389567984203719\n",
            "train loss:0.0005518494385799413\n",
            "train loss:0.018635717449438944\n",
            "train loss:0.0038777919837852054\n",
            "train loss:0.00025589644332200923\n",
            "train loss:0.0022649805672027394\n",
            "train loss:0.00023409518671773093\n",
            "train loss:0.0037916186614682028\n",
            "train loss:0.0045543631106327795\n",
            "train loss:0.003658829338401413\n",
            "train loss:0.0037088589753342237\n",
            "train loss:0.01032619439994528\n",
            "train loss:0.004400074133333819\n",
            "train loss:0.00376759438984102\n",
            "train loss:0.0008702631578668208\n",
            "train loss:0.0035707633303675994\n",
            "train loss:0.001723205264496809\n",
            "train loss:0.11489479954720755\n",
            "train loss:0.0014264355424224448\n",
            "train loss:0.0015271536741779121\n",
            "train loss:0.004524247853282506\n",
            "train loss:0.0101413492388328\n",
            "train loss:0.016950927645030655\n",
            "train loss:0.0022068494247851067\n",
            "train loss:0.011276649498598705\n",
            "train loss:0.0011500771088923376\n",
            "train loss:0.002817684408843\n",
            "train loss:0.003374476121772765\n",
            "train loss:0.0014624665828942565\n",
            "train loss:0.005875033858444213\n",
            "train loss:0.004183263564313296\n",
            "train loss:0.011615527617191646\n",
            "train loss:0.004587513800419921\n",
            "train loss:0.001520186326849641\n",
            "train loss:0.0038421365317575086\n",
            "train loss:0.005406765243053997\n",
            "train loss:0.0002915893086926041\n",
            "train loss:0.013486424031646276\n",
            "train loss:0.0014323252160710898\n",
            "train loss:0.003715250377246091\n",
            "train loss:0.008443115113617877\n",
            "train loss:0.0001109813692884584\n",
            "train loss:0.03426153899492828\n",
            "train loss:0.005312225265814405\n",
            "train loss:0.0010467520415379772\n",
            "train loss:0.00044024623477451665\n",
            "train loss:0.0014103426744102962\n",
            "train loss:0.006648388533881\n",
            "train loss:0.00638578760728845\n",
            "train loss:0.00222425569213448\n",
            "train loss:0.025241669872631604\n",
            "train loss:0.0010323787092102745\n",
            "train loss:0.0011662308923014808\n",
            "train loss:0.008116155542109222\n",
            "train loss:0.0004634878358246293\n",
            "train loss:0.002186485035188178\n",
            "train loss:0.0012498834694778284\n",
            "train loss:0.0019304667103551753\n",
            "train loss:0.0006245373259817136\n",
            "train loss:0.006828136043909474\n",
            "train loss:0.005824366254733732\n",
            "train loss:0.0007151102420541414\n",
            "train loss:0.0006358050720342861\n",
            "train loss:0.02733107509297464\n",
            "train loss:0.0037944888055687696\n",
            "train loss:0.005026335359109253\n",
            "train loss:0.002550883129720895\n",
            "train loss:0.002068185783686501\n",
            "train loss:0.0005606795140826177\n",
            "train loss:0.01005690985600099\n",
            "train loss:0.002100025494122684\n",
            "train loss:0.0020292053138834115\n",
            "train loss:0.00041752222468936914\n",
            "train loss:0.0022684811516372524\n",
            "train loss:0.0038465960050222845\n",
            "train loss:0.0017429073594591627\n",
            "train loss:0.00041645705598166593\n",
            "train loss:0.0026701611971140567\n",
            "train loss:0.006614110654376864\n",
            "train loss:0.002220607802081815\n",
            "train loss:0.0009505021925286224\n",
            "train loss:0.005139685937501439\n",
            "train loss:0.000942598581294225\n",
            "train loss:0.0002073023585837631\n",
            "train loss:0.0044731906609822986\n",
            "train loss:0.00038998058698436677\n",
            "train loss:0.0095806396770508\n",
            "train loss:0.003222456073378296\n",
            "train loss:0.0005459945833626455\n",
            "train loss:0.007696491902811689\n",
            "train loss:0.01823790096081855\n",
            "train loss:0.08231149680027106\n",
            "train loss:0.0007175772278053221\n",
            "train loss:0.0010792459062764048\n",
            "train loss:0.001708100439125616\n",
            "train loss:0.00023819287216521619\n",
            "train loss:0.006738789561305865\n",
            "train loss:0.0001322342452987606\n",
            "train loss:0.001756267291296325\n",
            "train loss:0.005506140460789083\n",
            "train loss:0.0009199992245689346\n",
            "train loss:0.0019802354062368483\n",
            "train loss:0.005141011764632524\n",
            "train loss:0.003602327018459373\n",
            "train loss:0.0018416380018625269\n",
            "train loss:0.004915985977474575\n",
            "train loss:0.0014963340153925995\n",
            "train loss:0.0013833184703540005\n",
            "train loss:0.006130533005036608\n",
            "train loss:0.0007264302084708857\n",
            "train loss:0.0020019708789889594\n",
            "train loss:0.004731926177508476\n",
            "train loss:0.0009266930978431028\n",
            "train loss:0.006146374122969598\n",
            "train loss:0.007120808344224454\n",
            "train loss:0.0007655500723916258\n",
            "train loss:0.0005982744111952527\n",
            "train loss:0.0014071939964824009\n",
            "train loss:0.000549417327879122\n",
            "train loss:0.002278871154084207\n",
            "train loss:0.0007307671010324975\n",
            "train loss:0.0005243380929786385\n",
            "train loss:0.019636516749409055\n",
            "train loss:0.0077634940856116785\n",
            "train loss:0.0010757063973470835\n",
            "train loss:0.000958140300223859\n",
            "train loss:0.003932273868201127\n",
            "train loss:0.003149634008225097\n",
            "train loss:0.0013185586192638705\n",
            "train loss:0.005441512504515692\n",
            "train loss:0.00048471310444687786\n",
            "train loss:0.0018240734180174562\n",
            "train loss:0.0014264168318521633\n",
            "train loss:0.005029823171356789\n",
            "train loss:0.000610559125453782\n",
            "train loss:0.0005251379738492524\n",
            "train loss:0.0033459007266524537\n",
            "train loss:0.005820964267262376\n",
            "train loss:0.003180369511632809\n",
            "train loss:0.0032867402254677307\n",
            "train loss:0.000508378385780048\n",
            "train loss:0.005207417291181729\n",
            "train loss:0.004750625155094811\n",
            "train loss:0.000980161272772441\n",
            "train loss:0.00023886422057463875\n",
            "train loss:0.0003217174352153213\n",
            "train loss:0.002627967245903239\n",
            "train loss:0.00455329921182774\n",
            "train loss:0.0017527645176016865\n",
            "train loss:0.0018096219978036116\n",
            "train loss:0.002944829192617597\n",
            "train loss:0.0030672358239731547\n",
            "train loss:0.00393311646890169\n",
            "train loss:0.000446334406592146\n",
            "train loss:0.0025965939705891133\n",
            "train loss:0.0012893698795825254\n",
            "train loss:0.0005079360711056015\n",
            "train loss:0.00015873164911908182\n",
            "train loss:0.004065001452173784\n",
            "train loss:0.0005816217688590845\n",
            "train loss:0.0024425009298753996\n",
            "train loss:0.00019917732549067858\n",
            "train loss:0.013469423501948621\n",
            "train loss:0.0005339283008277021\n",
            "train loss:0.005589419158830603\n",
            "train loss:0.002960997754601481\n",
            "train loss:0.002545212128983661\n",
            "train loss:0.0013158305797938263\n",
            "train loss:0.0014561937270299754\n",
            "train loss:0.0011723083169328024\n",
            "train loss:0.0015259965784772303\n",
            "train loss:0.0014820850818464328\n",
            "train loss:0.00024887151785392295\n",
            "train loss:0.00032767519469223497\n",
            "train loss:0.00011597529614825188\n",
            "train loss:0.0037206831428457966\n",
            "train loss:0.004183615473807429\n",
            "train loss:0.00383576195270463\n",
            "train loss:0.001700987041276074\n",
            "train loss:0.002095949944238416\n",
            "train loss:0.0004827077464714458\n",
            "train loss:0.0004914077679621\n",
            "train loss:0.0033366695333852873\n",
            "train loss:0.0001410490441529366\n",
            "train loss:0.0023680037957537602\n",
            "train loss:0.001972789593780921\n",
            "train loss:0.0009242647306183447\n",
            "train loss:0.001867819507120182\n",
            "train loss:0.00012870150887395247\n",
            "train loss:0.009970404080337586\n",
            "train loss:0.003037354906823829\n",
            "train loss:0.02760216289509126\n",
            "train loss:0.0033438117168793197\n",
            "train loss:0.0012474605942652032\n",
            "train loss:0.0010715357961638688\n",
            "train loss:0.0013971616352671146\n",
            "train loss:0.00525330409838635\n",
            "train loss:0.0005872760194991967\n",
            "train loss:0.003210943131582662\n",
            "train loss:0.001772779204106169\n",
            "train loss:0.008613508585194168\n",
            "train loss:0.005331155243559315\n",
            "train loss:0.0055832208504450085\n",
            "train loss:0.00015218949431163568\n",
            "train loss:0.010621314961833567\n",
            "train loss:0.0008270965938599971\n",
            "train loss:0.001787915027527644\n",
            "train loss:0.0012804571131770934\n",
            "train loss:0.006646797452814637\n",
            "train loss:0.0029461488270830618\n",
            "train loss:0.00318952332136094\n",
            "train loss:0.0013752038361746323\n",
            "train loss:0.0048801616689670224\n",
            "train loss:0.0023698755614354277\n",
            "train loss:0.003112451708721571\n",
            "train loss:0.003028355069312128\n",
            "train loss:0.005714351639959067\n",
            "train loss:0.00315193506149697\n",
            "train loss:0.0002853423807180426\n",
            "train loss:0.0050745840063129355\n",
            "train loss:0.006512310742920303\n",
            "train loss:0.00026798921912885373\n",
            "train loss:0.0021171776244430607\n",
            "train loss:0.004153574120161565\n",
            "train loss:0.0025712684552901106\n",
            "train loss:0.00016036032587377866\n",
            "train loss:0.0012098410654094436\n",
            "train loss:0.0006612877960332884\n",
            "train loss:0.0011098813290764218\n",
            "train loss:3.1700018676947824e-05\n",
            "train loss:0.05729699105415759\n",
            "train loss:0.0006060014331869454\n",
            "train loss:0.0005680201671264322\n",
            "train loss:0.0015628789242458565\n",
            "train loss:0.0024507705270425516\n",
            "train loss:0.003865551797072762\n",
            "train loss:0.00121907951915522\n",
            "train loss:0.002233419701706512\n",
            "train loss:0.0009693306715301708\n",
            "train loss:0.0013390483857005963\n",
            "train loss:0.001380221478350939\n",
            "train loss:0.008359380965888\n",
            "train loss:0.00028426348483121097\n",
            "train loss:0.03079841856474876\n",
            "train loss:0.0017417897461895187\n",
            "train loss:0.0016544913023532905\n",
            "train loss:0.0021159008175455516\n",
            "train loss:0.0031216878841481\n",
            "train loss:0.009038167083787196\n",
            "train loss:0.005725188539463558\n",
            "train loss:0.004754397288022908\n",
            "train loss:0.00263353968662722\n",
            "train loss:0.003429267922057068\n",
            "train loss:0.003024509195471701\n",
            "train loss:0.0006034728469114141\n",
            "train loss:0.0040275651729404435\n",
            "train loss:0.0011807644888610852\n",
            "train loss:0.003505676226279002\n",
            "train loss:0.0006040192648366731\n",
            "train loss:0.008832226955480322\n",
            "train loss:0.0005579995392471309\n",
            "train loss:0.001372038534044425\n",
            "train loss:0.00711851005221029\n",
            "train loss:0.002173418919021561\n",
            "train loss:0.00025095052966402873\n",
            "train loss:0.00019408598852110794\n",
            "train loss:0.0020327957167785918\n",
            "train loss:0.00218988896008172\n",
            "train loss:0.002693884348695079\n",
            "train loss:0.0035110199264516847\n",
            "train loss:0.003944675668647676\n",
            "train loss:0.005493820592437982\n",
            "train loss:0.0030552218212338868\n",
            "train loss:0.0019895811749408437\n",
            "train loss:0.0010209979275284766\n",
            "train loss:0.0007626580317469815\n",
            "train loss:0.019878699118425186\n",
            "train loss:0.001517486483366535\n",
            "train loss:0.00023051071923867308\n",
            "train loss:0.004156167929138911\n",
            "train loss:0.0007672077046392952\n",
            "train loss:0.002436876765552672\n",
            "train loss:0.0008151761197983338\n",
            "train loss:0.0009588312030603896\n",
            "train loss:0.0014682595685141502\n",
            "train loss:0.001483807385801767\n",
            "train loss:0.0002721882204825233\n",
            "train loss:0.017902643212624032\n",
            "train loss:0.0010772901252639059\n",
            "train loss:0.0007187979008844246\n",
            "train loss:0.005548988078237861\n",
            "train loss:0.0007733888222466851\n",
            "train loss:0.0022003637009577943\n",
            "train loss:0.0015822535831567913\n",
            "train loss:0.002980463303683592\n",
            "train loss:0.0030291964857622642\n",
            "train loss:0.011388192240530094\n",
            "train loss:0.0011305675464034302\n",
            "train loss:0.002464147401763716\n",
            "train loss:0.0037971481677636725\n",
            "train loss:0.02000890137297249\n",
            "train loss:0.006116717171582043\n",
            "train loss:0.0005728775249545063\n",
            "train loss:0.0011952426244967785\n",
            "train loss:0.002553120069012498\n",
            "train loss:0.008447598912944762\n",
            "train loss:0.0012753897011301871\n",
            "train loss:0.011532393824700837\n",
            "train loss:0.001522769830983589\n",
            "train loss:0.0028496115678482924\n",
            "train loss:0.0019385420732460615\n",
            "train loss:0.008199885444223069\n",
            "train loss:0.001208623621843492\n",
            "train loss:0.000304898248819152\n",
            "train loss:0.0005247906140777879\n",
            "train loss:0.0025541057883074958\n",
            "train loss:0.026643690496341986\n",
            "train loss:0.01245895657598121\n",
            "train loss:0.0011139630683957673\n",
            "train loss:0.003498079969434625\n",
            "train loss:0.01069946151269257\n",
            "train loss:0.004367704047366291\n",
            "train loss:0.0011583033010709514\n",
            "train loss:0.012242841571602301\n",
            "train loss:0.0016599712682688933\n",
            "train loss:0.001945625746900945\n",
            "train loss:0.010957485140900482\n",
            "train loss:0.0034637492928280204\n",
            "train loss:0.003331190950995596\n",
            "train loss:0.0017433658408359044\n",
            "train loss:0.0070463856309851535\n",
            "train loss:0.008824655020649571\n",
            "train loss:0.0013719613925248977\n",
            "train loss:0.008572691199038633\n",
            "train loss:0.0028775779622871992\n",
            "train loss:0.014346506123943854\n",
            "train loss:0.0012927466105513293\n",
            "train loss:0.0009795569494658214\n",
            "train loss:0.004837898089230756\n",
            "train loss:0.0009628170994144333\n",
            "train loss:0.030307707831644118\n",
            "train loss:0.0019521960574596117\n",
            "train loss:0.00237927246701845\n",
            "train loss:0.0008699098550672226\n",
            "train loss:0.0048162779066128385\n",
            "train loss:0.0015522820640751145\n",
            "train loss:0.007070492851358082\n",
            "train loss:0.0001350168731692327\n",
            "train loss:0.004566814581838031\n",
            "train loss:0.010188279679732239\n",
            "train loss:0.001863410971500808\n",
            "train loss:0.0027683156203440213\n",
            "train loss:0.0015367259551288788\n",
            "train loss:0.0013048562568551058\n",
            "train loss:0.0032612318743531626\n",
            "train loss:0.0004005008371046857\n",
            "train loss:0.0013973007963806786\n",
            "train loss:0.0021236623171457165\n",
            "train loss:0.004985687701772888\n",
            "train loss:0.00635605855338553\n",
            "train loss:0.0005164273781282316\n",
            "train loss:0.002367963832692886\n",
            "train loss:0.0053855269807704135\n",
            "train loss:0.00023039555054441704\n",
            "train loss:0.00037617713462075074\n",
            "train loss:0.001058265688345801\n",
            "train loss:0.0005315814057747193\n",
            "train loss:0.000367617640453863\n",
            "train loss:0.006310329948130622\n",
            "train loss:0.002471892111696003\n",
            "train loss:0.0017163096168387277\n",
            "train loss:0.00239556417771031\n",
            "train loss:0.001076753958796027\n",
            "train loss:0.0017715144714944462\n",
            "train loss:0.0038854130251304076\n",
            "train loss:0.06951011061835598\n",
            "train loss:0.0022479267828661356\n",
            "train loss:0.002276688609711842\n",
            "train loss:0.002598789774188359\n",
            "train loss:0.0012847322551654983\n",
            "train loss:0.0016410883467543025\n",
            "train loss:0.0013294885353552894\n",
            "train loss:0.0005396339554514044\n",
            "train loss:0.000902639109096817\n",
            "train loss:0.00025111537499046327\n",
            "train loss:0.000313392483255458\n",
            "train loss:0.000365507704201132\n",
            "train loss:0.004106406210017644\n",
            "train loss:0.005437910389019239\n",
            "train loss:0.007754159553951337\n",
            "train loss:0.0017219045600665864\n",
            "train loss:0.00195516686606297\n",
            "train loss:0.004564972881779847\n",
            "train loss:0.0021501563969141117\n",
            "train loss:0.001910667390882001\n",
            "=== epoch:15, train acc:1.0, test acc:0.987 ===\n",
            "train loss:0.0009144953929641585\n",
            "train loss:0.0010859020738764338\n",
            "train loss:0.0005624286659730059\n",
            "train loss:0.0017926960706635365\n",
            "train loss:0.0006697877530033798\n",
            "train loss:0.0018930325930994114\n",
            "train loss:0.0019961887420370432\n",
            "train loss:0.0014149368175571959\n",
            "train loss:0.0011461785428236648\n",
            "train loss:0.0005605323606091976\n",
            "train loss:0.0003687250694264694\n",
            "train loss:0.009105920581094148\n",
            "train loss:7.999195556605547e-05\n",
            "train loss:0.0016285723175458967\n",
            "train loss:0.0003308286287268486\n",
            "train loss:0.000592775125299392\n",
            "train loss:0.01866129153780172\n",
            "train loss:0.0005266237363817389\n",
            "train loss:0.00346028846068109\n",
            "train loss:0.0009453569452510788\n",
            "train loss:0.0004797977323033492\n",
            "train loss:0.00560125069589375\n",
            "train loss:0.00595287896423718\n",
            "train loss:0.0007413946352315225\n",
            "train loss:0.0020002974525344234\n",
            "train loss:0.0004900278556404861\n",
            "train loss:0.007756641363777767\n",
            "train loss:0.01876877373055373\n",
            "train loss:0.009009065259449098\n",
            "train loss:0.00523240243380344\n",
            "train loss:0.004746588048713257\n",
            "train loss:0.00030609007304725484\n",
            "train loss:0.003659403420054162\n",
            "train loss:0.00192754613184594\n",
            "train loss:0.002617774360070768\n",
            "train loss:0.00275369514243559\n",
            "train loss:0.008231896452394465\n",
            "train loss:0.003625821014211816\n",
            "train loss:0.0002148172418647089\n",
            "train loss:0.004962550047169228\n",
            "train loss:0.0037714954267206967\n",
            "train loss:0.0018522633886186757\n",
            "train loss:0.005430495904548663\n",
            "train loss:0.00362395719355963\n",
            "train loss:0.002195891657019521\n",
            "train loss:0.00021749338409665718\n",
            "train loss:0.005355329018562518\n",
            "train loss:0.0005786921466392271\n",
            "train loss:0.0017258099463125993\n",
            "train loss:0.0015228336100978285\n",
            "train loss:0.0007227125651766023\n",
            "train loss:0.005428918781012777\n",
            "train loss:0.0009548894249795697\n",
            "train loss:0.0032351128708117127\n",
            "train loss:0.1428827605476341\n",
            "train loss:0.0030372141014501463\n",
            "train loss:0.0004158100620391004\n",
            "train loss:0.0011000223826616092\n",
            "train loss:0.04464002416052765\n",
            "train loss:0.002049080085197954\n",
            "train loss:0.0035735946326575768\n",
            "train loss:0.003316765119776245\n",
            "train loss:0.0012537870699833838\n",
            "train loss:0.002276200368144415\n",
            "train loss:0.0025568176834291747\n",
            "train loss:0.0018052718508796697\n",
            "train loss:0.0043114197523543545\n",
            "train loss:0.0021247753677847776\n",
            "train loss:0.0031416397838151615\n",
            "train loss:0.0008067272501111075\n",
            "train loss:0.0038810208540410985\n",
            "train loss:0.00107001953170822\n",
            "train loss:0.000897967354437792\n",
            "train loss:0.000790210443271763\n",
            "train loss:0.005839337790472271\n",
            "train loss:0.0022188771373659348\n",
            "train loss:0.00046771884760810084\n",
            "train loss:0.0022534573885908144\n",
            "train loss:0.003383716638626714\n",
            "train loss:0.0015922001712151165\n",
            "train loss:0.005273626071913391\n",
            "train loss:0.0001071749000580576\n",
            "train loss:0.0020185079875996562\n",
            "train loss:0.012111518052555705\n",
            "train loss:0.00014789982981233546\n",
            "train loss:0.008784222364012363\n",
            "train loss:0.006794586250797905\n",
            "train loss:0.010100378701299484\n",
            "train loss:0.0005126010522129146\n",
            "train loss:0.0036178285292655576\n",
            "train loss:0.018580412193257432\n",
            "train loss:0.002720490271898718\n",
            "train loss:0.0023869563008904306\n",
            "train loss:0.0024454523088439407\n",
            "train loss:0.0026247185704863724\n",
            "train loss:0.004640615205150276\n",
            "train loss:0.001960479664909507\n",
            "train loss:0.0010100055554735214\n",
            "train loss:0.004091588724850988\n",
            "train loss:0.011343261827976615\n",
            "train loss:0.0004480845804317258\n",
            "train loss:0.00173736962806209\n",
            "train loss:0.0007276258470860488\n",
            "train loss:0.00016477620769333825\n",
            "train loss:0.00560455607719854\n",
            "train loss:0.006926355548171293\n",
            "train loss:0.014513836887598814\n",
            "train loss:0.0017636844847782945\n",
            "train loss:0.001501202213838001\n",
            "train loss:6.385401395703247e-05\n",
            "train loss:0.0005294530975235644\n",
            "train loss:0.0007234401580540161\n",
            "train loss:0.0022051690728321265\n",
            "train loss:0.003709895043714927\n",
            "train loss:0.0027569785654075135\n",
            "train loss:0.012437174383117689\n",
            "train loss:0.0010787396012228482\n",
            "train loss:0.001223360634694388\n",
            "train loss:0.012505577287898577\n",
            "train loss:0.002606176912988722\n",
            "train loss:0.0004679313618176043\n",
            "train loss:0.002222031505712754\n",
            "train loss:0.001864613656926046\n",
            "train loss:0.009537304299082556\n",
            "train loss:0.0021834526358433647\n",
            "train loss:0.0012815091431489214\n",
            "train loss:0.00036277398372125397\n",
            "train loss:0.004237709451072944\n",
            "train loss:0.0006390881783399669\n",
            "train loss:0.001156137693395906\n",
            "train loss:0.0031748984431666074\n",
            "train loss:0.003768596388222089\n",
            "train loss:0.0013630238613557822\n",
            "train loss:0.00061512756916415\n",
            "train loss:0.001982088814318857\n",
            "train loss:0.008319531873364474\n",
            "train loss:0.0030815979727433483\n",
            "train loss:0.014641172672038539\n",
            "train loss:0.006186816778525544\n",
            "train loss:0.0008929238411862823\n",
            "train loss:0.0031966790361512855\n",
            "train loss:0.005849019758822075\n",
            "train loss:0.0026622095260125816\n",
            "train loss:0.005173263042176322\n",
            "train loss:0.0067645218909506664\n",
            "train loss:0.0009634503226088208\n",
            "train loss:0.004461314817741632\n",
            "train loss:0.0008005962526525165\n",
            "train loss:0.006203842556922951\n",
            "train loss:0.024477208963655257\n",
            "train loss:0.006966307248394592\n",
            "train loss:0.0019404740081837586\n",
            "train loss:0.003650421639303778\n",
            "train loss:0.009322287910890781\n",
            "train loss:0.0013850350435874006\n",
            "train loss:0.007618612902875493\n",
            "train loss:0.0012030624126302806\n",
            "train loss:0.0010691975884622668\n",
            "train loss:0.020828835039595255\n",
            "train loss:0.023053338864898944\n",
            "train loss:0.008155608648850274\n",
            "train loss:0.00954032219242289\n",
            "train loss:0.0014691599654928001\n",
            "train loss:0.004201119969374748\n",
            "train loss:0.01346063125832537\n",
            "train loss:0.00656479495868879\n",
            "train loss:0.016832522053945625\n",
            "train loss:0.0030934825365112996\n",
            "train loss:0.00449122472362727\n",
            "train loss:0.004750977556425195\n",
            "train loss:0.0008199427878733208\n",
            "train loss:0.001020120007589582\n",
            "train loss:0.013285656632440287\n",
            "train loss:0.0033515716231412506\n",
            "train loss:0.004345827790885974\n",
            "train loss:0.006103663361549592\n",
            "train loss:0.002447741695862324\n",
            "train loss:0.005433319612878763\n",
            "train loss:0.0007179014591699748\n",
            "train loss:0.004406359430115187\n",
            "train loss:0.0007386118979351906\n",
            "train loss:0.0019874327006456955\n",
            "train loss:0.001872577288972036\n",
            "train loss:0.005117338082458196\n",
            "train loss:0.000902589053272202\n",
            "train loss:0.004649152327390512\n",
            "train loss:0.0043427772863531685\n",
            "train loss:0.0003547928341594468\n",
            "train loss:0.0020215370718830315\n",
            "train loss:0.001126262508308045\n",
            "train loss:0.00012903521542989539\n",
            "train loss:0.00036916869843937677\n",
            "train loss:0.03702922294063396\n",
            "train loss:0.0012431499238051296\n",
            "train loss:0.003907252454279827\n",
            "train loss:0.007732011956977222\n",
            "train loss:0.010096397640222804\n",
            "train loss:0.00038065817513112024\n",
            "train loss:0.0016749487606314937\n",
            "train loss:0.01801536759504759\n",
            "train loss:0.0007963921704430895\n",
            "train loss:0.002322367692368178\n",
            "train loss:0.004540226772746182\n",
            "train loss:0.003010957471261883\n",
            "train loss:0.006729308961868968\n",
            "train loss:0.003811879555089796\n",
            "train loss:0.0018038672067717048\n",
            "train loss:0.0035873569662432324\n",
            "train loss:0.006526136226792347\n",
            "train loss:0.005386251866179321\n",
            "train loss:0.0033775007794579104\n",
            "train loss:0.002923116221720577\n",
            "train loss:0.0015613232162924107\n",
            "train loss:0.003851713168870349\n",
            "train loss:0.0027103919238698516\n",
            "train loss:0.0007945031218455511\n",
            "train loss:0.0024740572831422\n",
            "train loss:0.0028114171616244956\n",
            "train loss:0.00022949338401891142\n",
            "train loss:0.0021207810990709845\n",
            "train loss:0.0009187181177249261\n",
            "train loss:0.0012772144351544778\n",
            "train loss:0.0035925299168779734\n",
            "train loss:0.000646646258509809\n",
            "train loss:0.0005099611974533906\n",
            "train loss:0.007921377575542964\n",
            "train loss:0.0009266750611565747\n",
            "train loss:0.012609848202427715\n",
            "train loss:0.0007008087898994987\n",
            "train loss:0.0008068320342614845\n",
            "train loss:0.0029960390345028275\n",
            "train loss:0.007731650465037033\n",
            "train loss:0.00040162912050095353\n",
            "train loss:0.0033739138836038794\n",
            "train loss:0.005840821431297263\n",
            "train loss:0.001247230097055185\n",
            "train loss:0.0008218402283393314\n",
            "train loss:0.0039085805531200064\n",
            "train loss:0.00059810815884039\n",
            "train loss:0.009810992232138467\n",
            "train loss:0.004093360448112433\n",
            "train loss:0.0022719699125234817\n",
            "train loss:0.0029481878407542944\n",
            "train loss:0.0031151468375358567\n",
            "train loss:0.003041266618530872\n",
            "train loss:0.003599050779623558\n",
            "train loss:0.0008265500100025122\n",
            "train loss:0.009271268767010754\n",
            "train loss:0.00011771758426744649\n",
            "train loss:0.0030380719662164283\n",
            "train loss:0.003052168551499623\n",
            "train loss:0.0001465405995787415\n",
            "train loss:0.005857454295667187\n",
            "train loss:0.01004208920335293\n",
            "train loss:0.0034259773565182977\n",
            "train loss:0.0018895122549886186\n",
            "train loss:0.010722812664221997\n",
            "train loss:0.0008658363155122337\n",
            "train loss:0.0005855071236632028\n",
            "train loss:0.00012267556510985896\n",
            "train loss:0.0010723657398453166\n",
            "train loss:0.000619399803897342\n",
            "train loss:0.004346912687940077\n",
            "train loss:0.000652212323899076\n",
            "train loss:0.0021792881195328104\n",
            "train loss:0.06704999664760264\n",
            "train loss:0.0010346958942005944\n",
            "train loss:0.005324361045701197\n",
            "train loss:0.021072667692753594\n",
            "train loss:0.0007485706248223415\n",
            "train loss:0.0004927206342645342\n",
            "train loss:0.00216699403378344\n",
            "train loss:0.0008784934053671868\n",
            "train loss:0.0003471177424709706\n",
            "train loss:0.0014722519731067332\n",
            "train loss:0.00013164913584414487\n",
            "train loss:0.0012565092783344064\n",
            "train loss:0.007752769010755323\n",
            "train loss:0.0009067584008748448\n",
            "train loss:0.001018023650879524\n",
            "train loss:0.0005649082981178565\n",
            "train loss:0.02936544742744862\n",
            "train loss:0.00027989165828387575\n",
            "train loss:0.001062976780588225\n",
            "train loss:0.011402661956993753\n",
            "train loss:0.000492067128017245\n",
            "train loss:0.0013990147528861526\n",
            "train loss:0.00022568630552894983\n",
            "train loss:0.03434767990843271\n",
            "train loss:0.004973231492613888\n",
            "train loss:0.00041989941882416117\n",
            "train loss:0.0009935564814468351\n",
            "train loss:0.00018456898899343\n",
            "train loss:0.001813639808185453\n",
            "train loss:0.0014598484063568892\n",
            "train loss:0.00045819022986649376\n",
            "train loss:0.0007550194194365903\n",
            "train loss:0.0027963702090224147\n",
            "train loss:0.00014000797748637547\n",
            "train loss:0.00018044903467539627\n",
            "train loss:0.0021434792963257033\n",
            "train loss:0.004890688254573372\n",
            "train loss:0.011863471965502232\n",
            "train loss:0.0011390833297739704\n",
            "train loss:0.00035915553755690323\n",
            "train loss:0.05924263961295487\n",
            "train loss:0.004222831079941145\n",
            "train loss:0.025288505955119906\n",
            "train loss:0.002507829109812834\n",
            "train loss:0.0022225357443464737\n",
            "train loss:0.0012614194328866546\n",
            "train loss:0.0006890637842981817\n",
            "train loss:0.0024668953765901824\n",
            "train loss:0.0034751879893250674\n",
            "train loss:0.005332040942169679\n",
            "train loss:0.0035187504206414797\n",
            "train loss:0.02349820391100421\n",
            "train loss:0.0009468785715137011\n",
            "train loss:0.0012097777870305945\n",
            "train loss:0.0012491059519496375\n",
            "train loss:0.0006930587466476285\n",
            "train loss:0.0044406073918706775\n",
            "train loss:0.0020257595868907654\n",
            "train loss:0.0006834069107871147\n",
            "train loss:0.0015386564257567495\n",
            "train loss:0.002447235559137522\n",
            "train loss:0.0021271123466506466\n",
            "train loss:0.000571857012091415\n",
            "train loss:0.0005340863913775088\n",
            "train loss:0.0010988612914614262\n",
            "train loss:0.00023255566065946614\n",
            "train loss:0.0062308800193239585\n",
            "train loss:0.02584862456612325\n",
            "train loss:0.005090145100817841\n",
            "train loss:0.0013776189771729952\n",
            "train loss:0.0005433383481069788\n",
            "train loss:0.006733284145167473\n",
            "train loss:0.006202471520104366\n",
            "train loss:0.002197505059458576\n",
            "train loss:0.0008036321894587826\n",
            "train loss:0.015459163552304043\n",
            "train loss:0.0003161458387674945\n",
            "train loss:0.0005231372730997207\n",
            "train loss:0.0016279272465148087\n",
            "train loss:0.0008787484010727821\n",
            "train loss:0.001981232889288544\n",
            "train loss:0.0010671928483471271\n",
            "train loss:0.000794420476866137\n",
            "train loss:0.00035360570288683175\n",
            "train loss:0.004510872086107718\n",
            "train loss:0.006297127815897141\n",
            "train loss:0.002708547187105017\n",
            "train loss:0.0008413161936578213\n",
            "train loss:0.003327498199242983\n",
            "train loss:0.0027762510051580415\n",
            "train loss:0.001469168329806792\n",
            "train loss:0.00033722957330167635\n",
            "train loss:0.0057293741880512315\n",
            "train loss:0.0002420428034318315\n",
            "train loss:0.0007891578847252234\n",
            "train loss:0.0005283924617564353\n",
            "train loss:0.004309654673353132\n",
            "train loss:0.0005887796596066658\n",
            "train loss:0.003485364052929327\n",
            "train loss:0.0029777975579929755\n",
            "train loss:0.0007285054408738391\n",
            "train loss:0.0006461124821042701\n",
            "train loss:0.005159639415529611\n",
            "train loss:0.0017269185614802243\n",
            "train loss:0.0016116989857722069\n",
            "train loss:0.0023858759337154977\n",
            "train loss:0.0007452684564603217\n",
            "train loss:0.00015482376264080322\n",
            "train loss:0.0022848256621817685\n",
            "train loss:0.0011247487784843656\n",
            "train loss:9.369569353382914e-05\n",
            "train loss:0.00286405120513933\n",
            "train loss:8.540452712697816e-05\n",
            "train loss:0.00015998024179960803\n",
            "train loss:0.0003051759601862937\n",
            "train loss:0.0020236848211945013\n",
            "train loss:0.0003498830709100041\n",
            "train loss:0.002848360995752211\n",
            "train loss:0.004856855917243539\n",
            "train loss:0.003484688813057302\n",
            "train loss:0.0008267203474509445\n",
            "train loss:0.0018109462415906517\n",
            "train loss:0.0019109830225378128\n",
            "train loss:0.006785950336244823\n",
            "train loss:0.0007048240500157342\n",
            "train loss:0.0028151980641181198\n",
            "train loss:0.0019006443371971649\n",
            "train loss:0.0033778593507138343\n",
            "train loss:0.004266042514174053\n",
            "train loss:0.0019113599968453643\n",
            "train loss:0.009664783155095908\n",
            "train loss:0.0007354274301367605\n",
            "train loss:0.0008298687446739613\n",
            "train loss:0.003629592028950433\n",
            "train loss:0.0038500453516009774\n",
            "train loss:0.002940816722086268\n",
            "train loss:0.0008977419144725291\n",
            "train loss:0.0008530772744740004\n",
            "train loss:0.0224992360356763\n",
            "train loss:0.00011511786331780429\n",
            "train loss:0.0023315979617525686\n",
            "train loss:0.0025370684573237955\n",
            "train loss:0.0035773361744129047\n",
            "train loss:0.0025061869479736016\n",
            "train loss:0.0038947916333600422\n",
            "train loss:9.039738205622896e-05\n",
            "train loss:0.00021301907282337672\n",
            "train loss:0.0016739976855917962\n",
            "train loss:0.0004792481935562849\n",
            "train loss:0.0010040170229405052\n",
            "train loss:0.003790942067414273\n",
            "train loss:0.0005144791992772813\n",
            "train loss:0.000698161552594136\n",
            "train loss:0.0029102378417471624\n",
            "train loss:0.0018913972506457632\n",
            "train loss:9.957998451619465e-05\n",
            "train loss:0.0036445752883108628\n",
            "train loss:0.0018576254439587564\n",
            "train loss:0.001746721267801144\n",
            "train loss:0.001137505871882931\n",
            "train loss:0.0005681489765669457\n",
            "train loss:0.004153601155969384\n",
            "train loss:0.0009398428458699279\n",
            "train loss:0.0024748760015415316\n",
            "train loss:0.00155794598618319\n",
            "train loss:0.0025743438779642935\n",
            "train loss:0.0009307713747688208\n",
            "train loss:0.00011321230994653862\n",
            "train loss:0.001112955754296978\n",
            "train loss:0.0011959466942967735\n",
            "train loss:0.005667727977159592\n",
            "train loss:0.00153042664955967\n",
            "train loss:0.0005608349176519366\n",
            "train loss:0.0002579695382968682\n",
            "train loss:0.00506484098735414\n",
            "train loss:0.0013800778148393752\n",
            "train loss:0.0033324596973479527\n",
            "train loss:0.001261745665238951\n",
            "train loss:0.003376044012411721\n",
            "train loss:0.0017304906803594327\n",
            "train loss:0.001277469208230682\n",
            "train loss:0.0014658318949228948\n",
            "train loss:0.0007393004910358203\n",
            "train loss:0.0005074624452928274\n",
            "train loss:0.003168860636275908\n",
            "train loss:0.0003050297048604181\n",
            "train loss:0.0002448086526057295\n",
            "train loss:0.001975503290482299\n",
            "train loss:0.0004453099026120944\n",
            "train loss:0.0003776418013396388\n",
            "train loss:0.005266661397350966\n",
            "train loss:0.0003740123455431132\n",
            "train loss:0.004922719033179631\n",
            "train loss:6.481579744981902e-05\n",
            "train loss:0.0025313776292226696\n",
            "train loss:0.0003113932487004711\n",
            "train loss:0.00022017608497373789\n",
            "train loss:0.0036524081238129293\n",
            "train loss:0.00011414692193785283\n",
            "train loss:0.0015188931878464353\n",
            "train loss:0.00047808104276268705\n",
            "train loss:0.0005505351772727386\n",
            "train loss:0.0034565624771479763\n",
            "train loss:0.00033408327638164185\n",
            "train loss:0.0014825848317575755\n",
            "train loss:0.007331650908973725\n",
            "train loss:0.0023354051762132693\n",
            "train loss:0.004295053462159155\n",
            "train loss:0.00022304099301116413\n",
            "train loss:0.002692291574857913\n",
            "train loss:0.0002541865915892452\n",
            "train loss:0.003712518982234216\n",
            "train loss:0.00011692095880686851\n",
            "train loss:0.019212738914360202\n",
            "train loss:0.0016462536239819456\n",
            "train loss:0.004428871944160861\n",
            "train loss:0.004365597060506052\n",
            "train loss:0.01055893158739186\n",
            "train loss:0.002793842124364365\n",
            "train loss:0.0005314161749313321\n",
            "train loss:0.00053721464876253\n",
            "train loss:0.0015351561513240177\n",
            "train loss:0.007983355302288076\n",
            "train loss:0.0032474394188180392\n",
            "train loss:0.0004524599386316879\n",
            "train loss:0.002367656216479822\n",
            "train loss:0.0016920749417261183\n",
            "train loss:0.0003093629916428312\n",
            "train loss:0.0003134007636774875\n",
            "train loss:0.0008685192687758243\n",
            "train loss:0.010436431937803272\n",
            "train loss:0.000262675699493576\n",
            "train loss:0.00021660078289265837\n",
            "train loss:0.002096592934973494\n",
            "train loss:0.0009093400068989659\n",
            "train loss:0.0004515849148334903\n",
            "train loss:0.0004321014202292985\n",
            "train loss:0.0037019165237102596\n",
            "train loss:0.011499328493155889\n",
            "train loss:0.002605454675009781\n",
            "train loss:0.0015515584327106195\n",
            "train loss:0.0002978170259839334\n",
            "train loss:0.00033335870707592994\n",
            "train loss:0.0038063523261242373\n",
            "train loss:0.008146734996861377\n",
            "train loss:0.0014279974126319558\n",
            "train loss:0.0033162477734037\n",
            "train loss:0.006747000525952881\n",
            "train loss:0.0002118757694781997\n",
            "train loss:0.0005322397065294688\n",
            "train loss:0.00010811231151141665\n",
            "train loss:7.867593595804151e-05\n",
            "train loss:0.004264464021685973\n",
            "train loss:0.00035012399151654\n",
            "train loss:0.005067741087026062\n",
            "train loss:0.0010022097291052829\n",
            "train loss:0.0016962976812602015\n",
            "train loss:0.0011969760207643319\n",
            "train loss:0.0019167086717907164\n",
            "train loss:0.0011051016344233485\n",
            "train loss:0.0017204750772656264\n",
            "train loss:0.0001897121790634035\n",
            "train loss:0.0004233460925547243\n",
            "train loss:0.0004419855716062342\n",
            "train loss:0.00021964828038862312\n",
            "train loss:0.0031927300602548553\n",
            "train loss:0.0027221072617175175\n",
            "train loss:0.00013299131516591545\n",
            "train loss:0.09612736134327964\n",
            "train loss:0.0021488349200099576\n",
            "train loss:0.0024748717754379656\n",
            "train loss:0.012481423143093539\n",
            "train loss:0.0007381256468852396\n",
            "train loss:0.0038429854606577985\n",
            "train loss:0.0002795800118358526\n",
            "train loss:0.0030089279920137097\n",
            "train loss:0.0038060640723978963\n",
            "train loss:0.0012147970000975347\n",
            "train loss:0.0004172019774099038\n",
            "train loss:0.007653913652878839\n",
            "train loss:0.0001356617031613143\n",
            "train loss:0.00443746839909634\n",
            "train loss:0.0036138642549683603\n",
            "train loss:7.713617527469022e-05\n",
            "train loss:0.0026589454834596775\n",
            "train loss:0.00016173141444690155\n",
            "train loss:0.006482655672417074\n",
            "train loss:0.0016019385014622797\n",
            "train loss:0.00039189268892933927\n",
            "train loss:0.0009500612505625594\n",
            "train loss:0.0007499400817946024\n",
            "train loss:0.0010730414350364772\n",
            "train loss:0.0003315448111509397\n",
            "train loss:0.003017857799959032\n",
            "train loss:0.001516317494283004\n",
            "train loss:0.0003867808305331117\n",
            "train loss:0.0005045557066766337\n",
            "train loss:0.0004087502750904721\n",
            "train loss:0.0012395475223479604\n",
            "train loss:0.0012527496935677703\n",
            "train loss:0.00020189394236654637\n",
            "train loss:0.002005662812803962\n",
            "train loss:0.002066741138304616\n",
            "train loss:0.0005842232372315692\n",
            "train loss:0.006762116212504724\n",
            "train loss:0.0004602434008991275\n",
            "train loss:0.0004172839800597553\n",
            "train loss:0.00013077182170766606\n",
            "train loss:0.0005229715256576266\n",
            "train loss:0.0009564695004214137\n",
            "train loss:0.00023409025336767312\n",
            "train loss:0.00030838797532761227\n",
            "train loss:0.0027226121219540715\n",
            "train loss:0.005138588922900459\n",
            "train loss:0.004099044328950647\n",
            "train loss:0.0013890268530444333\n",
            "train loss:0.015101212197957433\n",
            "train loss:0.002551712045794263\n",
            "train loss:0.007781897522607639\n",
            "train loss:0.00013240788592674523\n",
            "train loss:0.00020913123251545222\n",
            "train loss:0.0011600840460697782\n",
            "train loss:0.0007679000884695302\n",
            "train loss:0.0006291004038680468\n",
            "train loss:0.0004277460762129543\n",
            "train loss:0.005267906651171121\n",
            "train loss:0.000201482769179875\n",
            "train loss:0.00019437960122593943\n",
            "train loss:0.0004947725031190762\n",
            "train loss:0.0006662377654134629\n",
            "train loss:0.0001891777693085983\n",
            "train loss:0.00018499314135085162\n",
            "train loss:0.00864131129109924\n",
            "train loss:0.00010046099936079762\n",
            "train loss:0.045672870390080854\n",
            "=== epoch:16, train acc:0.998, test acc:0.984 ===\n",
            "train loss:0.0009673816211332513\n",
            "train loss:0.0007230641143264026\n",
            "train loss:0.0004496997963474593\n",
            "train loss:0.0005656050181418974\n",
            "train loss:0.001945614673995994\n",
            "train loss:0.0014959007847762038\n",
            "train loss:0.002317810400404742\n",
            "train loss:0.0017559597879672046\n",
            "train loss:0.00048048224744509405\n",
            "train loss:0.003397279351214341\n",
            "train loss:0.0004230146483759341\n",
            "train loss:0.0015886183998220604\n",
            "train loss:0.0013464140210419642\n",
            "train loss:0.0009384038229302673\n",
            "train loss:0.004465535293522557\n",
            "train loss:0.0017605437136074462\n",
            "train loss:0.03811874433611524\n",
            "train loss:0.0073101262367783046\n",
            "train loss:0.0002361171101273743\n",
            "train loss:0.003397570063401526\n",
            "train loss:0.055885312547189446\n",
            "train loss:0.00037847175943910656\n",
            "train loss:0.0011551037676478658\n",
            "train loss:0.0008083340325271876\n",
            "train loss:0.001791101020350532\n",
            "train loss:0.006654678886545679\n",
            "train loss:0.028805327174940283\n",
            "train loss:0.0011049651578664914\n",
            "train loss:0.0006630853800369564\n",
            "train loss:0.0004241360277582561\n",
            "train loss:0.00019051303143696074\n",
            "train loss:0.0023342803084439243\n",
            "train loss:0.0029592300409925594\n",
            "train loss:0.000573772943089039\n",
            "train loss:0.0007500035139691463\n",
            "train loss:0.00046234098427231854\n",
            "train loss:8.941662111004549e-05\n",
            "train loss:0.00021069989981751928\n",
            "train loss:0.001556612632805328\n",
            "train loss:0.007443282717551146\n",
            "train loss:0.004736896172692497\n",
            "train loss:0.0003884314304183834\n",
            "train loss:0.004485063403298646\n",
            "train loss:0.001287435799562507\n",
            "train loss:0.0007671130497217795\n",
            "train loss:0.0003269411384620117\n",
            "train loss:0.0004332477177535437\n",
            "train loss:0.00032994506304229274\n",
            "train loss:0.005291102764227835\n",
            "train loss:0.008579496370371894\n",
            "train loss:0.006280881117354741\n",
            "train loss:0.00014920773161015584\n",
            "train loss:0.004524928754023153\n",
            "train loss:0.00028532314966624335\n",
            "train loss:0.0004859643507688683\n",
            "train loss:0.00043798452714137627\n",
            "train loss:0.0005244503470820584\n",
            "train loss:0.0004217843340627399\n",
            "train loss:0.0012535928889272979\n",
            "train loss:0.0019459547903849489\n",
            "train loss:0.0008131115154767018\n",
            "train loss:0.0028387718749085717\n",
            "train loss:0.0023238228638636717\n",
            "train loss:0.009412410999337524\n",
            "train loss:0.0027534903182024695\n",
            "train loss:0.0008943363949157414\n",
            "train loss:0.005523219866010651\n",
            "train loss:0.0012507237324669025\n",
            "train loss:0.0004172891139930902\n",
            "train loss:0.0017403853456503396\n",
            "train loss:0.001517714887793683\n",
            "train loss:0.0015405903498782914\n",
            "train loss:0.00038106502954069767\n",
            "train loss:0.0001449100770785249\n",
            "train loss:0.002308825991501455\n",
            "train loss:0.0012287281252752198\n",
            "train loss:0.00012086238472117436\n",
            "train loss:0.01026484848084238\n",
            "train loss:0.0006683322170660103\n",
            "train loss:0.00470400209418152\n",
            "train loss:0.002293632964015682\n",
            "train loss:0.0007124758316053023\n",
            "train loss:0.0041275214723964756\n",
            "train loss:0.00517406757562109\n",
            "train loss:0.002419009530978008\n",
            "train loss:0.003578985175576951\n",
            "train loss:0.003484637629689558\n",
            "train loss:0.0002652005127469013\n",
            "train loss:0.0031945872437851856\n",
            "train loss:0.0007798118716899942\n",
            "train loss:0.00034118835600369297\n",
            "train loss:0.0005886173838316824\n",
            "train loss:0.004425043391154286\n",
            "train loss:0.0003098601745065108\n",
            "train loss:0.0002678313088297224\n",
            "train loss:0.0015732873926512076\n",
            "train loss:0.0001831138300383017\n",
            "train loss:0.0014523190719487851\n",
            "train loss:0.0018433225897186338\n",
            "train loss:0.0033115198686472086\n",
            "train loss:0.002199800987050973\n",
            "train loss:0.0021664724728897343\n",
            "train loss:0.0029017475670656185\n",
            "train loss:0.0010373405470036452\n",
            "train loss:0.0015491785932069335\n",
            "train loss:0.0038927364171117396\n",
            "train loss:0.0021722977107892496\n",
            "train loss:0.002351527187038799\n",
            "train loss:0.0005775222373622644\n",
            "train loss:0.0007272024434577875\n",
            "train loss:0.0018715464217254085\n",
            "train loss:0.0012121528050106493\n",
            "train loss:0.002904969632995502\n",
            "train loss:0.00402066310027518\n",
            "train loss:0.002094041972667915\n",
            "train loss:0.002191215240843826\n",
            "train loss:0.0009380192478942309\n",
            "train loss:0.0009723211419196299\n",
            "train loss:0.003672091576010284\n",
            "train loss:0.0016122561839286835\n",
            "train loss:0.0017555143920785388\n",
            "train loss:9.387817389320121e-05\n",
            "train loss:0.0003319047881849428\n",
            "train loss:0.0009363245291502715\n",
            "train loss:0.0004255792633363059\n",
            "train loss:0.00025654855284422184\n",
            "train loss:0.001060187430575609\n",
            "train loss:0.0010995483662854808\n",
            "train loss:0.00013065188749108154\n",
            "train loss:0.00039190474054521927\n",
            "train loss:0.0007472499036906271\n",
            "train loss:3.703373178068777e-05\n",
            "train loss:0.000575441377222295\n",
            "train loss:0.0016447637935578477\n",
            "train loss:0.00018322433389267667\n",
            "train loss:0.0015684351447857704\n",
            "train loss:0.008390957745565846\n",
            "train loss:0.006376642663244395\n",
            "train loss:0.0008188844167199253\n",
            "train loss:0.000592199451671276\n",
            "train loss:0.0009173204026218334\n",
            "train loss:0.000883774311442563\n",
            "train loss:0.0016902912796972424\n",
            "train loss:0.0027406592685609047\n",
            "train loss:0.0010324814681113167\n",
            "train loss:0.0010708452313973663\n",
            "train loss:0.0015621591298674209\n",
            "train loss:0.0015510882438203352\n",
            "train loss:0.001295950749175296\n",
            "train loss:0.005064966279614331\n",
            "train loss:0.0011355733717133725\n",
            "train loss:0.022445154230489442\n",
            "train loss:0.0015425011880221317\n",
            "train loss:0.0001311483750658883\n",
            "train loss:0.0011652888961117657\n",
            "train loss:0.0009005021958602648\n",
            "train loss:0.0035148937731210046\n",
            "train loss:0.002938113506891199\n",
            "train loss:0.0011180744866268802\n",
            "train loss:0.0004979289305656683\n",
            "train loss:0.0006387244032875273\n",
            "train loss:0.001375525657918428\n",
            "train loss:0.0008262074322894775\n",
            "train loss:0.0001921613735771161\n",
            "train loss:0.001730195640713616\n",
            "train loss:0.0008897189377295426\n",
            "train loss:0.0063357619909852406\n",
            "train loss:0.0005728117853714488\n",
            "train loss:0.0003802793210856441\n",
            "train loss:0.0008148099597306038\n",
            "train loss:0.0003224454571332271\n",
            "train loss:0.0019187126306211952\n",
            "train loss:0.0002029026954174933\n",
            "train loss:0.0007894301299755582\n",
            "train loss:0.004014668911618334\n",
            "train loss:0.00011390261796481229\n",
            "train loss:0.0011938687431866434\n",
            "train loss:2.0638160857773812e-05\n",
            "train loss:0.0005070431919975395\n",
            "train loss:0.0013357559696250331\n",
            "train loss:0.0005582976845323621\n",
            "train loss:0.0025760146723510374\n",
            "train loss:0.000495992030038355\n",
            "train loss:0.00047137950210824627\n",
            "train loss:0.0032668378921168447\n",
            "train loss:0.013912849794604712\n",
            "train loss:0.008589535578462643\n",
            "train loss:0.0008393585311817568\n",
            "train loss:0.003687141651314139\n",
            "train loss:0.0005438395088585574\n",
            "train loss:0.005040724653419256\n",
            "train loss:0.0014929627312407349\n",
            "train loss:0.004374054224673849\n",
            "train loss:0.0019770703764269092\n",
            "train loss:0.00018246640506379668\n",
            "train loss:6.868506118946832e-05\n",
            "train loss:0.00030742902084039697\n",
            "train loss:0.002363152635821241\n",
            "train loss:0.00031681596959666383\n",
            "train loss:0.003641899399454291\n",
            "train loss:0.0010540605774410653\n",
            "train loss:0.0024111150502901142\n",
            "train loss:0.0017290243292920613\n",
            "train loss:0.0026900563313221547\n",
            "train loss:0.00017055556150367867\n",
            "train loss:0.0015725220306668812\n",
            "train loss:0.00040326721727491585\n",
            "train loss:0.015694217799675853\n",
            "train loss:0.006253615077505212\n",
            "train loss:0.0002486114095119794\n",
            "train loss:0.00016039004569646674\n",
            "train loss:0.001276623783880289\n",
            "train loss:0.0012997527879199436\n",
            "train loss:0.0011442344940944282\n",
            "train loss:0.0034273880669010636\n",
            "train loss:0.013665978588970628\n",
            "train loss:0.004719390666584122\n",
            "train loss:0.0018151636108145565\n",
            "train loss:0.042902603679734475\n",
            "train loss:0.0008251186903356272\n",
            "train loss:0.012667308262401034\n",
            "train loss:0.0006711197182518669\n",
            "train loss:0.0008749711049437948\n",
            "train loss:0.011248440105552156\n",
            "train loss:0.0005738430494579616\n",
            "train loss:0.0007223827034136415\n",
            "train loss:0.007610380256693376\n",
            "train loss:0.0027817226821378886\n",
            "train loss:0.0003674166236392014\n",
            "train loss:0.00015939853149251042\n",
            "train loss:0.00031046366358242954\n",
            "train loss:0.007624298566701021\n",
            "train loss:0.0005816779742777397\n",
            "train loss:0.0013298314021052702\n",
            "train loss:0.0039272851607597475\n",
            "train loss:0.0007531587383848554\n",
            "train loss:0.00391522867988851\n",
            "train loss:0.001406710960984831\n",
            "train loss:0.052378349029762114\n",
            "train loss:0.0014833352225217564\n",
            "train loss:0.0015330093559392686\n",
            "train loss:0.0008247602277554094\n",
            "train loss:0.00051069203311019\n",
            "train loss:0.001940141567248748\n",
            "train loss:0.008999919447999927\n",
            "train loss:0.02510505251421984\n",
            "train loss:0.0030755833478161593\n",
            "train loss:0.0015749539043360785\n",
            "train loss:0.0038102874853358365\n",
            "train loss:0.004081311114480413\n",
            "train loss:0.003702590663777521\n",
            "train loss:0.0013455891159135003\n",
            "train loss:0.002887201403043954\n",
            "train loss:0.0042980901932774965\n",
            "train loss:0.0010365079004262883\n",
            "train loss:0.0260440497881796\n",
            "train loss:0.0003880383217796701\n",
            "train loss:0.000957134010316795\n",
            "train loss:0.00028153944299988317\n",
            "train loss:0.0002183902209641846\n",
            "train loss:0.011058442344840077\n",
            "train loss:0.0019113822939403234\n",
            "train loss:0.0010503179748014724\n",
            "train loss:0.0006038704978831935\n",
            "train loss:0.002411338156072204\n",
            "train loss:0.0003732164854619512\n",
            "train loss:0.0034051698368911414\n",
            "train loss:0.009423726028867024\n",
            "train loss:0.000754340869363176\n",
            "train loss:0.0020741182241226504\n",
            "train loss:0.0034190762173648757\n",
            "train loss:0.00014036118663714062\n",
            "train loss:0.00032371421597734816\n",
            "train loss:0.07853819063816908\n",
            "train loss:0.029154203185227857\n",
            "train loss:0.020734130717403768\n",
            "train loss:0.00030884832914779276\n",
            "train loss:0.002407827883130266\n",
            "train loss:0.0005175250450507045\n",
            "train loss:0.005022695524783114\n",
            "train loss:4.807245589317848e-05\n",
            "train loss:0.00707322941138611\n",
            "train loss:0.006642937495646255\n",
            "train loss:0.0002579719233377584\n",
            "train loss:0.007679051678641466\n",
            "train loss:0.004117453685006481\n",
            "train loss:0.0021472493652353185\n",
            "train loss:0.0018569350620047586\n",
            "train loss:0.0004089222671636093\n",
            "train loss:0.00038722257770635183\n",
            "train loss:0.004228368514647851\n",
            "train loss:0.0020569095164308924\n",
            "train loss:0.0009112179719142388\n",
            "train loss:0.003667922763371666\n",
            "train loss:0.0015699056124449673\n",
            "train loss:0.0014753487022370196\n",
            "train loss:0.00012889292259586917\n",
            "train loss:0.0030526946705922505\n",
            "train loss:0.010815892888696133\n",
            "train loss:0.0029502419071404627\n",
            "train loss:0.0001893377940510309\n",
            "train loss:0.005331452383085517\n",
            "train loss:0.011712542989034846\n",
            "train loss:0.000920577219961084\n",
            "train loss:0.0002590157857550899\n",
            "train loss:0.002077379851637119\n",
            "train loss:0.004236774743394709\n",
            "train loss:8.700462560897181e-05\n",
            "train loss:0.000160405534843946\n",
            "train loss:0.005908177622971927\n",
            "train loss:0.0122119196261183\n",
            "train loss:0.00429705430658235\n",
            "train loss:0.0031468569851505553\n",
            "train loss:0.0011687740318751143\n",
            "train loss:0.0017188674034283925\n",
            "train loss:0.00041188556148678536\n",
            "train loss:0.0004445968701034551\n",
            "train loss:0.0017902275131659792\n",
            "train loss:0.006425720849868341\n",
            "train loss:0.00030963578372563013\n",
            "train loss:0.00019463594880344355\n",
            "train loss:0.0005581132178622559\n",
            "train loss:0.003799181012086988\n",
            "train loss:0.0014386053213418983\n",
            "train loss:0.00012857591829703812\n",
            "train loss:9.86260525029449e-05\n",
            "train loss:0.0008538537933119203\n",
            "train loss:0.00011569920101724413\n",
            "train loss:0.0005982928060123926\n",
            "train loss:0.0036124955831780153\n",
            "train loss:0.0044989920517866265\n",
            "train loss:0.00019887170508600967\n",
            "train loss:0.005926332493789523\n",
            "train loss:0.002028833272533906\n",
            "train loss:0.010967283616005992\n",
            "train loss:0.0008078633378887322\n",
            "train loss:0.0032072785942553333\n",
            "train loss:0.0018271569115312723\n",
            "train loss:0.00030504934330601523\n",
            "train loss:0.040273381716094424\n",
            "train loss:0.00021826384141687523\n",
            "train loss:0.0009059375826205217\n",
            "train loss:0.00036909217019095406\n",
            "train loss:0.07645374506147101\n",
            "train loss:0.0016943640455112834\n",
            "train loss:0.006490580408860777\n",
            "train loss:0.002653223922232001\n",
            "train loss:0.006196776676531499\n",
            "train loss:0.0020996913986825135\n",
            "train loss:0.006409403131111359\n",
            "train loss:0.016002489504265846\n",
            "train loss:0.007003634633855013\n",
            "train loss:0.0033814424453763973\n",
            "train loss:0.00205502331147562\n",
            "train loss:0.004927486126324743\n",
            "train loss:0.0006288135771046629\n",
            "train loss:0.0020449131095096073\n",
            "train loss:0.007743099464286116\n",
            "train loss:0.0031496798062321655\n",
            "train loss:0.00309579962489039\n",
            "train loss:0.001055208231363191\n",
            "train loss:0.007326672709371242\n",
            "train loss:0.007258532104601803\n",
            "train loss:0.004234642072832629\n",
            "train loss:0.0048101732714153815\n",
            "train loss:0.00013299592251346515\n",
            "train loss:0.0031937876169007466\n",
            "train loss:0.0045369965870376205\n",
            "train loss:0.0014344200018467964\n",
            "train loss:0.00089091151203474\n",
            "train loss:0.017785390486202153\n",
            "train loss:0.0011655767079797813\n",
            "train loss:0.004894033140567479\n",
            "train loss:0.0013066023176456687\n",
            "train loss:0.0015903992614591154\n",
            "train loss:0.006241820609844989\n",
            "train loss:0.0011547892486795494\n",
            "train loss:0.005424794475359814\n",
            "train loss:0.011953429957995062\n",
            "train loss:0.0031683019826728278\n",
            "train loss:0.007212119100356651\n",
            "train loss:0.0012732129640588147\n",
            "train loss:0.005262184528409737\n",
            "train loss:0.008052419605415565\n",
            "train loss:0.002493169898024274\n",
            "train loss:0.002961177628472587\n",
            "train loss:0.00807623888297221\n",
            "train loss:0.003752258186589788\n",
            "train loss:0.00520613487847518\n",
            "train loss:0.004170319755161551\n",
            "train loss:0.00028772577641131785\n",
            "train loss:0.002173362687610523\n",
            "train loss:0.015171122097667212\n",
            "train loss:0.0025511655654861676\n",
            "train loss:0.00716490001222273\n",
            "train loss:0.002839885707848039\n",
            "train loss:0.0029899604935470963\n",
            "train loss:0.00032035298379148256\n",
            "train loss:0.008090769185631104\n",
            "train loss:0.00039180400569050996\n",
            "train loss:0.0010448700970428757\n",
            "train loss:0.005284754088064931\n",
            "train loss:0.0029873865178454495\n",
            "train loss:0.0005717120092695455\n",
            "train loss:0.009915238699599531\n",
            "train loss:0.004041797968847737\n",
            "train loss:0.0018745259855942598\n",
            "train loss:0.00154895394643142\n",
            "train loss:0.0027090198912744653\n",
            "train loss:0.0022411054982917527\n",
            "train loss:0.0012180018747022362\n",
            "train loss:0.0013280020053879481\n",
            "train loss:0.001532210334556342\n",
            "train loss:0.008348600614572845\n",
            "train loss:0.0057388341056481265\n",
            "train loss:0.0012216728979029092\n",
            "train loss:0.0007302487229406612\n",
            "train loss:0.0010098049925471256\n",
            "train loss:0.0005223336465937178\n",
            "train loss:0.00022052232446853368\n",
            "train loss:0.0005831405648090762\n",
            "train loss:0.0014306582018886508\n",
            "train loss:0.003034799548953222\n",
            "train loss:0.0011233996881089847\n",
            "train loss:0.0022541330458670087\n",
            "train loss:0.0019238970994317258\n",
            "train loss:0.0009891053906874675\n",
            "train loss:0.0008393453860923221\n",
            "train loss:0.0033907437889258885\n",
            "train loss:0.005607059924372777\n",
            "train loss:0.000266977376672559\n",
            "train loss:0.001476711489872985\n",
            "train loss:0.0051840899332585315\n",
            "train loss:0.014500821461492593\n",
            "train loss:0.00030204746203039404\n",
            "train loss:0.0006953976813020697\n",
            "train loss:0.009987472367607175\n",
            "train loss:0.000717020280716732\n",
            "train loss:0.001261597400288071\n",
            "train loss:0.00189740748304464\n",
            "train loss:0.004757407685386928\n",
            "train loss:0.00039589038337842176\n",
            "train loss:0.0014459995871020323\n",
            "train loss:0.0011510656333232993\n",
            "train loss:0.0018131792279418195\n",
            "train loss:0.00033075024685247215\n",
            "train loss:0.098152426392129\n",
            "train loss:0.0036179945769941224\n",
            "train loss:0.000293380604085262\n",
            "train loss:0.00608272703169834\n",
            "train loss:0.0030070498944296748\n",
            "train loss:0.0022316793219286342\n",
            "train loss:0.0021579103807185516\n",
            "train loss:0.0011736611120290747\n",
            "train loss:0.0010004563969819495\n",
            "train loss:0.001745180906982244\n",
            "train loss:0.004959530485756902\n",
            "train loss:0.0016563554918012783\n",
            "train loss:0.002201552417697043\n",
            "train loss:0.0015469516400399546\n",
            "train loss:0.001474767107233933\n",
            "train loss:0.0029501699860311217\n",
            "train loss:0.0014035086888637438\n",
            "train loss:0.001133055831143121\n",
            "train loss:0.0017622391567667253\n",
            "train loss:0.0016758713190749828\n",
            "train loss:0.01571955486956793\n",
            "train loss:0.0024061680152760627\n",
            "train loss:0.00019421316529092604\n",
            "train loss:0.0013902351951904203\n",
            "train loss:0.026100548503164362\n",
            "train loss:0.0015479845848441589\n",
            "train loss:0.005857379253416882\n",
            "train loss:0.000271391298024309\n",
            "train loss:0.0011416809132871947\n",
            "train loss:0.0005786941980435501\n",
            "train loss:0.00119629224284214\n",
            "train loss:0.0008480705667155715\n",
            "train loss:0.000595545793362664\n",
            "train loss:0.005776430460184183\n",
            "train loss:0.001813857703170087\n",
            "train loss:0.0006242494273912642\n",
            "train loss:0.01889665588589836\n",
            "train loss:0.000941684008274665\n",
            "train loss:0.0026156087498123443\n",
            "train loss:0.00027330833604859677\n",
            "train loss:0.006336684040464089\n",
            "train loss:0.00019595323331734836\n",
            "train loss:0.0005520816440828464\n",
            "train loss:0.00021075059756487928\n",
            "train loss:0.008793972560786513\n",
            "train loss:0.0015102815411636378\n",
            "train loss:0.0025230758814337477\n",
            "train loss:0.000373291706607422\n",
            "train loss:0.00028306459243235293\n",
            "train loss:0.0014509979874573475\n",
            "train loss:0.0007089119628960594\n",
            "train loss:0.012041977071310703\n",
            "train loss:0.0013514462939583562\n",
            "train loss:0.0001558130049994944\n",
            "train loss:0.0009829743673640736\n",
            "train loss:0.0006839830731173939\n",
            "train loss:0.06304690845430183\n",
            "train loss:0.0017495116138211452\n",
            "train loss:0.0034100485238485983\n",
            "train loss:0.0021217340201065233\n",
            "train loss:0.020692486252078285\n",
            "train loss:0.005887429503774701\n",
            "train loss:0.00016281808138861968\n",
            "train loss:0.0031807030505389706\n",
            "train loss:0.0009550796260605835\n",
            "train loss:0.003102492736793575\n",
            "train loss:0.0025326579422814193\n",
            "train loss:0.00010366021765285343\n",
            "train loss:0.0013992380186352634\n",
            "train loss:0.0022732712368310746\n",
            "train loss:0.0024802753482954256\n",
            "train loss:0.009363313420305268\n",
            "train loss:0.0027256993043067094\n",
            "train loss:8.734108046905808e-05\n",
            "train loss:0.022325880111198848\n",
            "train loss:0.0019179428198400515\n",
            "train loss:0.00011834782734200687\n",
            "train loss:0.004486048477813292\n",
            "train loss:0.004926433024188625\n",
            "train loss:0.00030160855483606303\n",
            "train loss:0.0018866460203959586\n",
            "train loss:0.0005658805972040522\n",
            "train loss:0.0019449238193125174\n",
            "train loss:0.003285639423667384\n",
            "train loss:0.001340652145377642\n",
            "train loss:0.005575974896493153\n",
            "train loss:0.0011065161340409744\n",
            "train loss:0.001490149861848791\n",
            "train loss:0.023143732294018938\n",
            "train loss:0.013970072527321974\n",
            "train loss:0.00347460999188119\n",
            "train loss:0.0013926041555982673\n",
            "train loss:0.0006577282743481743\n",
            "train loss:0.0027091213906800765\n",
            "train loss:0.0003235421884726104\n",
            "train loss:0.001624117167316999\n",
            "train loss:0.03079181189672986\n",
            "train loss:0.009734541687307398\n",
            "train loss:0.0034363119674765963\n",
            "train loss:0.00047053728618693893\n",
            "train loss:0.0014649141919107654\n",
            "train loss:0.0016627150692782992\n",
            "train loss:0.0013064222492826768\n",
            "train loss:0.0034402331084466536\n",
            "train loss:0.0036022190756718453\n",
            "train loss:0.005488285671977999\n",
            "train loss:0.0012342459342181721\n",
            "train loss:0.00019757409097830722\n",
            "train loss:0.001281211246031602\n",
            "train loss:0.00883062068552914\n",
            "train loss:0.0034656865333117736\n",
            "train loss:0.0026179550755288244\n",
            "train loss:0.003923988492784861\n",
            "train loss:0.003665124254844425\n",
            "train loss:0.00046616309348588366\n",
            "train loss:0.009566250551518284\n",
            "train loss:0.00573868189311716\n",
            "train loss:0.0005893302198066355\n",
            "train loss:3.989264540969683e-05\n",
            "train loss:0.0006116172028083739\n",
            "train loss:0.0016450946936317924\n",
            "train loss:0.0037472674080035757\n",
            "train loss:0.00036612563157141883\n",
            "train loss:0.0017034899598967045\n",
            "train loss:0.00239599735747029\n",
            "train loss:0.0007534783455518801\n",
            "train loss:0.0023070124386027663\n",
            "train loss:0.0016865138208224484\n",
            "train loss:0.0001129763069915233\n",
            "train loss:0.0039543723385375516\n",
            "train loss:0.0011602100244381102\n",
            "train loss:0.003747193784824997\n",
            "train loss:0.0018394250728349642\n",
            "train loss:0.0015804804609551991\n",
            "train loss:0.0013790736392138856\n",
            "train loss:7.843909541279133e-05\n",
            "train loss:0.00493241201480018\n",
            "train loss:0.0015921046046769346\n",
            "train loss:0.0007827077641085003\n",
            "train loss:0.0011762753265785126\n",
            "train loss:0.000639971553764761\n",
            "train loss:5.272882634021753e-05\n",
            "train loss:0.0006694820345437961\n",
            "train loss:0.000681429760680429\n",
            "train loss:0.004269879821585328\n",
            "train loss:0.004012091590442568\n",
            "train loss:0.006866410627778573\n",
            "train loss:0.0005773044336017067\n",
            "train loss:9.358740554675488e-05\n",
            "train loss:0.00022973799170127593\n",
            "train loss:0.0003357296973567354\n",
            "train loss:0.00021922249075697535\n",
            "train loss:0.0010456212511302855\n",
            "train loss:0.0019291131902872951\n",
            "=== epoch:17, train acc:0.999, test acc:0.99 ===\n",
            "train loss:0.0014617378806238968\n",
            "train loss:0.0009000422414270226\n",
            "train loss:0.007785335435638449\n",
            "train loss:0.0006350950167671776\n",
            "train loss:0.0018033342144060033\n",
            "train loss:0.0006287476917828476\n",
            "train loss:0.0002122185503563528\n",
            "train loss:0.0023745538408445318\n",
            "train loss:0.001068255859558612\n",
            "train loss:0.00025601133548903315\n",
            "train loss:0.002940453443361289\n",
            "train loss:0.0008756249216454443\n",
            "train loss:0.00019675865325679228\n",
            "train loss:0.0011261498321120584\n",
            "train loss:0.00033384914161259285\n",
            "train loss:0.0022044396726203265\n",
            "train loss:0.0047197917158111\n",
            "train loss:0.0033746000965154737\n",
            "train loss:0.0009539337793954355\n",
            "train loss:0.0003983669073526557\n",
            "train loss:0.0025174202243525064\n",
            "train loss:0.001915484431395272\n",
            "train loss:0.003265288831343572\n",
            "train loss:0.0012449881457257447\n",
            "train loss:0.002555631744873647\n",
            "train loss:0.0033729451292753587\n",
            "train loss:0.00027802533380071363\n",
            "train loss:0.00028485420263800855\n",
            "train loss:0.0009278108963068159\n",
            "train loss:0.0018149253255221973\n",
            "train loss:0.001278113594874957\n",
            "train loss:0.006135182486847693\n",
            "train loss:0.0007710881110753537\n",
            "train loss:0.0002188257203246525\n",
            "train loss:0.0016922793552049103\n",
            "train loss:0.0007611628512171596\n",
            "train loss:0.0017492327064570256\n",
            "train loss:0.0002593028609185257\n",
            "train loss:3.2714161554545036e-05\n",
            "train loss:0.0015584871371900285\n",
            "train loss:0.00011340444591427197\n",
            "train loss:0.003969194281889204\n",
            "train loss:0.0025769417587858928\n",
            "train loss:0.00264194527356168\n",
            "train loss:0.0002800053257903654\n",
            "train loss:4.975582749851256e-05\n",
            "train loss:0.0027223185393934167\n",
            "train loss:0.0009161076858755546\n",
            "train loss:6.580479903000035e-05\n",
            "train loss:0.001099657856063032\n",
            "train loss:0.036100952746417087\n",
            "train loss:4.4409399125644266e-05\n",
            "train loss:5.838483424182292e-05\n",
            "train loss:0.00014436947562610156\n",
            "train loss:0.0004671900060190108\n",
            "train loss:0.0011793349354210078\n",
            "train loss:0.0021949618202444943\n",
            "train loss:0.0023232678396679167\n",
            "train loss:0.0018359562883319147\n",
            "train loss:0.009380747403063399\n",
            "train loss:0.013061015667362367\n",
            "train loss:0.0005229634192577285\n",
            "train loss:0.0011191685742669769\n",
            "train loss:0.00045723451322401075\n",
            "train loss:0.0010204857742891732\n",
            "train loss:0.0022992301288693507\n",
            "train loss:0.00027430678093251477\n",
            "train loss:0.0015321708557350072\n",
            "train loss:0.0073036178353766655\n",
            "train loss:0.0017292757984371668\n",
            "train loss:0.0026265003663444703\n",
            "train loss:0.0006397112167183222\n",
            "train loss:0.00734464578372666\n",
            "train loss:0.0028050280610532547\n",
            "train loss:0.0008477473503683171\n",
            "train loss:0.0003908652739040879\n",
            "train loss:0.00011170195091236672\n",
            "train loss:0.0017792803643954741\n",
            "train loss:0.015718890115700622\n",
            "train loss:0.002088043731888708\n",
            "train loss:0.0021893275957809376\n",
            "train loss:0.003263439538841909\n",
            "train loss:0.006693592432025377\n",
            "train loss:7.7594822935746e-05\n",
            "train loss:0.0011675956429385511\n",
            "train loss:0.0018076024278816539\n",
            "train loss:0.004722641143466394\n",
            "train loss:0.0021786217476039123\n",
            "train loss:0.0039096852858266\n",
            "train loss:0.0028398682186424017\n",
            "train loss:0.01078309217505357\n",
            "train loss:7.72055283321664e-05\n",
            "train loss:0.0006734555883639312\n",
            "train loss:7.019448558981512e-05\n",
            "train loss:0.0025535345303781885\n",
            "train loss:0.0006437942005188625\n",
            "train loss:0.0011862687991966185\n",
            "train loss:0.0008128198941713098\n",
            "train loss:0.019214990865630194\n",
            "train loss:0.001470886736894013\n",
            "train loss:0.003615238705632\n",
            "train loss:0.0037238128716743724\n",
            "train loss:0.0010765128782744742\n",
            "train loss:0.002960693218889827\n",
            "train loss:0.00034499598991634704\n",
            "train loss:0.0005248845738400955\n",
            "train loss:0.002357742273522229\n",
            "train loss:0.0006922682792231426\n",
            "train loss:0.0002300020185158499\n",
            "train loss:0.004724776988232305\n",
            "train loss:0.00010613944020610043\n",
            "train loss:0.0002842650626554449\n",
            "train loss:0.00043667684147470756\n",
            "train loss:0.0012165677314099658\n",
            "train loss:0.0005025772418469312\n",
            "train loss:0.0010677174011577183\n",
            "train loss:0.00022995121385014454\n",
            "train loss:0.002302397192340588\n",
            "train loss:0.016681350069663425\n",
            "train loss:0.006161270629413672\n",
            "train loss:0.0006441973557669674\n",
            "train loss:0.0007444843219394137\n",
            "train loss:0.00437849679019292\n",
            "train loss:0.0008544701549625247\n",
            "train loss:0.00031984862039461173\n",
            "train loss:0.00019062099196320801\n",
            "train loss:0.00046635721917555925\n",
            "train loss:0.009607994106525746\n",
            "train loss:0.0008131258111686219\n",
            "train loss:0.003972410338468966\n",
            "train loss:0.0012353773489075675\n",
            "train loss:0.0005965096128858041\n",
            "train loss:0.0003620309395372999\n",
            "train loss:0.0008720482738946205\n",
            "train loss:0.00531643069661164\n",
            "train loss:0.0016275115518989236\n",
            "train loss:0.0018414465156740992\n",
            "train loss:0.00212797192599212\n",
            "train loss:0.00021300142557116535\n",
            "train loss:0.0015350237710906904\n",
            "train loss:0.0011975094439584154\n",
            "train loss:0.00025044100241134544\n",
            "train loss:0.0013193753418538842\n",
            "train loss:0.000861192977027196\n",
            "train loss:0.0021487765280813823\n",
            "train loss:0.0023209045806417343\n",
            "train loss:0.0011693986973265122\n",
            "train loss:0.005639800195944574\n",
            "train loss:0.0009905438525140426\n",
            "train loss:0.00013565368436229184\n",
            "train loss:0.0011986527708978702\n",
            "train loss:0.00013299916626451647\n",
            "train loss:0.0017163112161200395\n",
            "train loss:0.001946232829138765\n",
            "train loss:0.0011871308563932265\n",
            "train loss:0.0001208873256399856\n",
            "train loss:0.0019785943253983764\n",
            "train loss:0.0016554982748064049\n",
            "train loss:0.00017038880492918707\n",
            "train loss:0.0003001760036062139\n",
            "train loss:0.00020454299214839235\n",
            "train loss:0.0003012169802124268\n",
            "train loss:0.010483079704755555\n",
            "train loss:0.00024445167986177817\n",
            "train loss:0.00016223562214186246\n",
            "train loss:0.0007266151827872476\n",
            "train loss:0.0003201081313602449\n",
            "train loss:0.0007804919029479657\n",
            "train loss:0.0004411664996494944\n",
            "train loss:0.00021486995240244287\n",
            "train loss:0.002769956693692954\n",
            "train loss:0.010738684723716434\n",
            "train loss:0.002227458742095969\n",
            "train loss:0.00029624147581892445\n",
            "train loss:0.0008444992257015313\n",
            "train loss:0.000738688590983054\n",
            "train loss:0.0068467612221310755\n",
            "train loss:0.00013034736819820582\n",
            "train loss:0.000942454385678145\n",
            "train loss:0.0005567740769571741\n",
            "train loss:0.001035774413535349\n",
            "train loss:0.0008536909631434643\n",
            "train loss:0.00017665066095240783\n",
            "train loss:0.001620573039207262\n",
            "train loss:0.00037551350473884535\n",
            "train loss:0.001085106146618855\n",
            "train loss:4.654113073842359e-05\n",
            "train loss:0.001808282636325515\n",
            "train loss:0.00023943346107985233\n",
            "train loss:0.00020261055235500043\n",
            "train loss:0.0007911413491176887\n",
            "train loss:0.00020900690019388615\n",
            "train loss:0.000857173594214369\n",
            "train loss:0.002794912129728383\n",
            "train loss:0.0005332137753804672\n",
            "train loss:0.005254566395478618\n",
            "train loss:0.00019504355791360236\n",
            "train loss:0.0007912977498102402\n",
            "train loss:0.00010314028917028813\n",
            "train loss:0.00013293482105502746\n",
            "train loss:8.455803664380413e-05\n",
            "train loss:0.001311590155222358\n",
            "train loss:0.0015602771981269676\n",
            "train loss:0.00021150241480160785\n",
            "train loss:0.0001886202267159055\n",
            "train loss:0.002441137950485122\n",
            "train loss:0.0007703722294062754\n",
            "train loss:0.0014608423795493314\n",
            "train loss:0.0002259451691321733\n",
            "train loss:0.0005457753920513474\n",
            "train loss:0.0005631602835999319\n",
            "train loss:0.004760235321819555\n",
            "train loss:0.0010909560106346502\n",
            "train loss:0.0003500411258166284\n",
            "train loss:0.0042237375100928525\n",
            "train loss:0.0008854758583658504\n",
            "train loss:0.00015979961089051308\n",
            "train loss:7.822105456149488e-05\n",
            "train loss:0.0003093574939670911\n",
            "train loss:0.0019478755443226485\n",
            "train loss:0.0013824588896585199\n",
            "train loss:0.0004548775014692542\n",
            "train loss:0.001657764817257729\n",
            "train loss:0.00014869119291430828\n",
            "train loss:0.0002633613959727625\n",
            "train loss:0.00012511902468651128\n",
            "train loss:0.0004919880775121383\n",
            "train loss:0.004644383007879573\n",
            "train loss:0.00011330907346972356\n",
            "train loss:0.0007766418197406478\n",
            "train loss:0.0027201645009326853\n",
            "train loss:0.0002744257923598422\n",
            "train loss:0.002068631783412477\n",
            "train loss:0.0023490155877194867\n",
            "train loss:0.0004364116876502962\n",
            "train loss:0.0004269268903510207\n",
            "train loss:0.0002464263598372159\n",
            "train loss:0.000974022259827297\n",
            "train loss:3.5973224892776455e-05\n",
            "train loss:0.003032797015756676\n",
            "train loss:0.00033762969746019186\n",
            "train loss:0.0005103163595177743\n",
            "train loss:0.00018269899224427583\n",
            "train loss:0.008560388465564355\n",
            "train loss:4.15030051039073e-05\n",
            "train loss:0.0013956553038808083\n",
            "train loss:0.00011036195149121238\n",
            "train loss:0.0008405506172018943\n",
            "train loss:0.00044974298463120696\n",
            "train loss:0.0005122235498120825\n",
            "train loss:0.0022140325879549914\n",
            "train loss:0.00041672803031777845\n",
            "train loss:0.00042575725223976924\n",
            "train loss:0.0021662397354743883\n",
            "train loss:0.00011636511874284316\n",
            "train loss:0.0018856897255989775\n",
            "train loss:0.0003062159854261765\n",
            "train loss:0.00024855270274555183\n",
            "train loss:0.00020763412023368913\n",
            "train loss:0.0004563337899316495\n",
            "train loss:0.0024784266380157485\n",
            "train loss:0.0009178342856562978\n",
            "train loss:0.00022701466737365058\n",
            "train loss:0.00017535580303613136\n",
            "train loss:0.00010862662445634216\n",
            "train loss:0.0011236868289462897\n",
            "train loss:0.0006742908029341221\n",
            "train loss:0.00018854698150108252\n",
            "train loss:0.001178445422637503\n",
            "train loss:0.0008096199420518335\n",
            "train loss:3.937400457912962e-05\n",
            "train loss:0.00026206456269776095\n",
            "train loss:0.0015838294816636362\n",
            "train loss:0.0001700675427210429\n",
            "train loss:0.0006907393671023199\n",
            "train loss:0.0008527538276063974\n",
            "train loss:0.002081005941142974\n",
            "train loss:0.0030868978360133153\n",
            "train loss:0.00026471490142361163\n",
            "train loss:0.00110669192366875\n",
            "train loss:0.00017188216697246818\n",
            "train loss:0.0014402466292916952\n",
            "train loss:0.0001730303187478314\n",
            "train loss:0.0034074009780748456\n",
            "train loss:0.0005986208045610367\n",
            "train loss:0.00022776167038255903\n",
            "train loss:0.002252324410839611\n",
            "train loss:0.00033094825310785197\n",
            "train loss:0.0008872844934050963\n",
            "train loss:0.0003150993417813223\n",
            "train loss:0.0007421754621168289\n",
            "train loss:8.148314381772901e-05\n",
            "train loss:0.0005347237390606474\n",
            "train loss:0.010007217935244379\n",
            "train loss:0.0014020428444732485\n",
            "train loss:0.0017876108917982269\n",
            "train loss:0.0010451403328006134\n",
            "train loss:0.002562396901792394\n",
            "train loss:0.00016865416338743944\n",
            "train loss:0.00042282225331197936\n",
            "train loss:0.0012002865136026089\n",
            "train loss:0.0032871466172627872\n",
            "train loss:0.00020902691573367578\n",
            "train loss:0.00010556713120771456\n",
            "train loss:0.0007302914683453243\n",
            "train loss:0.0005189961001022075\n",
            "train loss:0.002731770443996546\n",
            "train loss:0.0002567948218512002\n",
            "train loss:0.002888205345562683\n",
            "train loss:0.0017860661967273978\n",
            "train loss:0.0011219350570345343\n",
            "train loss:0.014199229747424434\n",
            "train loss:0.004657938763519509\n",
            "train loss:0.0003260457758440537\n",
            "train loss:0.0002175995038422448\n",
            "train loss:0.0004002826527554\n",
            "train loss:0.00042853523649287727\n",
            "train loss:0.00019913495777836306\n",
            "train loss:0.0007799257258379004\n",
            "train loss:0.00685237901093478\n",
            "train loss:0.0003702877263658411\n",
            "train loss:0.005084190478063283\n",
            "train loss:0.0010390184068017644\n",
            "train loss:7.457872267960612e-06\n",
            "train loss:0.0017359005595155132\n",
            "train loss:0.003778361661050545\n",
            "train loss:0.0005342540691581631\n",
            "train loss:8.065563322554407e-05\n",
            "train loss:0.001083253439094012\n",
            "train loss:0.0030476087342977158\n",
            "train loss:0.0014002002845474098\n",
            "train loss:0.0010058736261656983\n",
            "train loss:0.0026623878923652516\n",
            "train loss:0.0016915470280365547\n",
            "train loss:0.07369588711715164\n",
            "train loss:0.0007129285148599677\n",
            "train loss:0.0024389426524533487\n",
            "train loss:0.0007428012053737589\n",
            "train loss:5.8459588688952915e-05\n",
            "train loss:0.00011002177297553809\n",
            "train loss:0.00024065820674448312\n",
            "train loss:3.320897235735223e-05\n",
            "train loss:0.0060272073050690956\n",
            "train loss:0.0007921101974563549\n",
            "train loss:0.00011300304469723013\n",
            "train loss:0.0024406368199365717\n",
            "train loss:0.0006135286652576543\n",
            "train loss:0.0009243791283096614\n",
            "train loss:0.003766051804539725\n",
            "train loss:0.0005600686360370233\n",
            "train loss:0.004309993744521564\n",
            "train loss:0.004892310421192381\n",
            "train loss:0.0003306681613875611\n",
            "train loss:0.001934109411595933\n",
            "train loss:0.0027572735839632447\n",
            "train loss:0.0007357255919766277\n",
            "train loss:0.004282091345435796\n",
            "train loss:0.0016183728911791304\n",
            "train loss:0.0005788655565193365\n",
            "train loss:0.00014672838070707635\n",
            "train loss:0.00423462743127926\n",
            "train loss:0.00016410099116827149\n",
            "train loss:7.355770368476287e-05\n",
            "train loss:0.001359266371864866\n",
            "train loss:0.0004846528084585227\n",
            "train loss:0.0016628961989843035\n",
            "train loss:0.0012522396978999933\n",
            "train loss:0.013368437914508416\n",
            "train loss:0.00012042847709221481\n",
            "train loss:0.0001829662470611378\n",
            "train loss:0.0023716459069463096\n",
            "train loss:0.0011104586213729999\n",
            "train loss:0.0031834588300165075\n",
            "train loss:0.00021242934161393252\n",
            "train loss:0.0014458291171000983\n",
            "train loss:0.0028943092264612706\n",
            "train loss:0.0004495471086914403\n",
            "train loss:0.00016227826480882856\n",
            "train loss:0.0007429558001582213\n",
            "train loss:0.0005709812412630685\n",
            "train loss:0.00355537437891989\n",
            "train loss:0.0028487736371577465\n",
            "train loss:0.00040359395224066766\n",
            "train loss:0.001550017383997944\n",
            "train loss:0.020572122626644568\n",
            "train loss:0.030414469095517437\n",
            "train loss:0.005082955955352285\n",
            "train loss:0.0009985103449067071\n",
            "train loss:0.0013318563859686906\n",
            "train loss:0.001969371543503718\n",
            "train loss:0.00013531422838957625\n",
            "train loss:0.0006680093978107182\n",
            "train loss:0.017946846045092966\n",
            "train loss:0.00019146974032304532\n",
            "train loss:0.010060012651856593\n",
            "train loss:0.0013498088174062398\n",
            "train loss:7.730754574256762e-05\n",
            "train loss:0.003106306482127347\n",
            "train loss:0.02899123241534414\n",
            "train loss:0.0009571139021157262\n",
            "train loss:0.00013201828490538227\n",
            "train loss:0.015207158693114542\n",
            "train loss:0.0006026134214131259\n",
            "train loss:0.00611917287820904\n",
            "train loss:0.00031825035264213637\n",
            "train loss:0.000901054418193237\n",
            "train loss:0.0019131171329428666\n",
            "train loss:0.004272084308251843\n",
            "train loss:0.0007356689178833098\n",
            "train loss:0.0008695348071276802\n",
            "train loss:0.004747286203103492\n",
            "train loss:0.004359297507920766\n",
            "train loss:0.0005829777520405008\n",
            "train loss:0.00025816358087402466\n",
            "train loss:0.0022246326959098135\n",
            "train loss:0.0009750661660783143\n",
            "train loss:0.0015401430589403425\n",
            "train loss:0.00035777708532501977\n",
            "train loss:0.0009504739080572164\n",
            "train loss:0.0003146572794951284\n",
            "train loss:0.004362163040221497\n",
            "train loss:0.023946106087714494\n",
            "train loss:0.00025630707400498264\n",
            "train loss:0.0034400236932662677\n",
            "train loss:0.0006949083723520209\n",
            "train loss:0.0018887168358079406\n",
            "train loss:0.0023273440068696284\n",
            "train loss:0.000633122212878421\n",
            "train loss:0.0014375535050733183\n",
            "train loss:0.0003487172161229629\n",
            "train loss:9.252093579922132e-05\n",
            "train loss:0.0005080163003471763\n",
            "train loss:0.0016540222678814247\n",
            "train loss:0.0028099592966194225\n",
            "train loss:0.0018317359693853143\n",
            "train loss:0.006953048420293295\n",
            "train loss:0.011842656536233646\n",
            "train loss:0.005617034730852036\n",
            "train loss:0.0026585939097235546\n",
            "train loss:0.0003847563545171805\n",
            "train loss:0.0056304862816173905\n",
            "train loss:0.003441573520595127\n",
            "train loss:0.0007683090068868788\n",
            "train loss:0.0008827596443672185\n",
            "train loss:0.00766003116045626\n",
            "train loss:0.001949691247328798\n",
            "train loss:0.00011822023457291794\n",
            "train loss:0.006402623481828578\n",
            "train loss:0.00036902067282362625\n",
            "train loss:0.0010862923585483967\n",
            "train loss:0.0028948403817041957\n",
            "train loss:0.0019660675700094578\n",
            "train loss:0.0037365618702316855\n",
            "train loss:0.0015686311051306785\n",
            "train loss:0.0002569787829274863\n",
            "train loss:0.002610026483831896\n",
            "train loss:0.003956976522475802\n",
            "train loss:0.0011162816191892598\n",
            "train loss:0.0001415136844102136\n",
            "train loss:0.0017420467270078289\n",
            "train loss:0.0014420370001352108\n",
            "train loss:0.0024571869296925856\n",
            "train loss:0.0038881131185563365\n",
            "train loss:0.006076956741621573\n",
            "train loss:0.0010331416190456774\n",
            "train loss:0.001956486148366218\n",
            "train loss:0.000704180196536163\n",
            "train loss:0.0016539124573025546\n",
            "train loss:0.0013960093146621936\n",
            "train loss:0.011344240058813864\n",
            "train loss:0.01037309562232558\n",
            "train loss:0.0013569388052780344\n",
            "train loss:0.0003030361934890673\n",
            "train loss:0.00045844029607375986\n",
            "train loss:0.0007878302542496498\n",
            "train loss:0.00039575605133182853\n",
            "train loss:0.0013515149680381696\n",
            "train loss:4.0072926609688635e-05\n",
            "train loss:6.864100814221731e-05\n",
            "train loss:0.001983021124271666\n",
            "train loss:0.0025157461767810196\n",
            "train loss:0.0017440216441386288\n",
            "train loss:0.00028526587443820055\n",
            "train loss:0.0009493700197688209\n",
            "train loss:0.0019295745195245142\n",
            "train loss:0.0015545106594711804\n",
            "train loss:0.0020876015620922505\n",
            "train loss:0.002072291795146777\n",
            "train loss:0.0016844358567478694\n",
            "train loss:0.0011184246054473095\n",
            "train loss:0.0033396221525373066\n",
            "train loss:0.0009550731804458483\n",
            "train loss:0.00043388825636427\n",
            "train loss:5.935136983831449e-05\n",
            "train loss:0.0009869340978689962\n",
            "train loss:0.0006763918000327833\n",
            "train loss:0.0005866424019033452\n",
            "train loss:0.005038002611507227\n",
            "train loss:0.000529091545725671\n",
            "train loss:0.0019552599247613157\n",
            "train loss:0.0016840568627917245\n",
            "train loss:0.0002742630319245978\n",
            "train loss:0.0024151122530155582\n",
            "train loss:0.00046911207442543976\n",
            "train loss:0.0005640230902128906\n",
            "train loss:0.00031239545725182774\n",
            "train loss:0.001493336510807211\n",
            "train loss:0.0001758300770516681\n",
            "train loss:0.0016929481765285404\n",
            "train loss:0.0014827135019442295\n",
            "train loss:4.841156651706618e-05\n",
            "train loss:0.0030103428307128414\n",
            "train loss:0.0002624851090470779\n",
            "train loss:0.02134816762902086\n",
            "train loss:0.0023044835926151765\n",
            "train loss:0.00026477496832503155\n",
            "train loss:2.4783302743240863e-05\n",
            "train loss:0.0017639635589020047\n",
            "train loss:0.002449195448297716\n",
            "train loss:0.000320240800239327\n",
            "train loss:0.002701440628949894\n",
            "train loss:0.002813700644339404\n",
            "train loss:0.0008828218823117948\n",
            "train loss:0.009787093086098318\n",
            "train loss:0.0007900923455037262\n",
            "train loss:0.00036326853020242675\n",
            "train loss:0.0006700498085127855\n",
            "train loss:0.0007486946593049132\n",
            "train loss:0.0007505113725690334\n",
            "train loss:0.0006330701421144376\n",
            "train loss:0.004441850006100283\n",
            "train loss:0.001422947560489032\n",
            "train loss:0.000761739022240266\n",
            "train loss:0.0012637251492451634\n",
            "train loss:0.000518935882250858\n",
            "train loss:0.0010677172887022664\n",
            "train loss:0.0013515754431858932\n",
            "train loss:0.0015818539199092016\n",
            "train loss:0.0026728466168813945\n",
            "train loss:0.0021101749221136682\n",
            "train loss:0.0005362203155575663\n",
            "train loss:0.00010340017274471662\n",
            "train loss:0.0012927116742608498\n",
            "train loss:0.0012075200008575665\n",
            "train loss:0.0003275257750284487\n",
            "train loss:0.007824571409469901\n",
            "train loss:0.003396330957617794\n",
            "train loss:0.0013753391747658448\n",
            "train loss:0.0010719659195895907\n",
            "train loss:0.0007682108566908752\n",
            "train loss:3.6687686633671026e-05\n",
            "train loss:0.0007468716342167695\n",
            "train loss:0.0008635679075051727\n",
            "train loss:0.0002996027426562237\n",
            "train loss:0.00040783404079825994\n",
            "train loss:0.000529299375995253\n",
            "train loss:0.0028617131353094235\n",
            "train loss:0.0025460567670459334\n",
            "train loss:0.002458593046308768\n",
            "train loss:0.0015333723493834736\n",
            "train loss:0.0037940984492005805\n",
            "train loss:0.002271932555486694\n",
            "train loss:0.0006277856322688918\n",
            "train loss:0.000617881821762423\n",
            "train loss:0.0034890207213896314\n",
            "train loss:0.00040966125523162687\n",
            "train loss:0.0005752830449070808\n",
            "train loss:0.0005260876498494026\n",
            "train loss:0.0004684633956858674\n",
            "train loss:0.0025318258282622484\n",
            "train loss:0.00017351506867632502\n",
            "train loss:4.9240864491114697e-05\n",
            "train loss:0.0023981596239210094\n",
            "train loss:0.004359097330132538\n",
            "train loss:0.0003115588252418208\n",
            "train loss:0.0019577838481420994\n",
            "train loss:0.0014323541719664995\n",
            "train loss:0.0023229689602864883\n",
            "train loss:0.00045435002700392157\n",
            "train loss:0.0008361754195975059\n",
            "train loss:5.369141766330903e-05\n",
            "train loss:0.0018314083907772136\n",
            "train loss:0.00027792077948069914\n",
            "train loss:0.000584459578567383\n",
            "train loss:0.01459277196468581\n",
            "train loss:8.211899527257607e-05\n",
            "train loss:0.0019330983383530464\n",
            "train loss:0.0009325931456101747\n",
            "train loss:0.00032319342501636747\n",
            "train loss:0.0006613999162702086\n",
            "train loss:0.0009656804139243525\n",
            "train loss:5.270576081311039e-05\n",
            "train loss:0.0020314951263057613\n",
            "train loss:0.0027419455721998526\n",
            "train loss:0.019280875680521625\n",
            "train loss:0.0016562013144281657\n",
            "train loss:0.0005614922983400588\n",
            "train loss:0.000376482348804483\n",
            "train loss:0.0005164417798289527\n",
            "train loss:0.000646141759858335\n",
            "=== epoch:18, train acc:0.997, test acc:0.988 ===\n",
            "train loss:0.008897646784984996\n",
            "train loss:0.00043933908518790476\n",
            "train loss:0.0019097224990278117\n",
            "train loss:0.0009740974020457722\n",
            "train loss:0.00046842576154573865\n",
            "train loss:0.0004188047609018487\n",
            "train loss:0.0012833050395359641\n",
            "train loss:0.0004066851561821138\n",
            "train loss:0.001564404251584137\n",
            "train loss:0.0022776333765480087\n",
            "train loss:0.0003903189190463875\n",
            "train loss:0.0041878079230786925\n",
            "train loss:0.0002103667711009518\n",
            "train loss:0.0011381271301692563\n",
            "train loss:5.127242141904503e-05\n",
            "train loss:0.00030367504122662644\n",
            "train loss:0.0035418783437268903\n",
            "train loss:0.002218678144367565\n",
            "train loss:0.00010601764551107555\n",
            "train loss:0.00011579551724744397\n",
            "train loss:0.0022788069836419556\n",
            "train loss:0.00011185269613375638\n",
            "train loss:0.0018315535920434604\n",
            "train loss:0.0044799713869354135\n",
            "train loss:0.0008232136737385165\n",
            "train loss:0.0004079398489387427\n",
            "train loss:0.005431878794469019\n",
            "train loss:0.00020466444085359646\n",
            "train loss:7.069513774255815e-05\n",
            "train loss:0.00047009126385439456\n",
            "train loss:0.002025046956068085\n",
            "train loss:0.0008905904251278437\n",
            "train loss:0.0010459688825572857\n",
            "train loss:0.00037735389243411833\n",
            "train loss:0.000254090040491331\n",
            "train loss:0.001302055643871599\n",
            "train loss:0.00014702082910007116\n",
            "train loss:0.0048541433220127\n",
            "train loss:0.0003114971633989545\n",
            "train loss:0.00020097663294879297\n",
            "train loss:7.997019111051884e-05\n",
            "train loss:8.817865979455742e-05\n",
            "train loss:0.00019048814380298213\n",
            "train loss:0.0006324232650564018\n",
            "train loss:0.0014604876179003276\n",
            "train loss:0.005012954525311315\n",
            "train loss:0.0005842073235486338\n",
            "train loss:5.967595588319372e-05\n",
            "train loss:0.001288969097641016\n",
            "train loss:0.0004193371598820133\n",
            "train loss:0.01646806613969444\n",
            "train loss:0.0045427413190992465\n",
            "train loss:0.0019396376309780265\n",
            "train loss:0.00015235355840611815\n",
            "train loss:0.003663038664787235\n",
            "train loss:0.006821390648022221\n",
            "train loss:0.0002494078307832136\n",
            "train loss:0.0014119382382227928\n",
            "train loss:0.0011516304177195795\n",
            "train loss:0.0005038142610497713\n",
            "train loss:0.001283045768000775\n",
            "train loss:0.0040343821403374105\n",
            "train loss:0.0008825064209659021\n",
            "train loss:0.0004038445220281369\n",
            "train loss:0.002373048866029086\n",
            "train loss:0.005112724006167718\n",
            "train loss:0.00016103276037482\n",
            "train loss:0.0022114300279250073\n",
            "train loss:0.005063066343780464\n",
            "train loss:0.0005836707866725947\n",
            "train loss:0.0015250278933147043\n",
            "train loss:0.0002836495449204148\n",
            "train loss:0.00019180043016888172\n",
            "train loss:0.0012950890233560464\n",
            "train loss:0.0006341523680734006\n",
            "train loss:0.000814793342791222\n",
            "train loss:0.0017401730297092138\n",
            "train loss:0.0027785269432684763\n",
            "train loss:0.0021350511635140727\n",
            "train loss:0.002583206973805374\n",
            "train loss:0.0009576955557103765\n",
            "train loss:0.003841260869418929\n",
            "train loss:0.0008823084929005336\n",
            "train loss:0.0037963722169941584\n",
            "train loss:0.0002379527232636668\n",
            "train loss:0.00018116085607624275\n",
            "train loss:0.0008397889459473796\n",
            "train loss:0.00015264462345252662\n",
            "train loss:0.000864109422339385\n",
            "train loss:0.0007467577936724609\n",
            "train loss:0.0007573751397619295\n",
            "train loss:0.0006242981338895367\n",
            "train loss:0.0015149738755241215\n",
            "train loss:0.0023490124950308034\n",
            "train loss:0.002332128522280866\n",
            "train loss:0.00024290089566988374\n",
            "train loss:0.0004738842656395828\n",
            "train loss:6.860170561558873e-05\n",
            "train loss:0.0003642222793551701\n",
            "train loss:0.00013473893069565688\n",
            "train loss:0.002366689018526702\n",
            "train loss:0.0036914871091164782\n",
            "train loss:0.01422710708411849\n",
            "train loss:6.355148114095873e-05\n",
            "train loss:0.00030442640049440115\n",
            "train loss:0.0009148316428556501\n",
            "train loss:0.0014974625183490605\n",
            "train loss:0.00045768355176779857\n",
            "train loss:0.0006336857090121764\n",
            "train loss:0.005224457311770919\n",
            "train loss:0.002347922447816091\n",
            "train loss:6.388390492461922e-05\n",
            "train loss:0.0003234959175563633\n",
            "train loss:0.00039077671788723426\n",
            "train loss:0.0010708343802852372\n",
            "train loss:0.000753334421792297\n",
            "train loss:0.0013995080018435768\n",
            "train loss:0.0012920468274037322\n",
            "train loss:0.00044632754253146295\n",
            "train loss:0.005329240867946557\n",
            "train loss:3.9932943595870646e-05\n",
            "train loss:0.0007056870410528006\n",
            "train loss:0.0023603551707707766\n",
            "train loss:0.0014819502418356259\n",
            "train loss:0.0009422144652972681\n",
            "train loss:0.0031773542866745685\n",
            "train loss:0.008267249909963642\n",
            "train loss:0.005093109494032819\n",
            "train loss:0.00014578399869661572\n",
            "train loss:1.7879116860134582e-05\n",
            "train loss:7.764995299715657e-05\n",
            "train loss:0.0005412456199317055\n",
            "train loss:0.0009733118500875861\n",
            "train loss:0.0015566902491365145\n",
            "train loss:0.0003292264329916147\n",
            "train loss:0.00019798555899396507\n",
            "train loss:0.0037268639070080494\n",
            "train loss:0.0018048341285058203\n",
            "train loss:0.000250641454508407\n",
            "train loss:0.0005574695874395233\n",
            "train loss:0.0028804807894682156\n",
            "train loss:0.0018950248695264547\n",
            "train loss:0.0003748367447319033\n",
            "train loss:0.0008204469262784147\n",
            "train loss:0.0015604619108215742\n",
            "train loss:0.00019239430928325312\n",
            "train loss:0.00045853376682828393\n",
            "train loss:0.00033855059532119806\n",
            "train loss:0.00022782299400669586\n",
            "train loss:0.010289596817701393\n",
            "train loss:0.0032359871370266913\n",
            "train loss:0.0007747123741936177\n",
            "train loss:0.0004249025440674133\n",
            "train loss:0.0019152176443789914\n",
            "train loss:0.0001354123918834041\n",
            "train loss:0.0008875907110944177\n",
            "train loss:0.0028372367330498586\n",
            "train loss:0.0032977687465033357\n",
            "train loss:0.002027806059215209\n",
            "train loss:0.0015029072846727534\n",
            "train loss:0.0007305569567256309\n",
            "train loss:0.0031379306519052673\n",
            "train loss:0.00018028889521660266\n",
            "train loss:0.0012931178692060807\n",
            "train loss:0.0033890444308979327\n",
            "train loss:0.00022075433174838552\n",
            "train loss:5.177063634651541e-05\n",
            "train loss:0.005446267610574792\n",
            "train loss:0.0006758517642817432\n",
            "train loss:0.002513543799424301\n",
            "train loss:0.029132128642436524\n",
            "train loss:0.0006975364931329198\n",
            "train loss:0.00045421160499027835\n",
            "train loss:0.0018499753154330228\n",
            "train loss:0.002763635280172719\n",
            "train loss:0.0014943277232833505\n",
            "train loss:0.001822678538962002\n",
            "train loss:0.0018621549653491038\n",
            "train loss:2.1529514152253796e-05\n",
            "train loss:0.0007312509738600573\n",
            "train loss:0.001544147255780986\n",
            "train loss:0.0010632015123471518\n",
            "train loss:0.0034433179966901783\n",
            "train loss:0.0004068981726731441\n",
            "train loss:0.0010114649350035322\n",
            "train loss:7.236502694464133e-05\n",
            "train loss:0.000474748103490862\n",
            "train loss:0.011687366167974809\n",
            "train loss:0.0002708752356662251\n",
            "train loss:0.009706625382321742\n",
            "train loss:0.0064872917600518245\n",
            "train loss:0.0015163050720667095\n",
            "train loss:0.0006983480128984294\n",
            "train loss:0.00028437356047207043\n",
            "train loss:0.0004897638936189712\n",
            "train loss:0.00045762625706216885\n",
            "train loss:5.9267004560672654e-05\n",
            "train loss:0.00149415893006371\n",
            "train loss:9.406371151441044e-05\n",
            "train loss:0.00012642149077830028\n",
            "train loss:0.004561543534648705\n",
            "train loss:3.998721658920271e-05\n",
            "train loss:0.0007011722657107293\n",
            "train loss:0.0011791652169433162\n",
            "train loss:0.0022211991095344497\n",
            "train loss:0.0008593296664154155\n",
            "train loss:0.0007957191094317463\n",
            "train loss:0.00042151734176530605\n",
            "train loss:0.00010755341532318068\n",
            "train loss:3.9918466890060325e-05\n",
            "train loss:0.006618590817732449\n",
            "train loss:0.0008347467888506838\n",
            "train loss:0.0008302314789910841\n",
            "train loss:4.433217929088391e-05\n",
            "train loss:0.0009900325044677335\n",
            "train loss:0.001537764774226987\n",
            "train loss:0.0017155712657792317\n",
            "train loss:0.0015719566492791875\n",
            "train loss:0.00011921623304009649\n",
            "train loss:0.00019734827569144715\n",
            "train loss:7.837780825433426e-05\n",
            "train loss:0.0003920585136371234\n",
            "train loss:0.002070107263802743\n",
            "train loss:5.086296392020724e-05\n",
            "train loss:0.0036749993209785376\n",
            "train loss:0.021890830304580926\n",
            "train loss:0.0018165053075516824\n",
            "train loss:0.0030056626869953886\n",
            "train loss:0.00020927973200973515\n",
            "train loss:0.0003009108096188487\n",
            "train loss:2.434793691414342e-05\n",
            "train loss:0.004276119264686626\n",
            "train loss:3.9898283735587004e-05\n",
            "train loss:0.0020911968297651264\n",
            "train loss:0.0004547619797920962\n",
            "train loss:0.0011955881515264344\n",
            "train loss:0.0012617901942788736\n",
            "train loss:0.0029510108494188473\n",
            "train loss:0.0004821748076487841\n",
            "train loss:0.0015346876641585813\n",
            "train loss:0.0011920912201597953\n",
            "train loss:0.0014519802220321343\n",
            "train loss:0.0005150936805493617\n",
            "train loss:0.001875823577872707\n",
            "train loss:0.00013818861011436972\n",
            "train loss:0.00010907240783736539\n",
            "train loss:0.001998634645434164\n",
            "train loss:0.003059358701432557\n",
            "train loss:0.00028690427727600954\n",
            "train loss:0.003686970749214591\n",
            "train loss:0.002078466179055372\n",
            "train loss:0.002124992905756525\n",
            "train loss:0.002446489058197367\n",
            "train loss:0.0001458155650616664\n",
            "train loss:0.0006703925875300935\n",
            "train loss:0.0021541822331306104\n",
            "train loss:0.0003653848404355969\n",
            "train loss:0.006202971220918712\n",
            "train loss:0.007062236369289514\n",
            "train loss:0.0004786847004842916\n",
            "train loss:0.000863614136319773\n",
            "train loss:5.35633599164829e-05\n",
            "train loss:0.0027117217949559898\n",
            "train loss:0.00023883924558557715\n",
            "train loss:0.008773550880456827\n",
            "train loss:0.0013743006012522784\n",
            "train loss:0.0014838127260674125\n",
            "train loss:0.001412343803431699\n",
            "train loss:0.025289914178051466\n",
            "train loss:0.0009509415010332704\n",
            "train loss:0.0011821429132282861\n",
            "train loss:0.0023515803694100054\n",
            "train loss:0.0007978279984187379\n",
            "train loss:0.005922786646202486\n",
            "train loss:0.0019590210164274237\n",
            "train loss:0.0008192089409737932\n",
            "train loss:0.0008514465675019714\n",
            "train loss:0.0040996724771253075\n",
            "train loss:0.00015380447862670848\n",
            "train loss:0.0015688898624307596\n",
            "train loss:0.0006901714282771345\n",
            "train loss:0.0058277287672393475\n",
            "train loss:0.000709146625011169\n",
            "train loss:0.0004036997959575697\n",
            "train loss:8.679261463192312e-05\n",
            "train loss:0.018560053843587818\n",
            "train loss:0.0014628510883654374\n",
            "train loss:0.0018126748148639565\n",
            "train loss:0.0011510540276225896\n",
            "train loss:0.00012223849560293582\n",
            "train loss:6.504587380216972e-05\n",
            "train loss:0.0008042451376510929\n",
            "train loss:0.0020871622983471066\n",
            "train loss:0.00021498573903766616\n",
            "train loss:0.0006947801382998195\n",
            "train loss:0.00027552535907352714\n",
            "train loss:0.0003958594008546707\n",
            "train loss:0.00014734723819330718\n",
            "train loss:5.4227957849649465e-05\n",
            "train loss:0.00010116207442903363\n",
            "train loss:0.00029304920420989187\n",
            "train loss:0.0025498420470305406\n",
            "train loss:0.0003951240175195333\n",
            "train loss:0.006198239142825976\n",
            "train loss:0.0006118146678516611\n",
            "train loss:0.0008325042347262959\n",
            "train loss:0.0027951836197454383\n",
            "train loss:0.0007780600559284235\n",
            "train loss:5.02340047699023e-05\n",
            "train loss:0.0052083340470895755\n",
            "train loss:0.003266428697390461\n",
            "train loss:0.0015913153020209458\n",
            "train loss:0.0007571720492978523\n",
            "train loss:0.002749041172926101\n",
            "train loss:0.0023376243997895673\n",
            "train loss:0.002086558951510145\n",
            "train loss:0.0005236872168466498\n",
            "train loss:0.00010731862271687685\n",
            "train loss:0.00031046762366717875\n",
            "train loss:0.00040852840871411595\n",
            "train loss:0.0008778187231230761\n",
            "train loss:0.00016167922007935136\n",
            "train loss:8.290632022766408e-05\n",
            "train loss:0.00014692359661772268\n",
            "train loss:0.001570815029714831\n",
            "train loss:0.0023062710039263253\n",
            "train loss:0.0008954977223676723\n",
            "train loss:0.00020199477355527858\n",
            "train loss:0.0011410189971844072\n",
            "train loss:0.0011484397580837171\n",
            "train loss:0.0006419231332203834\n",
            "train loss:0.06875671949093147\n",
            "train loss:0.0019645800537719882\n",
            "train loss:0.00045672284151957723\n",
            "train loss:0.0013389687865994959\n",
            "train loss:0.001257927025737987\n",
            "train loss:5.353414829340826e-05\n",
            "train loss:0.0001254919914194563\n",
            "train loss:0.00011515322387091788\n",
            "train loss:0.0016062840619879373\n",
            "train loss:5.770850030293787e-05\n",
            "train loss:6.036392457165457e-05\n",
            "train loss:0.0011052055259239161\n",
            "train loss:0.0005031550471385446\n",
            "train loss:0.0003824194446947597\n",
            "train loss:0.001016025694559082\n",
            "train loss:0.0014766733236769702\n",
            "train loss:0.0008029453807703864\n",
            "train loss:2.331638698397882e-05\n",
            "train loss:0.00016146328443662682\n",
            "train loss:0.003022110501374667\n",
            "train loss:0.0015445396323178287\n",
            "train loss:4.714316263476827e-05\n",
            "train loss:0.00020040705604113722\n",
            "train loss:0.0002343805982091781\n",
            "train loss:6.740509552155012e-05\n",
            "train loss:0.0005011084669524913\n",
            "train loss:0.0005334337300556416\n",
            "train loss:0.0008236750703880895\n",
            "train loss:0.002240039837798624\n",
            "train loss:0.0006810193354814274\n",
            "train loss:0.0002279108276687871\n",
            "train loss:0.00013984509400635642\n",
            "train loss:0.0002557597418586292\n",
            "train loss:0.0007182917088470166\n",
            "train loss:0.001438416926997774\n",
            "train loss:0.00416057687688751\n",
            "train loss:0.001512441370497408\n",
            "train loss:0.0011252047908295155\n",
            "train loss:0.0002114038044472018\n",
            "train loss:1.8574432823859644e-05\n",
            "train loss:0.00028547814929015183\n",
            "train loss:0.0023330967829542156\n",
            "train loss:0.0016103903647378957\n",
            "train loss:0.0013681037373395688\n",
            "train loss:0.0008244890136199313\n",
            "train loss:0.0004672821102875329\n",
            "train loss:0.00020882545547012854\n",
            "train loss:0.000329192926697894\n",
            "train loss:0.0003870570074166961\n",
            "train loss:0.0009654150672522264\n",
            "train loss:0.0003765563952012011\n",
            "train loss:0.00021285821628187708\n",
            "train loss:3.744827134718668e-05\n",
            "train loss:0.021893212498032426\n",
            "train loss:0.0008899238634421157\n",
            "train loss:0.0003513524091119655\n",
            "train loss:0.0045885175230825845\n",
            "train loss:0.00043004138819222493\n",
            "train loss:0.0007401414607405946\n",
            "train loss:0.00041250820687288456\n",
            "train loss:0.0026713100130508543\n",
            "train loss:0.019070009185281664\n",
            "train loss:0.00019090787096702326\n",
            "train loss:0.00038410024737151586\n",
            "train loss:0.00020981951934414959\n",
            "train loss:0.00019813784330000869\n",
            "train loss:0.0016134098028852389\n",
            "train loss:0.00023477528216875234\n",
            "train loss:0.003912920146565488\n",
            "train loss:0.0017868914581462144\n",
            "train loss:0.0018666153378029322\n",
            "train loss:0.0018454823599814455\n",
            "train loss:0.00017082929302837807\n",
            "train loss:0.002059825996054135\n",
            "train loss:0.006671866365001453\n",
            "train loss:0.0009073834440559106\n",
            "train loss:0.0014881238502620253\n",
            "train loss:0.0015001967299432483\n",
            "train loss:0.0035362346037269184\n",
            "train loss:0.0009080223365467621\n",
            "train loss:0.0018461998396461577\n",
            "train loss:0.00695377017173744\n",
            "train loss:0.0005355294380830819\n",
            "train loss:0.001033183479816768\n",
            "train loss:0.0009032234775368771\n",
            "train loss:0.00017325433949107777\n",
            "train loss:4.61635292233119e-05\n",
            "train loss:0.0020792844288420975\n",
            "train loss:0.002113739979910009\n",
            "train loss:0.0067537991896068714\n",
            "train loss:0.0007767448823861021\n",
            "train loss:0.0005749705627349477\n",
            "train loss:0.0007589987841642769\n",
            "train loss:0.001272287007684374\n",
            "train loss:0.00034398946228318607\n",
            "train loss:0.0009531542216507877\n",
            "train loss:0.0023396608989087707\n",
            "train loss:0.0002662906713820756\n",
            "train loss:0.0001440528819136505\n",
            "train loss:0.000497068504065939\n",
            "train loss:4.1726192787200016e-05\n",
            "train loss:0.0002897206993208069\n",
            "train loss:0.0006355009204432274\n",
            "train loss:0.0002787082991033509\n",
            "train loss:0.0007432970416536008\n",
            "train loss:0.00013402829046653628\n",
            "train loss:0.009368942818360385\n",
            "train loss:0.009273395386471258\n",
            "train loss:0.001622008875091097\n",
            "train loss:0.00040418812006958745\n",
            "train loss:0.002491547907689363\n",
            "train loss:0.0006404404872084434\n",
            "train loss:0.0019217268711466404\n",
            "train loss:0.008149958870365128\n",
            "train loss:0.0004307146404439232\n",
            "train loss:0.0023104397441391826\n",
            "train loss:0.004429488894607283\n",
            "train loss:0.0002559878629729794\n",
            "train loss:0.0005435195510084916\n",
            "train loss:0.0016806736528766936\n",
            "train loss:0.0014712393062349374\n",
            "train loss:0.0005165639616315748\n",
            "train loss:0.0010617416569614721\n",
            "train loss:0.0012661656780197147\n",
            "train loss:0.0010102290316312537\n",
            "train loss:0.0015813638541091457\n",
            "train loss:0.0013235558192394652\n",
            "train loss:0.007430350302263224\n",
            "train loss:0.007667071543072957\n",
            "train loss:0.03129786631980246\n",
            "train loss:0.0004452163937472414\n",
            "train loss:0.0013951315527841752\n",
            "train loss:0.0022496561005276184\n",
            "train loss:0.03032785847363473\n",
            "train loss:0.0001411237561561052\n",
            "train loss:0.000346700275054755\n",
            "train loss:0.0025762735051123135\n",
            "train loss:0.002458050136780471\n",
            "train loss:0.009213847970513599\n",
            "train loss:0.0030507618999248243\n",
            "train loss:0.0018645819726882942\n",
            "train loss:0.002783445831703126\n",
            "train loss:0.046578644896486214\n",
            "train loss:0.0028882480627206693\n",
            "train loss:0.0024093051852323343\n",
            "train loss:0.0016994618734340156\n",
            "train loss:0.0015061587385247963\n",
            "train loss:0.005766271807312562\n",
            "train loss:0.00025331052573809187\n",
            "train loss:0.0021110977977008816\n",
            "train loss:0.00019118550368448745\n",
            "train loss:0.0038929520328683017\n",
            "train loss:0.0001307876818004861\n",
            "train loss:0.0013378611542032531\n",
            "train loss:5.773844471298951e-05\n",
            "train loss:0.008825784928002222\n",
            "train loss:0.0027395177798104227\n",
            "train loss:0.0013979860415426124\n",
            "train loss:3.440767937184071e-05\n",
            "train loss:0.0002739767315716741\n",
            "train loss:0.002821883249607903\n",
            "train loss:0.00025951962656014426\n",
            "train loss:0.0004987831439995802\n",
            "train loss:3.251914248170792e-05\n",
            "train loss:0.0008947271165528031\n",
            "train loss:0.001126235208572529\n",
            "train loss:0.0009300435228453548\n",
            "train loss:0.005251506203787376\n",
            "train loss:0.003946890259484938\n",
            "train loss:0.009017679955858232\n",
            "train loss:0.001941080882494767\n",
            "train loss:0.0010626734597819322\n",
            "train loss:0.0017393192961983554\n",
            "train loss:0.003822883477954398\n",
            "train loss:0.0040485343664436405\n",
            "train loss:0.0034125116375375198\n",
            "train loss:0.0006522992276500357\n",
            "train loss:0.0007350988959411026\n",
            "train loss:0.0028929653408558036\n",
            "train loss:0.00032816183830923615\n",
            "train loss:0.0002243893558191945\n",
            "train loss:0.0014534670261750285\n",
            "train loss:0.00035910071840522333\n",
            "train loss:2.9448354828109443e-05\n",
            "train loss:0.0012367930867934391\n",
            "train loss:0.0033487752618136272\n",
            "train loss:0.0014780821894537\n",
            "train loss:0.0025876247986308144\n",
            "train loss:0.00197997848781097\n",
            "train loss:0.00023933664695288776\n",
            "train loss:0.001431771895895967\n",
            "train loss:0.000316162703318377\n",
            "train loss:0.002363364438844638\n",
            "train loss:0.00388851483529897\n",
            "train loss:0.0005369659671742967\n",
            "train loss:0.00011601131165014792\n",
            "train loss:0.0013980081822612847\n",
            "train loss:0.0013946698194106277\n",
            "train loss:0.00195273059920518\n",
            "train loss:0.0009983597095682543\n",
            "train loss:2.5840007092323724e-05\n",
            "train loss:0.0009909392507649387\n",
            "train loss:0.0020521318702435404\n",
            "train loss:0.004779019338784207\n",
            "train loss:0.004433008415562209\n",
            "train loss:0.0006309446190994446\n",
            "train loss:0.0028445630983051882\n",
            "train loss:0.000584537702853841\n",
            "train loss:0.0008180340483709619\n",
            "train loss:0.00036400185644766103\n",
            "train loss:0.0036398712255156103\n",
            "train loss:0.0003781147583813354\n",
            "train loss:0.00020851942510978234\n",
            "train loss:0.0019320929571664737\n",
            "train loss:0.003919932332396904\n",
            "train loss:0.00011839665231787986\n",
            "train loss:0.0012650436962875259\n",
            "train loss:0.0009243633319980496\n",
            "train loss:0.00024142337283152037\n",
            "train loss:0.0014654180486619753\n",
            "train loss:0.0004604902753046659\n",
            "train loss:0.00037577573679970796\n",
            "train loss:0.0006383463317201167\n",
            "train loss:0.0006419454782706345\n",
            "train loss:0.00017050401366232906\n",
            "train loss:0.0003156299511972028\n",
            "train loss:0.00020427612252240615\n",
            "train loss:0.0004215196434759947\n",
            "train loss:0.00022433339824066086\n",
            "train loss:0.0023277280383859145\n",
            "train loss:0.000683029824826478\n",
            "train loss:0.011241381356997602\n",
            "train loss:0.001594386629786984\n",
            "train loss:0.0006975825555833389\n",
            "train loss:0.006490398210224498\n",
            "train loss:0.0004553432225055679\n",
            "train loss:0.03064573687441474\n",
            "train loss:0.0008202443213785422\n",
            "train loss:0.0004501044842071337\n",
            "train loss:0.0020105319301789034\n",
            "train loss:0.00020460986745715048\n",
            "train loss:0.001037536649304244\n",
            "train loss:0.005647914700321375\n",
            "train loss:0.0006859728026843447\n",
            "train loss:0.0017569012043831811\n",
            "train loss:0.0017515685316708668\n",
            "train loss:0.007721236503252502\n",
            "train loss:0.0024367117951610124\n",
            "train loss:0.002935818910442002\n",
            "train loss:0.0009618893790928933\n",
            "train loss:0.0002698182303348116\n",
            "train loss:0.002379927613155521\n",
            "train loss:0.001363205198544603\n",
            "train loss:0.0018079307781375233\n",
            "train loss:0.0029582510179969263\n",
            "train loss:0.0020183780495037188\n",
            "train loss:0.001492791664193584\n",
            "train loss:0.0022558285469551176\n",
            "train loss:0.0007858397010261473\n",
            "train loss:0.003097400492926236\n",
            "train loss:0.004316595416321901\n",
            "train loss:0.0018935270987094255\n",
            "train loss:0.001007958474561815\n",
            "train loss:0.00019373713486443427\n",
            "train loss:0.00241574122089899\n",
            "train loss:0.001145108991771877\n",
            "train loss:0.003591742311177284\n",
            "train loss:0.03571065874787659\n",
            "train loss:0.0006249399845933457\n",
            "=== epoch:19, train acc:0.999, test acc:0.985 ===\n",
            "train loss:0.006228078806097553\n",
            "train loss:0.00045241259816420693\n",
            "train loss:0.0005607179374528117\n",
            "train loss:0.0025318095067433342\n",
            "train loss:0.0031199716430474578\n",
            "train loss:0.0006600183123763547\n",
            "train loss:0.00271477403625864\n",
            "train loss:0.00283281577499831\n",
            "train loss:0.00034585977297475507\n",
            "train loss:0.002523509766445878\n",
            "train loss:0.0004908967909998269\n",
            "train loss:0.0003341286846903081\n",
            "train loss:0.00045072845763166283\n",
            "train loss:0.00271329255549765\n",
            "train loss:0.006011584030834036\n",
            "train loss:0.0003004571335524245\n",
            "train loss:0.0024633956130300652\n",
            "train loss:0.00023247038286435467\n",
            "train loss:4.783073853518345e-05\n",
            "train loss:0.0016962842749936654\n",
            "train loss:0.0015664684305566304\n",
            "train loss:3.356517705088886e-05\n",
            "train loss:0.0006380855728417875\n",
            "train loss:0.0018937063409998215\n",
            "train loss:0.0014715445270637546\n",
            "train loss:0.0002484863409848942\n",
            "train loss:0.004685240855153817\n",
            "train loss:0.0023303774874676173\n",
            "train loss:0.0025518935264313507\n",
            "train loss:0.0009902119085018943\n",
            "train loss:0.0004322268989049162\n",
            "train loss:0.012384062305736776\n",
            "train loss:0.0008232048194193737\n",
            "train loss:0.00010937688630003323\n",
            "train loss:0.0008793091081018842\n",
            "train loss:0.0006013698023675253\n",
            "train loss:0.009561821006667687\n",
            "train loss:0.0004683889350878935\n",
            "train loss:0.0006388351859477348\n",
            "train loss:0.0013008875697684316\n",
            "train loss:0.0013315270882702315\n",
            "train loss:0.0003130449360940741\n",
            "train loss:0.0004388373677919783\n",
            "train loss:0.0029741435874382407\n",
            "train loss:5.922891015384778e-05\n",
            "train loss:0.00022367936341379443\n",
            "train loss:0.006254695941583707\n",
            "train loss:0.00011826111694854888\n",
            "train loss:0.0006390073785238172\n",
            "train loss:0.0016895326472979486\n",
            "train loss:0.002292736562115279\n",
            "train loss:0.0002280699126849488\n",
            "train loss:0.0021453521276775284\n",
            "train loss:0.0016079177271925232\n",
            "train loss:0.000994206395568418\n",
            "train loss:0.0006854709905388273\n",
            "train loss:0.009005578561345078\n",
            "train loss:0.0009406366971595682\n",
            "train loss:0.002028405473112569\n",
            "train loss:0.0006708466656179146\n",
            "train loss:0.0025549856558933774\n",
            "train loss:0.0023730714513673524\n",
            "train loss:0.0008723283603762062\n",
            "train loss:5.009305191643865e-05\n",
            "train loss:3.838582448042389e-05\n",
            "train loss:9.589427651663946e-05\n",
            "train loss:0.0019081127655211799\n",
            "train loss:0.0008099527216683597\n",
            "train loss:0.003954599271150959\n",
            "train loss:3.05946747371861e-05\n",
            "train loss:0.00037498002977335546\n",
            "train loss:0.0001648057880123182\n",
            "train loss:0.00035302122113726927\n",
            "train loss:0.0005210348070054205\n",
            "train loss:0.0005435670005201076\n",
            "train loss:4.909881909496946e-05\n",
            "train loss:0.0010083809924410834\n",
            "train loss:0.0030239205229847664\n",
            "train loss:0.0021297565577900654\n",
            "train loss:0.0006646704500696687\n",
            "train loss:0.003627671346964062\n",
            "train loss:0.00105428047844963\n",
            "train loss:0.00036926848937833594\n",
            "train loss:0.000342857111445348\n",
            "train loss:0.010073154970280608\n",
            "train loss:0.0005482059235256863\n",
            "train loss:0.0010674073025867157\n",
            "train loss:0.0032335426483904727\n",
            "train loss:0.0019444617439992001\n",
            "train loss:0.006648570390272454\n",
            "train loss:0.00017613958949819894\n",
            "train loss:0.00999513464619656\n",
            "train loss:0.002661704421718336\n",
            "train loss:0.010221804684339603\n",
            "train loss:0.00046825896101008026\n",
            "train loss:0.0010125554797956475\n",
            "train loss:0.0020128388924245504\n",
            "train loss:0.0042031181831338645\n",
            "train loss:0.00032395628340948113\n",
            "train loss:0.0006712309197708745\n",
            "train loss:0.002159821969597192\n",
            "train loss:0.003388352370941402\n",
            "train loss:0.007617534307159875\n",
            "train loss:0.0017548436842279413\n",
            "train loss:0.000395366651663194\n",
            "train loss:0.004717863699545775\n",
            "train loss:4.7360007161037016e-05\n",
            "train loss:0.003029050864625357\n",
            "train loss:0.0023690426757056837\n",
            "train loss:0.0017055016501237982\n",
            "train loss:0.0006118866990908993\n",
            "train loss:0.0005214154561822302\n",
            "train loss:0.001778829179798886\n",
            "train loss:0.004489503598904229\n",
            "train loss:0.004053078505889422\n",
            "train loss:0.0006062840629446658\n",
            "train loss:0.0005854709753557014\n",
            "train loss:0.0026205970060701415\n",
            "train loss:0.0035882664713513318\n",
            "train loss:0.0016004235482106515\n",
            "train loss:0.002399550973904919\n",
            "train loss:0.0008407082519080518\n",
            "train loss:0.0034801793674656967\n",
            "train loss:4.803791054766839e-05\n",
            "train loss:0.0007071324781834279\n",
            "train loss:0.0004204596236403098\n",
            "train loss:0.03378224419030314\n",
            "train loss:0.001482471605556582\n",
            "train loss:0.008169917180352253\n",
            "train loss:0.0010949352406932013\n",
            "train loss:0.002312153414785706\n",
            "train loss:0.00040178729823901505\n",
            "train loss:0.0005874697693992063\n",
            "train loss:0.0038174857187332294\n",
            "train loss:0.023723321132899343\n",
            "train loss:0.005466267577896423\n",
            "train loss:0.000794818468289466\n",
            "train loss:0.0023898724438146998\n",
            "train loss:0.0007272141983255502\n",
            "train loss:0.0003100038143370869\n",
            "train loss:0.002702443281182863\n",
            "train loss:0.0013510945886731657\n",
            "train loss:0.00244011231368623\n",
            "train loss:0.0026040653893333347\n",
            "train loss:0.0009576033265829455\n",
            "train loss:0.002475541396527215\n",
            "train loss:0.0020873745455973146\n",
            "train loss:0.00020989675880449498\n",
            "train loss:0.011949922967593058\n",
            "train loss:0.0017297704479801615\n",
            "train loss:0.00014681086899025702\n",
            "train loss:0.0016553641642263312\n",
            "train loss:0.003605316195436847\n",
            "train loss:0.002969460612088544\n",
            "train loss:0.0011549931625503545\n",
            "train loss:9.484457792790195e-05\n",
            "train loss:0.012839375857933289\n",
            "train loss:0.0008133960396016964\n",
            "train loss:0.0006145302872727718\n",
            "train loss:0.004809401790875363\n",
            "train loss:0.0005964285414555423\n",
            "train loss:0.0003552618760712345\n",
            "train loss:0.0014022080446544178\n",
            "train loss:0.0023030296364145654\n",
            "train loss:0.0015153962024248993\n",
            "train loss:0.0002789590589220611\n",
            "train loss:0.0001992196020583\n",
            "train loss:0.0022624652378195466\n",
            "train loss:0.0005892218095999449\n",
            "train loss:0.00042042117293090444\n",
            "train loss:0.023095322765304377\n",
            "train loss:0.0017048702242358257\n",
            "train loss:0.00039147859405119014\n",
            "train loss:0.0005933907559934321\n",
            "train loss:0.0009930025638899378\n",
            "train loss:0.00048177960873104284\n",
            "train loss:0.0024298497989299044\n",
            "train loss:0.0007628448939461925\n",
            "train loss:0.0005111956922717913\n",
            "train loss:0.0003544212762436269\n",
            "train loss:0.0001449746321154419\n",
            "train loss:0.003859187158926624\n",
            "train loss:0.0002736833103270146\n",
            "train loss:0.00342817905044311\n",
            "train loss:0.0028959203272779254\n",
            "train loss:0.0011803011055656163\n",
            "train loss:0.0005422191863145613\n",
            "train loss:0.00027043293957564935\n",
            "train loss:0.0013158107705298387\n",
            "train loss:0.0004483316037991599\n",
            "train loss:0.0007713880845938317\n",
            "train loss:0.0010681249532126357\n",
            "train loss:4.914643045647627e-05\n",
            "train loss:0.00014247362928358984\n",
            "train loss:0.00044240679727459666\n",
            "train loss:0.003231106986194946\n",
            "train loss:0.000804232108504426\n",
            "train loss:0.007996826981974757\n",
            "train loss:0.0004185468228924584\n",
            "train loss:0.0007795641136897089\n",
            "train loss:0.0011270443115573088\n",
            "train loss:0.006822567632063209\n",
            "train loss:0.008327228256743362\n",
            "train loss:0.000321075874192467\n",
            "train loss:0.00026345722636008165\n",
            "train loss:0.0024260464895920902\n",
            "train loss:0.005007839130146368\n",
            "train loss:0.00019499110457822368\n",
            "train loss:0.0017569196818522951\n",
            "train loss:0.00037356949570068994\n",
            "train loss:0.001459528198850877\n",
            "train loss:9.715258595460621e-05\n",
            "train loss:0.002549103299568827\n",
            "train loss:7.853993842733182e-05\n",
            "train loss:0.0010447315134811406\n",
            "train loss:8.014048199600634e-05\n",
            "train loss:0.00032742718266056287\n",
            "train loss:0.0009452828832358268\n",
            "train loss:0.005005509096735061\n",
            "train loss:0.0023448351420400216\n",
            "train loss:0.00018458943377696967\n",
            "train loss:0.00024137586441512474\n",
            "train loss:0.0007092767539697739\n",
            "train loss:0.0019456224403751547\n",
            "train loss:0.0027059260224549797\n",
            "train loss:0.00019309824256003713\n",
            "train loss:0.000774234892221274\n",
            "train loss:3.968320636012717e-05\n",
            "train loss:4.3695342359790075e-05\n",
            "train loss:0.00022593472772862582\n",
            "train loss:0.0014095826695050375\n",
            "train loss:0.0003692546113348259\n",
            "train loss:0.002253361938482829\n",
            "train loss:0.0003374192383160914\n",
            "train loss:0.00010967760319432579\n",
            "train loss:0.0012251371700487943\n",
            "train loss:0.0001773754753065421\n",
            "train loss:0.0008353303145268464\n",
            "train loss:0.0012802527932909958\n",
            "train loss:0.0011968863119464059\n",
            "train loss:0.0004733880023929098\n",
            "train loss:1.7749164530191607e-05\n",
            "train loss:0.0005307360354443263\n",
            "train loss:0.0004793317158449233\n",
            "train loss:0.00012210232050332065\n",
            "train loss:0.0007896481905647089\n",
            "train loss:0.00020442457119953914\n",
            "train loss:0.0014138528922595245\n",
            "train loss:8.866399418164177e-05\n",
            "train loss:0.0007234248819561874\n",
            "train loss:0.0003885114702734691\n",
            "train loss:8.270576287234795e-05\n",
            "train loss:0.0003618429693955759\n",
            "train loss:0.000916927930256369\n",
            "train loss:0.0006409432880633123\n",
            "train loss:0.00010578702165646527\n",
            "train loss:0.0013547060731647898\n",
            "train loss:0.0015376498807928903\n",
            "train loss:7.811657272340625e-05\n",
            "train loss:0.00021208821266342849\n",
            "train loss:0.004937415880466912\n",
            "train loss:0.0008357459442934044\n",
            "train loss:0.00035602896304493106\n",
            "train loss:0.0004382801692958093\n",
            "train loss:0.00048703082985334983\n",
            "train loss:0.002167919371719226\n",
            "train loss:0.0027730832551625096\n",
            "train loss:0.00020821684788468325\n",
            "train loss:0.0011118200510718847\n",
            "train loss:0.0011713481439081734\n",
            "train loss:0.0010671728798356086\n",
            "train loss:0.0011699530062211452\n",
            "train loss:0.0002404615724286995\n",
            "train loss:0.0027501372820171333\n",
            "train loss:0.0010846208569715312\n",
            "train loss:0.0003182809080812194\n",
            "train loss:0.001374378824791547\n",
            "train loss:0.02036585554159187\n",
            "train loss:0.004841879277118987\n",
            "train loss:0.0005522686208615972\n",
            "train loss:0.000647624703863865\n",
            "train loss:0.004362118566674345\n",
            "train loss:0.001517581055586025\n",
            "train loss:0.0001482799819195903\n",
            "train loss:0.001013819674720822\n",
            "train loss:0.0009157127726277173\n",
            "train loss:0.0012636208229076895\n",
            "train loss:0.0012175904641982113\n",
            "train loss:5.9755195212574316e-05\n",
            "train loss:0.0003220864928441419\n",
            "train loss:0.007428320725777449\n",
            "train loss:0.0032000686124203236\n",
            "train loss:0.0013460829212810518\n",
            "train loss:0.0025966434808025497\n",
            "train loss:0.0006821059791741034\n",
            "train loss:0.0007380219557001661\n",
            "train loss:0.0001279033608275386\n",
            "train loss:0.0009231218356694521\n",
            "train loss:2.72974947231113e-05\n",
            "train loss:0.0008443678660748007\n",
            "train loss:0.001003351184926041\n",
            "train loss:0.0014524214057331313\n",
            "train loss:0.0006604211437990175\n",
            "train loss:0.00044025236051541047\n",
            "train loss:0.000770240026163921\n",
            "train loss:0.0006318403265268194\n",
            "train loss:0.006929518757616128\n",
            "train loss:0.0015956329870028636\n",
            "train loss:0.0008616470106493178\n",
            "train loss:0.0033479216040896266\n",
            "train loss:0.0005197147900232398\n",
            "train loss:0.0001947256431752186\n",
            "train loss:0.00022257594072973858\n",
            "train loss:0.003234860836590005\n",
            "train loss:0.0007384446051880746\n",
            "train loss:0.0002241633426263849\n",
            "train loss:0.00016957321670225394\n",
            "train loss:0.0003409036028538327\n",
            "train loss:0.0013905784523313746\n",
            "train loss:0.00031589986228904276\n",
            "train loss:0.00024538098773255293\n",
            "train loss:0.0028029533707464548\n",
            "train loss:0.0008574596231974162\n",
            "train loss:0.00352203558381116\n",
            "train loss:0.0005008098741003952\n",
            "train loss:0.0016534493428366492\n",
            "train loss:0.005440631666809553\n",
            "train loss:0.0006406041866860645\n",
            "train loss:9.40110108160363e-05\n",
            "train loss:0.01723084258270058\n",
            "train loss:0.0004585659381735975\n",
            "train loss:0.003676990386123929\n",
            "train loss:0.0008565859200224418\n",
            "train loss:3.751680259002634e-05\n",
            "train loss:0.0002488946783874026\n",
            "train loss:0.0006094170739354284\n",
            "train loss:0.0012339630566576881\n",
            "train loss:0.0014236079408867738\n",
            "train loss:0.00140022409935101\n",
            "train loss:0.00037347439143282696\n",
            "train loss:0.00011608664539742073\n",
            "train loss:0.0018001629909464728\n",
            "train loss:0.0002815787627755321\n",
            "train loss:0.002358582223069798\n",
            "train loss:0.005364609999444814\n",
            "train loss:0.002363419320965967\n",
            "train loss:0.0011055495149071958\n",
            "train loss:0.0005836838086984412\n",
            "train loss:0.00012380824268137718\n",
            "train loss:0.00041299774343202234\n",
            "train loss:2.7340964950560346e-05\n",
            "train loss:0.0006309645198763138\n",
            "train loss:0.00023622665831110818\n",
            "train loss:8.603383028854871e-05\n",
            "train loss:0.0001845077949876034\n",
            "train loss:0.0030668909770654824\n",
            "train loss:0.00011591568491401754\n",
            "train loss:0.001831014357092961\n",
            "train loss:0.0005796173154760239\n",
            "train loss:0.0021297049046506257\n",
            "train loss:0.00017849364185996156\n",
            "train loss:0.003911284192802785\n",
            "train loss:0.00011143724615359974\n",
            "train loss:0.002243276801733028\n",
            "train loss:0.0003460757839243916\n",
            "train loss:8.161242748480822e-05\n",
            "train loss:0.000610196178312495\n",
            "train loss:0.0018789595605905624\n",
            "train loss:9.128166432586444e-05\n",
            "train loss:0.0004279863060662792\n",
            "train loss:0.0016590071799446268\n",
            "train loss:0.0003230736981504981\n",
            "train loss:0.0015425699729761434\n",
            "train loss:0.003531842167278276\n",
            "train loss:0.004095835619985252\n",
            "train loss:0.001087823349274091\n",
            "train loss:0.00044860718410943626\n",
            "train loss:0.0001124637933561145\n",
            "train loss:0.00015329294672573003\n",
            "train loss:0.0009534807810154271\n",
            "train loss:9.917202719024484e-05\n",
            "train loss:0.001323518991355644\n",
            "train loss:0.0012981650442407903\n",
            "train loss:0.002767015897800901\n",
            "train loss:0.00056488985802551\n",
            "train loss:0.0003465608769970378\n",
            "train loss:0.0016499909435254965\n",
            "train loss:0.00034729057456430975\n",
            "train loss:0.0005529998133859899\n",
            "train loss:0.0018335520078628525\n",
            "train loss:0.00048743568883352455\n",
            "train loss:5.444785190281205e-05\n",
            "train loss:0.000764941129646897\n",
            "train loss:0.0005339396830846328\n",
            "train loss:0.003481298031402091\n",
            "train loss:0.0022650322716366235\n",
            "train loss:6.714169880221668e-05\n",
            "train loss:0.003159104782994978\n",
            "train loss:0.015421391313912498\n",
            "train loss:0.00035520246624605483\n",
            "train loss:0.00010695872612057277\n",
            "train loss:0.0007088553247796806\n",
            "train loss:0.00027440545384300666\n",
            "train loss:0.0004394944544804258\n",
            "train loss:0.0017625943002314356\n",
            "train loss:0.000528111942986296\n",
            "train loss:0.0013428181950591303\n",
            "train loss:0.0021847807149795347\n",
            "train loss:0.000650451551927953\n",
            "train loss:0.0005391413114626159\n",
            "train loss:3.49264551882757e-05\n",
            "train loss:0.001135950722704901\n",
            "train loss:0.0014044653565672366\n",
            "train loss:0.0011765333185555357\n",
            "train loss:0.00038681941495717143\n",
            "train loss:0.0019678138339348367\n",
            "train loss:0.00025132707540851377\n",
            "train loss:5.2953741054223004e-05\n",
            "train loss:9.891076449311488e-05\n",
            "train loss:0.00040013762810829856\n",
            "train loss:9.378245709422936e-05\n",
            "train loss:0.0017673761485383654\n",
            "train loss:0.0003008879766510684\n",
            "train loss:0.0015000475493618056\n",
            "train loss:0.0006745979238301701\n",
            "train loss:0.000978995837866123\n",
            "train loss:0.002095252319423495\n",
            "train loss:0.0015903984187487182\n",
            "train loss:1.1037489673837382e-05\n",
            "train loss:6.174184686072028e-05\n",
            "train loss:0.0024380520044452922\n",
            "train loss:0.0020796135129216207\n",
            "train loss:0.0032672962878544853\n",
            "train loss:0.0008057289061385337\n",
            "train loss:0.0005892112976106238\n",
            "train loss:0.0001665123004345401\n",
            "train loss:0.0014629499925330222\n",
            "train loss:0.0014271084765818342\n",
            "train loss:0.002718580702661072\n",
            "train loss:0.00016429516316303217\n",
            "train loss:0.0012240215094139165\n",
            "train loss:0.00017181631672219414\n",
            "train loss:1.4147609044046971e-05\n",
            "train loss:0.001341088929643197\n",
            "train loss:0.0012438447336360903\n",
            "train loss:0.0005802177408921864\n",
            "train loss:0.0011729109667347587\n",
            "train loss:0.010193813229514539\n",
            "train loss:0.000572225897816544\n",
            "train loss:0.0007581098839291817\n",
            "train loss:0.00439164560515132\n",
            "train loss:0.0032230809655955416\n",
            "train loss:0.0013067901875950983\n",
            "train loss:0.003663062725999523\n",
            "train loss:0.00017372129260042092\n",
            "train loss:9.522765049858347e-05\n",
            "train loss:8.022825816791873e-05\n",
            "train loss:0.0003702949230247364\n",
            "train loss:0.0037389217576820955\n",
            "train loss:0.0015122411717577774\n",
            "train loss:0.00020584677081130333\n",
            "train loss:0.0010468333495516422\n",
            "train loss:0.00011735253835646322\n",
            "train loss:0.001189282154368866\n",
            "train loss:0.0021091747172147348\n",
            "train loss:0.00015514265675398815\n",
            "train loss:0.0035420251970046616\n",
            "train loss:0.0005301114401966697\n",
            "train loss:0.000757973389424087\n",
            "train loss:0.0002946985037481167\n",
            "train loss:0.00027352797863194076\n",
            "train loss:0.0033098746609990905\n",
            "train loss:0.001389249738352162\n",
            "train loss:0.0014816665553778095\n",
            "train loss:0.0023313089305585974\n",
            "train loss:0.0010908430969303535\n",
            "train loss:0.0003963617285432213\n",
            "train loss:0.0008047498725738482\n",
            "train loss:0.000318657100348766\n",
            "train loss:0.0025417514017286656\n",
            "train loss:0.0033929462909697643\n",
            "train loss:0.0021658965430485706\n",
            "train loss:0.00021652190599789255\n",
            "train loss:0.00011392651663927561\n",
            "train loss:0.0012833181889615273\n",
            "train loss:0.0002544380779349092\n",
            "train loss:0.00030324728732463303\n",
            "train loss:1.1139526682703916e-05\n",
            "train loss:0.0002666217589816852\n",
            "train loss:0.0001963099211222855\n",
            "train loss:0.0008176275238754929\n",
            "train loss:0.0014839947205948093\n",
            "train loss:0.002015593028255622\n",
            "train loss:0.0010269814220012687\n",
            "train loss:0.0015405742204403047\n",
            "train loss:0.00044532548982359\n",
            "train loss:0.005501474539408659\n",
            "train loss:0.0005015979554231381\n",
            "train loss:0.0035188557076872014\n",
            "train loss:0.0007553167201510698\n",
            "train loss:0.0009102910705293928\n",
            "train loss:0.0012674167167729497\n",
            "train loss:0.00024189471927750668\n",
            "train loss:0.0019353985731946704\n",
            "train loss:0.0015583078076895215\n",
            "train loss:0.0005040247055392094\n",
            "train loss:2.0192767887167588e-05\n",
            "train loss:0.00043791054313510136\n",
            "train loss:0.0010807887533538672\n",
            "train loss:0.005367112525744681\n",
            "train loss:0.0006946230874306324\n",
            "train loss:4.312877552183315e-05\n",
            "train loss:6.69197807782302e-05\n",
            "train loss:0.0011566811452520956\n",
            "train loss:0.0002606098113012267\n",
            "train loss:0.00023489094060316247\n",
            "train loss:0.0008551199209961028\n",
            "train loss:0.00035507856572002984\n",
            "train loss:0.0038414916606667004\n",
            "train loss:0.0007955359289150122\n",
            "train loss:0.0011310783163190929\n",
            "train loss:0.0027497891297296943\n",
            "train loss:0.0001633236923599112\n",
            "train loss:0.0006357578024056108\n",
            "train loss:0.0003375484064093526\n",
            "train loss:0.00040852871794610406\n",
            "train loss:0.00028305337245782046\n",
            "train loss:0.0044960402482722905\n",
            "train loss:0.0012342928522503969\n",
            "train loss:8.56885954357316e-05\n",
            "train loss:0.0038281789127760225\n",
            "train loss:0.00031078419020309425\n",
            "train loss:0.00025327705530699536\n",
            "train loss:0.010644517197564535\n",
            "train loss:0.00013075119197183193\n",
            "train loss:0.001110058416735698\n",
            "train loss:3.638784375172129e-05\n",
            "train loss:0.001455153488497469\n",
            "train loss:0.015063777428366336\n",
            "train loss:0.0008166311844848464\n",
            "train loss:0.0006865203470429827\n",
            "train loss:7.896369876494164e-05\n",
            "train loss:0.0023636369116406724\n",
            "train loss:0.00021545259657079147\n",
            "train loss:0.0007056046319636128\n",
            "train loss:0.002650315090467967\n",
            "train loss:0.0033429961148712063\n",
            "train loss:0.0007606346612710945\n",
            "train loss:0.0018762031797343968\n",
            "train loss:0.0031075039919544563\n",
            "train loss:0.002168581594163089\n",
            "train loss:0.008299654055117183\n",
            "train loss:0.0008370037643831195\n",
            "train loss:0.0030376580142979213\n",
            "train loss:0.004163915625518008\n",
            "train loss:0.0004560465129449607\n",
            "train loss:0.0016042164589626525\n",
            "train loss:0.001495774587596016\n",
            "train loss:0.0003898496694116436\n",
            "train loss:0.0011804493178679677\n",
            "train loss:0.0008264153943677344\n",
            "train loss:0.0015596745484804456\n",
            "train loss:0.003516106936856771\n",
            "train loss:0.007766092307323071\n",
            "train loss:0.00015333854196109608\n",
            "train loss:0.017353069894088677\n",
            "train loss:0.0003340428954975939\n",
            "train loss:0.00026609620229734354\n",
            "train loss:0.0022408900992530244\n",
            "train loss:0.00025542198370834973\n",
            "train loss:0.0012177253136592828\n",
            "train loss:0.0027304092692781406\n",
            "train loss:0.000870358640911969\n",
            "train loss:0.002559541099407989\n",
            "train loss:0.0015838154526405471\n",
            "train loss:0.00011110416714782784\n",
            "train loss:0.00037834584692809323\n",
            "train loss:7.888298356262498e-05\n",
            "train loss:0.002802118184667328\n",
            "train loss:0.00015309274206376196\n",
            "train loss:0.0010617123720961144\n",
            "train loss:9.54632794792578e-05\n",
            "train loss:0.0010292945677979053\n",
            "train loss:0.002403382663755836\n",
            "train loss:0.0009737598502590057\n",
            "train loss:0.001666079849531314\n",
            "train loss:0.006337203679192422\n",
            "train loss:0.0009087919712096856\n",
            "train loss:5.276122789511289e-05\n",
            "train loss:0.00021245196986605246\n",
            "train loss:0.0007177829344875597\n",
            "train loss:0.006223194744929245\n",
            "train loss:0.005260311039362232\n",
            "train loss:4.424190752115223e-05\n",
            "train loss:0.0004093298220944163\n",
            "train loss:0.0021012538144887403\n",
            "train loss:0.0006714926353861576\n",
            "train loss:0.0007238934425850879\n",
            "train loss:0.0006900603322658247\n",
            "train loss:0.00359573603960955\n",
            "=== epoch:20, train acc:0.995, test acc:0.988 ===\n",
            "train loss:0.0006282951499272589\n",
            "train loss:0.0011860411721198387\n",
            "train loss:0.004559468700536562\n",
            "train loss:0.0016594203708804058\n",
            "train loss:0.0007181769613148016\n",
            "train loss:0.009139175550215546\n",
            "train loss:0.0016238186444526613\n",
            "train loss:0.0021202190093952346\n",
            "train loss:0.0022075966689887056\n",
            "train loss:0.0005720653120374313\n",
            "train loss:9.269038968455907e-05\n",
            "train loss:5.170558854061121e-05\n",
            "train loss:0.004651272378557231\n",
            "train loss:0.012178517820145835\n",
            "train loss:0.0016439368684795634\n",
            "train loss:0.0068859823710924065\n",
            "train loss:0.002666594782852369\n",
            "train loss:0.0031561396813952675\n",
            "train loss:0.00016576270139594433\n",
            "train loss:0.0016580474223356542\n",
            "train loss:0.0021108006138083994\n",
            "train loss:0.0010990713007877036\n",
            "train loss:7.891087003581148e-05\n",
            "train loss:0.0008599478790091229\n",
            "train loss:0.0028126560942092404\n",
            "train loss:0.00013244645387968125\n",
            "train loss:0.00358686938416273\n",
            "train loss:0.0004021209212106705\n",
            "train loss:0.0005284764167301023\n",
            "train loss:0.0023408553715779756\n",
            "train loss:5.016143067729655e-05\n",
            "train loss:0.0008344462853545015\n",
            "train loss:0.0018264820152763248\n",
            "train loss:0.001702396423863788\n",
            "train loss:0.0014502269286700714\n",
            "train loss:7.868369828411917e-05\n",
            "train loss:0.0024737376210703732\n",
            "train loss:0.008943729902485459\n",
            "train loss:0.0005246411749980505\n",
            "train loss:0.0006809237908526857\n",
            "train loss:0.000896015904590521\n",
            "train loss:0.0013218635046434175\n",
            "train loss:0.0017090876237018699\n",
            "train loss:0.0019712451610792788\n",
            "train loss:0.0013018352031125785\n",
            "train loss:0.007829340257243288\n",
            "train loss:0.0005508069194967397\n",
            "train loss:0.001139708161363156\n",
            "train loss:0.006410571330920315\n",
            "train loss:0.0008394557240943705\n",
            "train loss:0.0016331971062822936\n",
            "train loss:0.0005063710220344645\n",
            "train loss:0.001502570484252508\n",
            "train loss:0.012527574451699117\n",
            "train loss:0.0008338751045586036\n",
            "train loss:0.0004938911551444579\n",
            "train loss:0.0015720359901860543\n",
            "train loss:0.0018069951195518366\n",
            "train loss:0.009178903084328456\n",
            "train loss:0.0020928085133464194\n",
            "train loss:0.006932504764175711\n",
            "train loss:0.00076677701294976\n",
            "train loss:0.0001977565518897807\n",
            "train loss:0.0010742592579418297\n",
            "train loss:0.00016728442860404344\n",
            "train loss:0.005201070322411795\n",
            "train loss:0.0002425336308512897\n",
            "train loss:0.001212917416531546\n",
            "train loss:0.0006316408014860624\n",
            "train loss:0.0001564951182746079\n",
            "train loss:0.0006900835890755931\n",
            "train loss:0.00026460773484492475\n",
            "train loss:0.003188731867435895\n",
            "train loss:0.00035321637051959775\n",
            "train loss:0.0009373588112800213\n",
            "train loss:0.0005797406581402936\n",
            "train loss:6.469637559655912e-05\n",
            "train loss:0.0031721947213550162\n",
            "train loss:0.0017375369426195406\n",
            "train loss:0.0008734234027574886\n",
            "train loss:0.0012396355094385738\n",
            "train loss:0.00020175946717479438\n",
            "train loss:0.0001717848033208115\n",
            "train loss:0.00043447007252956206\n",
            "train loss:0.0005715547053767205\n",
            "train loss:0.0010184984666820251\n",
            "train loss:0.0015410837627963137\n",
            "train loss:0.0007372480199744148\n",
            "train loss:0.0011139478166334166\n",
            "train loss:0.007601947739109542\n",
            "train loss:0.004977977872238515\n",
            "train loss:0.0007529375413698013\n",
            "train loss:0.005738669198627286\n",
            "train loss:0.0006144491084169132\n",
            "train loss:0.0013006341522978234\n",
            "train loss:0.0008087257174613375\n",
            "train loss:0.0005333270913510645\n",
            "train loss:0.0002717360296880372\n",
            "train loss:0.0006903211271160367\n",
            "train loss:0.0026018451227289656\n",
            "train loss:0.0019249395387997694\n",
            "train loss:1.9654568675846165e-05\n",
            "train loss:0.0003676952981540397\n",
            "train loss:0.0009405589868407911\n",
            "train loss:0.004536447330361265\n",
            "train loss:0.00567422187191379\n",
            "train loss:0.0033134358226310128\n",
            "train loss:0.0017520830877256163\n",
            "train loss:0.00010824005527434713\n",
            "train loss:0.0020238382652922405\n",
            "train loss:0.00041308410626449057\n",
            "train loss:7.485678717255602e-05\n",
            "train loss:0.0017103641197418263\n",
            "train loss:0.0014648037169732208\n",
            "train loss:0.0004110307145750207\n",
            "train loss:0.00021936115811777747\n",
            "train loss:0.0011544943450785487\n",
            "train loss:0.0008155351803593268\n",
            "train loss:2.429517842448677e-05\n",
            "train loss:0.003105441218186116\n",
            "train loss:8.693778833087149e-05\n",
            "train loss:0.0031002150656062296\n",
            "train loss:0.0002691435796013936\n",
            "train loss:0.00013715879531953212\n",
            "train loss:0.00028315719973644735\n",
            "train loss:0.000752439006971997\n",
            "train loss:0.002641471943671239\n",
            "train loss:0.020756208295825765\n",
            "train loss:9.395604258950403e-05\n",
            "train loss:0.001006190700239564\n",
            "train loss:8.322977225603439e-05\n",
            "train loss:0.005400234355615597\n",
            "train loss:0.00017230548844990247\n",
            "train loss:0.0017514383886781584\n",
            "train loss:0.004070499205136177\n",
            "train loss:0.00037157535661439656\n",
            "train loss:0.001365383036578495\n",
            "train loss:0.0010171890402396724\n",
            "train loss:0.00019491205700875941\n",
            "train loss:0.0005205039658353138\n",
            "train loss:0.0004201497435045922\n",
            "train loss:0.0001671283312616408\n",
            "train loss:0.002006056158393707\n",
            "train loss:0.00023934667916847426\n",
            "train loss:0.00036718141274422856\n",
            "train loss:0.000117573025848568\n",
            "train loss:0.0019258434698415947\n",
            "train loss:5.921968824543429e-05\n",
            "train loss:0.00033440033588838064\n",
            "train loss:0.0006420796040166424\n",
            "train loss:0.00013378382362469473\n",
            "train loss:0.0006568619776760847\n",
            "train loss:0.0005375629880786434\n",
            "train loss:0.0007828480452991143\n",
            "train loss:0.0006387724763549945\n",
            "train loss:0.0007233396082383301\n",
            "train loss:0.0022082053517764374\n",
            "train loss:0.0010878899230254901\n",
            "train loss:0.0012653049628628457\n",
            "train loss:8.645257319539029e-05\n",
            "train loss:0.0005314401514479632\n",
            "train loss:5.0785760037490086e-05\n",
            "train loss:7.222382573124307e-05\n",
            "train loss:0.00013304430942534474\n",
            "train loss:0.0003479135465202421\n",
            "train loss:0.001138789258266844\n",
            "train loss:0.00017253021714109444\n",
            "train loss:0.00016386833679368204\n",
            "train loss:0.00024831032672498616\n",
            "train loss:0.00037613369129687934\n",
            "train loss:0.0033099056413958953\n",
            "train loss:0.004710197583561162\n",
            "train loss:0.0019045103218439427\n",
            "train loss:0.0017357554179832032\n",
            "train loss:0.002931136760138154\n",
            "train loss:0.012838097520033072\n",
            "train loss:0.005947283631715321\n",
            "train loss:0.0006583058388613543\n",
            "train loss:0.0008953201371190739\n",
            "train loss:0.0033337910986219934\n",
            "train loss:0.0038448984502986307\n",
            "train loss:0.03845729833780105\n",
            "train loss:0.0004347584769851486\n",
            "train loss:0.0005581443981098882\n",
            "train loss:0.000503791994459066\n",
            "train loss:0.00038314447984381673\n",
            "train loss:0.0011182751247929119\n",
            "train loss:0.0028516128180905266\n",
            "train loss:9.449179153036469e-05\n",
            "train loss:0.004357737797236675\n",
            "train loss:0.0007872560976798758\n",
            "train loss:0.002445063949294702\n",
            "train loss:0.0006658632311309637\n",
            "train loss:0.0005656251032730822\n",
            "train loss:0.0007714488804956155\n",
            "train loss:0.0007475902161986804\n",
            "train loss:0.0002710010938884194\n",
            "train loss:0.0021340495780663225\n",
            "train loss:0.009739940536253206\n",
            "train loss:0.00043150060001443584\n",
            "train loss:0.0011114974369742993\n",
            "train loss:0.0002725456454644863\n",
            "train loss:0.002067682502413814\n",
            "train loss:0.002832389734788449\n",
            "train loss:0.004016984981949878\n",
            "train loss:0.0007871153703603216\n",
            "train loss:9.111572728175396e-06\n",
            "train loss:0.0008289195068474576\n",
            "train loss:0.0003322113875830216\n",
            "train loss:0.0023137656460458567\n",
            "train loss:0.0018369722359503375\n",
            "train loss:0.000536676252869078\n",
            "train loss:0.0010681768348818703\n",
            "train loss:0.0024507120464385265\n",
            "train loss:6.041112975920895e-05\n",
            "train loss:0.0001796487023694897\n",
            "train loss:0.0015109319575514516\n",
            "train loss:0.003043759441309068\n",
            "train loss:0.00011819133879275829\n",
            "train loss:0.00121654506546454\n",
            "train loss:0.00012509433817451564\n",
            "train loss:0.00019822752852856617\n",
            "train loss:2.9757543039492185e-05\n",
            "train loss:0.0004940430624074948\n",
            "train loss:0.0003254127332600776\n",
            "train loss:0.0001003614679662349\n",
            "train loss:0.0002698582492155046\n",
            "train loss:0.0005935636807700276\n",
            "train loss:0.00025556099811926514\n",
            "train loss:0.0006827180942001235\n",
            "train loss:0.0011112487811906209\n",
            "train loss:0.003958087506635696\n",
            "train loss:0.001012837816750849\n",
            "train loss:0.00010492331304559578\n",
            "train loss:0.000324578352351436\n",
            "train loss:4.2597070560830384e-05\n",
            "train loss:5.629866173374739e-05\n",
            "train loss:0.0024252724294326527\n",
            "train loss:0.0001307035485192354\n",
            "train loss:0.00300820835737459\n",
            "train loss:0.00013554344255359713\n",
            "train loss:0.0004625337632535916\n",
            "train loss:0.0014217059630496163\n",
            "train loss:0.0011543935577984664\n",
            "train loss:0.00013748925875310284\n",
            "train loss:0.00025869577883567957\n",
            "train loss:0.0030910793817056402\n",
            "train loss:0.000614057172137596\n",
            "train loss:9.405279301783826e-05\n",
            "train loss:0.0006796361331197228\n",
            "train loss:4.251694522707652e-05\n",
            "train loss:0.001149775471258892\n",
            "train loss:0.00010018672886842443\n",
            "train loss:0.0001522718027290604\n",
            "train loss:0.0005356866268334463\n",
            "train loss:0.0006620727855104863\n",
            "train loss:0.0022222144848864987\n",
            "train loss:0.0012606023175876458\n",
            "train loss:0.0004283696368915532\n",
            "train loss:0.00013157123953945498\n",
            "train loss:0.0001214862867340719\n",
            "train loss:0.0010853909258421643\n",
            "train loss:0.00020940049934050785\n",
            "train loss:0.0001099773101950177\n",
            "train loss:5.159330148786224e-05\n",
            "train loss:0.0008607496707804005\n",
            "train loss:0.0019242665245208978\n",
            "train loss:0.0018206301518051665\n",
            "train loss:0.0005416043826883641\n",
            "train loss:0.0045321346689937035\n",
            "train loss:0.0007857434663423004\n",
            "train loss:0.00044655795475868605\n",
            "train loss:0.0002524022631455689\n",
            "train loss:0.001493379991860654\n",
            "train loss:0.00012084653372726491\n",
            "train loss:0.0030579256618806483\n",
            "train loss:0.000708318112089686\n",
            "train loss:0.0003327422669241102\n",
            "train loss:0.001090775435660115\n",
            "train loss:0.0008659234180923142\n",
            "train loss:0.00438079886844785\n",
            "train loss:0.0006535400928044492\n",
            "train loss:0.003183403694335654\n",
            "train loss:0.0008627597124741598\n",
            "train loss:0.002745220791582463\n",
            "train loss:0.0014148009347967527\n",
            "train loss:3.9445234699347806e-05\n",
            "train loss:1.1343967155058824e-05\n",
            "train loss:0.00041789104440479103\n",
            "train loss:0.0005570970725323421\n",
            "train loss:0.0002556638653209095\n",
            "train loss:0.0002189040226505084\n",
            "train loss:0.000595215887008844\n",
            "train loss:0.0011517928936419669\n",
            "train loss:0.0004498477623424282\n",
            "train loss:0.001742381223143511\n",
            "train loss:0.0020172500927624934\n",
            "train loss:0.000566749453738695\n",
            "train loss:0.0009825862398614306\n",
            "train loss:8.944094646916629e-05\n",
            "train loss:0.0002648418521113946\n",
            "train loss:3.618673077385551e-05\n",
            "train loss:0.001036354595741551\n",
            "train loss:2.8757205032713114e-05\n",
            "train loss:0.0019767726431124026\n",
            "train loss:0.0002049900184352771\n",
            "train loss:0.000265541552938135\n",
            "train loss:0.0007150265154126262\n",
            "train loss:0.001639955379569775\n",
            "train loss:0.00036079710413499646\n",
            "train loss:0.0016282304440986062\n",
            "train loss:0.0009090986418687175\n",
            "train loss:0.0003975936166512734\n",
            "train loss:0.0008744230376425105\n",
            "train loss:3.5096897050734507e-05\n",
            "train loss:3.706936170840396e-05\n",
            "train loss:0.0022468114116656777\n",
            "train loss:0.0014271775003113715\n",
            "train loss:0.0003026066611234267\n",
            "train loss:0.0004129815119283903\n",
            "train loss:4.3128489817904665e-05\n",
            "train loss:0.0009033586305636031\n",
            "train loss:0.0006041611276649034\n",
            "train loss:5.7874507016653774e-05\n",
            "train loss:5.285075468699451e-05\n",
            "train loss:0.0001613339781137377\n",
            "train loss:0.0011895562294537687\n",
            "train loss:2.0615850252391942e-05\n",
            "train loss:0.003309281606909837\n",
            "train loss:1.85427360139541e-05\n",
            "train loss:0.0008352768836547446\n",
            "train loss:0.00041245761379395346\n",
            "train loss:0.0001365821415306309\n",
            "train loss:6.486967629302164e-05\n",
            "train loss:7.903338311587115e-05\n",
            "train loss:2.047993814369815e-05\n",
            "train loss:0.0003270859476887144\n",
            "train loss:1.7949242937816027e-05\n",
            "train loss:0.0002761563222066686\n",
            "train loss:5.8170310765985665e-05\n",
            "train loss:0.00033656814314059246\n",
            "train loss:0.00020702496376080777\n",
            "train loss:0.0005518187556022784\n",
            "train loss:0.0006405210789369571\n",
            "train loss:0.0002631589198272482\n",
            "train loss:8.613138477924942e-05\n",
            "train loss:0.0005880034683644459\n",
            "train loss:0.0003612831843297238\n",
            "train loss:0.006427315851764926\n",
            "train loss:0.0023462010350659033\n",
            "train loss:0.00014537379403035624\n",
            "train loss:0.0002679156492866758\n",
            "train loss:5.2978455923162234e-05\n",
            "train loss:0.00012472568784257783\n",
            "train loss:3.057245939361447e-05\n",
            "train loss:0.006469350157405669\n",
            "train loss:0.0005046125670018275\n",
            "train loss:0.0026258882655646443\n",
            "train loss:1.3419513427723249e-05\n",
            "train loss:4.5744759123209274e-05\n",
            "train loss:2.708218673800638e-05\n",
            "train loss:0.0012140813336679102\n",
            "train loss:5.516918347292033e-05\n",
            "train loss:0.001984873962778639\n",
            "train loss:7.804176317388805e-05\n",
            "train loss:0.005031271912707421\n",
            "train loss:0.0011308824917907268\n",
            "train loss:0.00022117847727809556\n",
            "train loss:0.0001088464201942709\n",
            "train loss:0.0002791942788354934\n",
            "train loss:0.001172538693607343\n",
            "train loss:0.0006166462825275185\n",
            "train loss:0.00014554552652578073\n",
            "train loss:0.0001896294475133225\n",
            "train loss:0.001189274039204567\n",
            "train loss:7.254577670417371e-06\n",
            "train loss:0.0018640161787868176\n",
            "train loss:0.001796780739606464\n",
            "train loss:2.3351564932103082e-05\n",
            "train loss:0.0003208545099491872\n",
            "train loss:3.6244294908469316e-05\n",
            "train loss:5.319981074386935e-05\n",
            "train loss:0.0011046987562737707\n",
            "train loss:0.00011854820131845665\n",
            "train loss:0.0010879869944454771\n",
            "train loss:0.0014935349477695986\n",
            "train loss:0.0003227001734326756\n",
            "train loss:2.4597919836207882e-05\n",
            "train loss:0.00010115353841064953\n",
            "train loss:0.0026925917862225864\n",
            "train loss:0.0005518129767887974\n",
            "train loss:0.0008902921934708708\n",
            "train loss:0.00012131988482096062\n",
            "train loss:5.961912370724483e-05\n",
            "train loss:2.9681870582766493e-05\n",
            "train loss:0.00024659369523623574\n",
            "train loss:0.0021385053186842506\n",
            "train loss:0.0002164602615464469\n",
            "train loss:0.028766594237106858\n",
            "train loss:0.0018515609944180595\n",
            "train loss:0.0006608868347348326\n",
            "train loss:0.011502230114884162\n",
            "train loss:0.00022767058022481486\n",
            "train loss:0.0015323774585030683\n",
            "train loss:0.00034472557827898746\n",
            "train loss:0.00031604050487586634\n",
            "train loss:0.0007253617702433281\n",
            "train loss:0.0012074826011972634\n",
            "train loss:0.0009640049594779081\n",
            "train loss:0.00067381922322307\n",
            "train loss:0.0018184979698450895\n",
            "train loss:0.00038507760266388445\n",
            "train loss:0.0040548549892478495\n",
            "train loss:0.0013441394236333836\n",
            "train loss:0.0007018713291181922\n",
            "train loss:6.847150449602463e-05\n",
            "train loss:3.4739889624098455e-05\n",
            "train loss:0.000741199258626887\n",
            "train loss:0.001236296331786632\n",
            "train loss:0.0005345156815654786\n",
            "train loss:0.001062278570588662\n",
            "train loss:0.0004464721827931171\n",
            "train loss:0.00041900970791527574\n",
            "train loss:0.0005318039786389675\n",
            "train loss:0.0025430070399301437\n",
            "train loss:0.0010357936279168619\n",
            "train loss:0.0017570972089050087\n",
            "train loss:0.0011028274055569166\n",
            "train loss:0.00041298517730675266\n",
            "train loss:0.00243339066579779\n",
            "train loss:0.0012639785867153625\n",
            "train loss:0.0002544813680467495\n",
            "train loss:0.00048750596409332644\n",
            "train loss:9.677716014870187e-05\n",
            "train loss:0.001711361790083503\n",
            "train loss:1.2906222457717974e-05\n",
            "train loss:0.00041837570609614327\n",
            "train loss:0.0001525111061395632\n",
            "train loss:5.447204500536977e-05\n",
            "train loss:0.0006565419858122542\n",
            "train loss:0.0003347280124741634\n",
            "train loss:0.0011473314283977152\n",
            "train loss:0.001224406389875696\n",
            "train loss:8.257531488810943e-05\n",
            "train loss:0.000684214259276722\n",
            "train loss:0.0017343926350684568\n",
            "train loss:0.0015351245619965015\n",
            "train loss:0.001465638776541202\n",
            "train loss:0.0002986323168358265\n",
            "train loss:0.0006832255133041191\n",
            "train loss:0.0013720143794849083\n",
            "train loss:0.00019474755452789376\n",
            "train loss:0.0026675582011107656\n",
            "train loss:0.0005057444398478678\n",
            "train loss:0.003859885011121833\n",
            "train loss:0.00014432543402960823\n",
            "train loss:5.0424014256619936e-05\n",
            "train loss:9.23737415670346e-05\n",
            "train loss:0.0009412973453133356\n",
            "train loss:0.00012027021232384188\n",
            "train loss:0.00016993070149414705\n",
            "train loss:0.0007201504206191252\n",
            "train loss:0.00024829801728468626\n",
            "train loss:0.00017084476315969315\n",
            "train loss:0.0004249179578111743\n",
            "train loss:0.0009345124972967207\n",
            "train loss:0.0009180437966809915\n",
            "train loss:0.0016154445040375642\n",
            "train loss:2.306669789886211e-05\n",
            "train loss:0.00030485452484177217\n",
            "train loss:0.0005785972748824111\n",
            "train loss:0.0003473663429138136\n",
            "train loss:0.00032801865491023495\n",
            "train loss:0.0006255946004910572\n",
            "train loss:0.0005757679506608936\n",
            "train loss:0.0004571271478284241\n",
            "train loss:0.00016223660569349645\n",
            "train loss:0.00022822418524093787\n",
            "train loss:0.0005444553579276294\n",
            "train loss:0.0003568604558082748\n",
            "train loss:0.0006760053881187789\n",
            "train loss:0.0013043471499357506\n",
            "train loss:0.00019133116922384963\n",
            "train loss:0.0007815505911075324\n",
            "train loss:0.0012907269702872213\n",
            "train loss:0.0006029072171903283\n",
            "train loss:0.0004999264497434695\n",
            "train loss:4.970287700327819e-05\n",
            "train loss:0.00013576571187202672\n",
            "train loss:0.0003011357752584079\n",
            "train loss:0.0012745533979174942\n",
            "train loss:9.23537434569195e-05\n",
            "train loss:2.487852890272806e-05\n",
            "train loss:0.0005399484026682745\n",
            "train loss:0.000547709042139484\n",
            "train loss:0.00017784322508145446\n",
            "train loss:0.00022228972477287813\n",
            "train loss:0.00025246897347359177\n",
            "train loss:0.00024634206227951876\n",
            "train loss:0.0001069335767368812\n",
            "train loss:7.096682590367948e-05\n",
            "train loss:0.000792659883188962\n",
            "train loss:0.001377549969129004\n",
            "train loss:0.0012877225852525485\n",
            "train loss:0.002140246610058563\n",
            "train loss:3.5905286354674574e-05\n",
            "train loss:0.000745935913453039\n",
            "train loss:3.437553304713282e-05\n",
            "train loss:0.0023344334604833827\n",
            "train loss:0.005452971826862663\n",
            "train loss:0.0001778688738649964\n",
            "train loss:0.003799093674273777\n",
            "train loss:0.0037259961492687303\n",
            "train loss:9.334318337895357e-05\n",
            "train loss:3.439098632477189e-05\n",
            "train loss:0.0010441369627573992\n",
            "train loss:0.002714311414027451\n",
            "train loss:0.0020127392837429323\n",
            "train loss:0.0006760556550619029\n",
            "train loss:9.51976278095623e-05\n",
            "train loss:0.001187818617999936\n",
            "train loss:0.0028526474957440095\n",
            "train loss:0.00014767974003609724\n",
            "train loss:7.690042629888095e-05\n",
            "train loss:8.082091081065006e-05\n",
            "train loss:7.298902228664027e-05\n",
            "train loss:0.0002485846959762749\n",
            "train loss:0.0010187095268187848\n",
            "train loss:0.000631494582269349\n",
            "train loss:0.0017053856138535125\n",
            "train loss:0.00016438142469538244\n",
            "train loss:0.00017730751603301228\n",
            "train loss:0.0006420124283592773\n",
            "train loss:0.00017276314965369177\n",
            "train loss:0.0018066848594307685\n",
            "train loss:0.014720025522199604\n",
            "train loss:0.0011122341184045565\n",
            "train loss:0.0006290832891839501\n",
            "train loss:0.0003223563675404927\n",
            "train loss:2.4710493964331287e-05\n",
            "train loss:0.00301169542131695\n",
            "train loss:8.83190470216702e-05\n",
            "train loss:0.0005160670989724243\n",
            "train loss:0.00042449695401806014\n",
            "train loss:0.0013159748860026973\n",
            "train loss:0.0005328789126454229\n",
            "train loss:0.00037693307106407154\n",
            "train loss:0.0002656106533861935\n",
            "train loss:0.004273839066815433\n",
            "train loss:0.0021116982158867906\n",
            "train loss:0.0014268164969452888\n",
            "train loss:0.004447800587502384\n",
            "train loss:1.138077517019047e-05\n",
            "train loss:0.0003803206914343955\n",
            "train loss:0.0020414590602898137\n",
            "train loss:0.0036459674948839432\n",
            "train loss:0.00010551209501945189\n",
            "train loss:0.0018597218053620218\n",
            "train loss:0.00012016960051334934\n",
            "train loss:0.0016204644568966508\n",
            "train loss:0.0007351135752154342\n",
            "train loss:0.001622400342024122\n",
            "train loss:0.0006934461764499403\n",
            "train loss:0.0005344575386718533\n",
            "train loss:0.002609516659119673\n",
            "train loss:0.0056376038237794515\n",
            "train loss:0.00028937031925482326\n",
            "train loss:0.00037836476518210394\n",
            "train loss:0.002388300497170126\n",
            "train loss:0.0001300395278091914\n",
            "train loss:0.0008119977480550628\n",
            "train loss:0.0024667811906275944\n",
            "train loss:0.0005964449629534916\n",
            "train loss:0.002572918194569686\n",
            "train loss:0.004530012969012106\n",
            "train loss:0.00010002893062496125\n",
            "train loss:6.922341762679697e-05\n",
            "train loss:0.0005275829169917784\n",
            "train loss:0.000586612836206155\n",
            "train loss:0.0004835384485819498\n",
            "train loss:0.00021994042638087775\n",
            "train loss:2.4763762016361825e-05\n",
            "train loss:0.00032796476319589605\n",
            "train loss:0.0002817693226845762\n",
            "train loss:0.0013307994677507651\n",
            "train loss:6.173940544709641e-05\n",
            "train loss:0.00010803687181365753\n",
            "train loss:0.0002651655031150842\n",
            "train loss:4.945884904029543e-05\n",
            "train loss:0.0011531905273242246\n",
            "train loss:0.00010281039693689482\n",
            "train loss:0.0012490175726050903\n",
            "train loss:0.0004241245702641755\n",
            "train loss:0.0004917784453064145\n",
            "train loss:0.001842964930365172\n",
            "train loss:8.058715644896958e-05\n",
            "train loss:1.324637625937103e-05\n",
            "train loss:0.000255632467319028\n",
            "train loss:0.0046535736932001364\n",
            "=============== Final Test Accuracy ===============\n",
            "test acc:0.9888\n",
            "Saved Network Parameters!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset.mnist import load_mnist\n",
        "from common.trainer import Trainer\n",
        "\n",
        "# データの読み込み\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
        "\n",
        "# 処理に時間のかかる場合はデータを削減 \n",
        "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
        "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
        "\n",
        "max_epochs = 20\n",
        "\n",
        "network = SimpleConvNet(input_dim=(1,28,28), \n",
        "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
        "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
        "                        \n",
        "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
        "                  epochs=max_epochs, mini_batch_size=100,\n",
        "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
        "                  evaluate_sample_num_per_epoch=1000)\n",
        "trainer.train()\n",
        "\n",
        "# パラメータの保存\n",
        "network.save_params(\"../ch07/params.pkl\")\n",
        "print(\"Saved Network Parameters!\")\n",
        "\n",
        "# グラフの描画\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(max_epochs)\n",
        "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
        "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.6 CNNの可視化\n",
        "## 7.6.1 1層目の重みの可視化\n",
        "畳み込み層のフィルターはエッジ（色が変化する境目）やブロブ（塊のある領域）などのプリミティブな情報を抽出する。"
      ],
      "metadata": {
        "id": "2-40RCi1eETC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHSHBssZPtAE"
      },
      "source": [
        "# ch07/visualize_filter.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GTqEjs2BPtAE",
        "outputId": "a9692771-3f3f-434c-9a3f-7f7beb2e803c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 30 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 30 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def filter_show(filters, nx=8, margin=3, scale=10):\n",
        "    \"\"\"\n",
        "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
        "    \"\"\"\n",
        "    FN, C, FH, FW = filters.shape\n",
        "    ny = int(np.ceil(FN / nx))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "    for i in range(FN):\n",
        "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
        "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "network = SimpleConvNet()\n",
        "# ランダム初期化後の重み\n",
        "filter_show(network.params['W1'])\n",
        "\n",
        "# 学習後の重み\n",
        "network.load_params(\"../ch07/params.pkl\")\n",
        "filter_show(network.params['W1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HygWWERPtAF"
      },
      "source": [
        "# ch07/apply_filter.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mzFrzOzYPtAF",
        "outputId": "f61489bc-93e5-4f3b-d326-2269e54f5f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from common.layers import Convolution\n",
        "\n",
        "def filter_show(filters, nx=4, show_num=16):\n",
        "    \"\"\"\n",
        "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
        "    \"\"\"\n",
        "    FN, C, FH, FW = filters.shape\n",
        "    ny = int(np.ceil(show_num / nx))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "    for i in range(show_num):\n",
        "        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
        "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "\n",
        "\n",
        "network = SimpleConvNet(input_dim=(1,28,28), \n",
        "                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
        "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
        "\n",
        "# 学習後の重み\n",
        "network.load_params(\"../ch07/params.pkl\")\n",
        "\n",
        "filter_show(network.params['W1'], 16)\n",
        "\n",
        "img = imread('../dataset/lena_gray.png')\n",
        "img = img.reshape(1, 1, *img.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "w_idx = 1\n",
        "\n",
        "for i in range(16):\n",
        "    w = network.params['W1'][i]\n",
        "    b = 0  # network.params['b1'][i]\n",
        "\n",
        "    w = w.reshape(1, *w.shape)\n",
        "    #b = b.reshape(1, *b.shape)\n",
        "    conv_layer = Convolution(w, b) \n",
        "    out = conv_layer.forward(img)\n",
        "    out = out.reshape(out.shape[2], out.shape[3])\n",
        "    \n",
        "    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.6.2 階層構造による情報抽出\n",
        "層が深くなるにつれて、抽出される情報はより抽象化される。  \n",
        "単純なエッジ→テクスチャ→より複雑な物体のパーツ、など。"
      ],
      "metadata": {
        "id": "rv2sFciOfjFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.7 代表的なCNN"
      ],
      "metadata": {
        "id": "spIBlSpKgoAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.7.1 LeNet\n",
        "1998年に提案されたCNNの元祖。  \n",
        "現在のCNNとの違い。  \n",
        "- 活性化関数がシグモイド関数。（現在はReLU）。  \n",
        "- サイズ縮小がサブサンプリング。（現在はMaxプーリング）。  \n",
        "\n",
        "※「現在」とあるが、本書執筆は2016年であることに注意。"
      ],
      "metadata": {
        "id": "erZmnAOTgtpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.7.2 AlexNet\n",
        "2012年にディープラーニングが注目されるきっかけとなった。  \n",
        "LeNetとの違い。  \n",
        "- 活性化関数がReLU。\n",
        "- LRN(Local Response Normalization)という局所的正規化を行う層を用いる。  \n",
        "- Dropoutを使用。"
      ],
      "metadata": {
        "id": "587NbcXlhhQI"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}