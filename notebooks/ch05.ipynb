{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/okada-tak/deep-learning-from-scratch/blob/master/notebooks/ch05.ipynb)\n",
        "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/okada-tak/deep-learning-from-scratch/blob/master/notebooks/ch05.ipynb)  \n",
        "# ■ch05/xxxx.py以外は追記（岡田）\n",
        "# 5章 誤差逆伝播法 のまとめ\n",
        "- 計算グラフを用いれば、計算過程を視覚的に把握することができる。  \n",
        "- 計算グラフのノードは局所的な計算によって構成される。局所的な計算が全体の計算を構成する。  \n",
        "- 計算グラフの順伝播は、通常の計算を行う。一方、計算グラフの逆伝播によって、各ノードの微分を求めることができる。  \n",
        "　＃ 逆伝播でなぜ微分が求まる？\n",
        "- ニューラルネットワークの構成要素をレイヤとして実装することで、勾配の計算を効率的に求めることができる（誤差逆伝播法）。  \n",
        "- 数値微分と誤差逆伝播法の結果を比較することで、誤差逆伝播法の実装に誤りがないことを確認できる（勾配確認）。"
      ],
      "metadata": {
        "id": "ckNSDHY-OrQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 連鎖律\n",
        "逆方向の伝播では「局所的な微分」を逆方向に伝達する。"
      ],
      "metadata": {
        "id": "T5ZybHe_aDXG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSqMVx8ROja5"
      },
      "source": [
        "# ch05/layer_naive.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGpgl3NoOja8"
      },
      "outputs": [],
      "source": [
        "# 乗算レイヤ\n",
        "class MulLayer:\n",
        "    def __init__(self):\n",
        "        self.x = None\n",
        "        self.y = None\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y                \n",
        "        out = x * y\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * self.y\n",
        "        dy = dout * self.x\n",
        "\n",
        "        return dx, dy\n",
        "\n",
        "# 加算レイヤ\n",
        "class AddLayer:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        out = x + y\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * 1\n",
        "        dy = dout * 1\n",
        "\n",
        "        return dx, dy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjdqG2mlOja9"
      },
      "source": [
        "# ch05/buy_apple.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6h6d3eROja-",
        "outputId": "f699649a-6bd6-47ef-fd64-54bae6185c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: 220\n",
            "dApple: 2.2\n",
            "dApple_num: 110\n",
            "dTax: 200\n"
          ]
        }
      ],
      "source": [
        "# p.138\n",
        "#\n",
        "# 100円 --X--X--\n",
        "# 2個   --|  |\n",
        "#            |\n",
        "# 消費税1.1--|\n",
        "#\n",
        "apple = 100\n",
        "apple_num = 2\n",
        "tax = 1.1\n",
        "\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# forward\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
        "price = mul_tax_layer.forward(apple_price, tax)\n",
        "\n",
        "# backward\n",
        "dprice = 1\n",
        "dapple_price, dtax = mul_tax_layer.backward(dprice)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
        "\n",
        "print(\"price:\", int(price))\n",
        "print(\"dApple:\", dapple)\n",
        "print(\"dApple_num:\", int(dapple_num))\n",
        "print(\"dTax:\", dtax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyDmDV2YOja_"
      },
      "source": [
        "# ch05/buy_apple_orange.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIBUzKsXOja_",
        "outputId": "c3373b0f-7dcc-4599-b0bf-578c1fbaa458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: 715\n",
            "dApple: 2.2\n",
            "dApple_num: 110\n",
            "dOrange: 3.3000000000000003\n",
            "dOrange_num: 165\n",
            "dTax: 650\n"
          ]
        }
      ],
      "source": [
        "# p.140\n",
        "#\n",
        "# リンゴ\n",
        "# 100円 --X--+--X--\n",
        "# 2個   --|  |  |\n",
        "#            |  |\n",
        "# オレンジ   |  |\n",
        "# 150円 --X--|  |\n",
        "# 3個   --|     |\n",
        "#               |\n",
        "#               |\n",
        "# 消費税1.1-----|\n",
        "#\n",
        "apple = 100\n",
        "apple_num = 2\n",
        "orange = 150\n",
        "orange_num = 3\n",
        "tax = 1.1\n",
        "\n",
        "# layer\n",
        "mul_apple_layer = MulLayer()\n",
        "mul_orange_layer = MulLayer()\n",
        "add_apple_orange_layer = AddLayer()\n",
        "mul_tax_layer = MulLayer()\n",
        "\n",
        "# forward\n",
        "apple_price = mul_apple_layer.forward(apple, apple_num)  # (1)\n",
        "orange_price = mul_orange_layer.forward(orange, orange_num)  # (2)\n",
        "all_price = add_apple_orange_layer.forward(apple_price, orange_price)  # (3)\n",
        "price = mul_tax_layer.forward(all_price, tax)  # (4)\n",
        "\n",
        "# backward\n",
        "dprice = 1\n",
        "dall_price, dtax = mul_tax_layer.backward(dprice)  # (4)\n",
        "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)  # (3)\n",
        "dorange, dorange_num = mul_orange_layer.backward(dorange_price)  # (2)\n",
        "dapple, dapple_num = mul_apple_layer.backward(dapple_price)  # (1)\n",
        "\n",
        "print(\"price:\", int(price))\n",
        "print(\"dApple:\", dapple)\n",
        "print(\"dApple_num:\", int(dapple_num))\n",
        "print(\"dOrange:\", dorange)\n",
        "print(\"dOrange_num:\", int(dorange_num))\n",
        "print(\"dTax:\", dtax)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5.1 ReLUレイヤ"
      ],
      "metadata": {
        "id": "mQlT4uApiXat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p.142\n",
        "import numpy as np\n",
        "\n",
        "x = np.array( [[1.0, -0.5], [-2.0, 3.0]])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBqq5_nzcWBu",
        "outputId": "16661331-5970-43c9-dbe5-77229b30f0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.  -0.5]\n",
            " [-2.   3. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (x <= 0)\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDjBQVm7ctua",
        "outputId": "c2a12e39-2305-4733-dc8a-b58fedac6c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False  True]\n",
            " [ True False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6.1 Affineレイヤ"
      ],
      "metadata": {
        "id": "KaKNVydeidnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# p.147\n",
        "import numpy as np\n",
        "\n",
        "X = np.random.rand(2)\n",
        "W = np.random.rand(2,3)\n",
        "B = np.random.rand(3)\n",
        "\n",
        "X.shape\n",
        "W.shape\n",
        "B.shape\n",
        "\n",
        "Y = np.dot(X, W) + B"
      ],
      "metadata": {
        "id": "_Q8jOy_ktvez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# p.147のおまけ\n",
        "import numpy as np\n",
        "\n",
        "X = np.random.rand(2)\n",
        "W = np.random.rand(3,2)\n",
        "B = np.random.rand(3)"
      ],
      "metadata": {
        "id": "S4CTzT6BuKyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.dot(W, X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIaGvGBvUOMl",
        "outputId": "3371c84f-62be-4a4a-ee1d-25b89eb181f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.78680389 0.89022726 0.80685978]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "p.147  \n",
        "X.shape (2,)と\n",
        "W.shape (2, 3)の行列積がとれるのはなぜ？\n",
        "\n",
        "(2,)は、2「行」n「列」を意味しない。要素数「2」というだけ。  \n",
        "\n",
        "p.57-58の3.3.3にも説明あり。"
      ],
      "metadata": {
        "id": "mzcDy54jV0mv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "p.148 式(5.13)の導出  \n",
        "1データ版Affineレイヤの逆伝播の導出【ゼロつく1のノート(数学)】  \n",
        "https://www.anarchive-beta.com/entry/2020/08/03/180000\n",
        "\n",
        "バッチデータ版Affineレイヤの逆伝播の導出【ゼロつく1のノート(数学)】  \n",
        "https://www.anarchive-beta.com/entry/2020/08/04/180000\n"
      ],
      "metadata": {
        "id": "0ttpyhq-ZPZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "★p.155の鳥マークの注釈  \n",
        "さらっと大事なことが書いてある。  \n",
        "・「ソフトマックス関数」の損失関数として「交差エントロピー誤差」を使う理由。  \n",
        "$$\n",
        "E=-\\sum_k t_k \\log{y_k}\n",
        "$$\n",
        "・「恒等関数」の損失関数として「2乗和誤差」を使う理由。  \n",
        "$$\n",
        "E=\\frac{1}{2}\\sum_k (y_k-t_k)^2\n",
        "$$\n",
        "いずれも逆伝播が$(y_1-t_1, y_2-t_2, y_3-t_3)$という、出力と教師ラベルの差という簡潔な形になるから。  \n",
        "p.278～の付録A.2で交差エントロピー誤差についての導出が書かれている。  \n",
        "\n",
        "感想：説明されれば、おお！と思うがそうなるように損失関数を設計する方法（どうやって考えつくの？）がわからない。"
      ],
      "metadata": {
        "id": "ZkfUaL91baQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ■追記（岡田）Colaboratory用\n",
        "Google Colaboratoryの場合、Google Driveに  \n",
        "dl-from-scratch/ch05  \n",
        "というフォルダを用意し、そこにこのjupyter notebookを配置。  \n",
        "(dl-from-scratchの部分は任意。)  \n",
        "また、datasetフォルダとcommonフォルダを\n",
        "dl-from-scratch/dataset  \n",
        "dl-from-scratch/common\n",
        "にコピーしておく。  \n",
        "\n",
        "以下のセルでGoogle Driveをマウント。許可を求められるので許可する。"
      ],
      "metadata": {
        "id": "bAN74CQGlIq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnjCkmJ4k3Eu",
        "outputId": "b473429b-7355-4280-c003-bba18acee875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ■追記（岡田）Colaboratory用\n",
        "chdirする。"
      ],
      "metadata": {
        "id": "7hvO60aYlQy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys,os\n",
        "os.chdir('/content/drive/My Drive/dl-from-scratch/')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BAxDdYj8lBax",
        "outputId": "a86935cc-9f33-44e6-99b7-86f202065872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/dl-from-scratch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjTIGlUpOjbA"
      },
      "source": [
        "# ch05/two_layer_net.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "p.113～ 4.5.1のTowLayerNetでは、np.dot+b, sigmoid, np.dot+b, softmaxの層構成だった。  \n",
        "ここでは、sigmoidではなくReluにしている。  \n",
        "また、p.153の図5-28はAffine, ReLU, Affine, ReLU, Affine, Softmaxで説明していて、1層おおい。  \n",
        "（Affineはnp.dot+bと同じ。）  \n",
        "↓のTwoLayerNetは、Affine, Relu, Affine, Softmaxの構成。"
      ],
      "metadata": {
        "id": "wQaxxKyp_2Vc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq6SuQAMOjbA"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "from common.layers import *\n",
        "from common.gradient import numerical_gradient\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "\n",
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
        "        # 重みの初期化\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        # レイヤの生成\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "        \n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "        \n",
        "    # x:入力データ, t:教師データ\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.lastLayer.forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "        \n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    # x:入力データ, t:教師データ\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "        \n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "        \n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 設定\n",
        "        grads = {}\n",
        "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
        "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
        "\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "↑のコードのgradientのところ。  \n",
        "\n",
        "lossを計算する。  \n",
        "　predictでOrderedDictの順にforwardを実行。(Affine, ReLU, Affine)  \n",
        "　最後にlastLayer(SoftmaxWithLoss)のforwardを実行。  \n",
        "■ここから逆伝播  \n",
        "lastLayer(SoftmaxWithLoss)の微分(dout)を計算し、  \n",
        "以降はOrderedDictに積んだ逆順でdoutを計算していく。  \n",
        "最後に１層２層の重み(W1, W2)、バイアス(b1, b2)を更新する。  \n",
        "W1,W2とか書き下しているのはわかりやすくするためだと思われる。  \n",
        "10層, 100層などになればループで回したりするのだろう。"
      ],
      "metadata": {
        "id": "Ue4Da51cf7R9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ54VSzTOjbB"
      },
      "source": [
        "# ch05/gradient_check.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBV-OWdEOjbC",
        "outputId": "3724003c-00b9-4d72-a740-e0c2015178b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1:3.9197367159310613e-10\n",
            "b1:2.135368406556894e-09\n",
            "W2:5.264271249327249e-09\n",
            "b2:1.4032852126283358e-07\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "# データの読み込み\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "x_batch = x_train[:3]\n",
        "t_batch = t_train[:3]\n",
        "\n",
        "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
        "grad_backprop = network.gradient(x_batch, t_batch)\n",
        "\n",
        "for key in grad_numerical.keys():\n",
        "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
        "    print(key + \":\" + str(diff))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlup3SgAOjbC"
      },
      "source": [
        "# ch05/train_neuralnet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv4r-P4aOjbC",
        "outputId": "05a197a3-1c61-49a5-b962-a0a28f4737b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11601666666666667 0.1129\n",
            "0.9069166666666667 0.9078\n",
            "0.9223666666666667 0.9245\n",
            "0.9371 0.9367\n",
            "0.9459 0.9421\n",
            "0.95115 0.9506\n",
            "0.9552666666666667 0.9517\n",
            "0.9591333333333333 0.9541\n",
            "0.9629833333333333 0.9583\n",
            "0.9662333333333334 0.9592\n",
            "0.9692333333333333 0.9621\n",
            "0.9706666666666667 0.9643\n",
            "0.9731333333333333 0.9661\n",
            "0.97475 0.9666\n",
            "0.9759666666666666 0.9661\n",
            "0.9774166666666667 0.9683\n",
            "0.9787 0.9686\n"
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "# データの読み込み\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 勾配\n",
        "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "    \n",
        "    # 更新\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "    \n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "一応、グラフを描いてみる。"
      ],
      "metadata": {
        "id": "O8tJzjoUh2vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# グラフの描画\n",
        "markers = {'train': 'o', 'test': 's'}\n",
        "x = np.arange(len(train_acc_list))\n",
        "plt.plot(x, train_acc_list, label='train acc')\n",
        "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "5QKJFuidgxW2",
        "outputId": "172575c5-8188-4c2d-9618-1687245d1880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}